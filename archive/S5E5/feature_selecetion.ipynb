{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc092aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rmsle import ag_rmsle_clamped_scorer, ag_rmsle_scorer\n",
    "from autogluon.tabular import TabularPredictor\n",
    "from itertools import combinations\n",
    "\n",
    "download = False\n",
    "\n",
    "if download:\n",
    "    !kaggle competitions download -c playground-series-s5e5 -p data/\n",
    "\n",
    "    import zipfile, pathlib, os\n",
    "\n",
    "    zip_path = pathlib.Path('data/playground-series-s5e5.zip')\n",
    "    with zipfile.ZipFile(zip_path) as z:\n",
    "        z.extractall(zip_path.parent)\n",
    "    os.remove(zip_path)\n",
    "\n",
    "def preprocess(train_df, test_df):\n",
    "    train_df, test_df = handle_columns(train_df, test_df)\n",
    "\n",
    "    for col in ['Age', 'Weight', 'Height', 'Duration', 'Heart_Rate', 'Body_Temp', 'BMI']:\n",
    "        train_df, test_df = handle_outliers(train_df, test_df, col)\n",
    "\n",
    "    train_df = remove_outliers(train_df, 'Calories')\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def handle_columns(train_df, test_df):\n",
    "    target = 'Calories'\n",
    "\n",
    "    combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "    combined_df['female'] = (combined_df['Sex'] == 'female').astype('int16')\n",
    "    combined_df['male']   = (combined_df['Sex'] == 'male').astype('int16')\n",
    "    combined_df = combined_df.drop(columns='Sex')\n",
    "    combined_df['Age'] = combined_df['Age'].astype('float64')\n",
    "\n",
    "    combined_df['BMI']  = combined_df['Weight'] / ((combined_df['Height'] / 100) ** 2)\n",
    "    combined_df['BSA']  = 0.007184 * combined_df['Weight'] ** 0.425 * combined_df['Height'] ** 0.725\n",
    "    combined_df['FFM']  = 0.407 * combined_df['Weight'] + 0.267 * combined_df['Height'] - 19.2\n",
    "    combined_df['HRMax'] = 220.0 - combined_df['Age']\n",
    "    combined_df['%HRMax'] = combined_df['Heart_Rate'] / combined_df['HRMax']\n",
    "    combined_df['HRR']   = combined_df['HRMax'] - combined_df['Heart_Rate']\n",
    "    combined_df['TRIMP'] = combined_df['Duration'] * combined_df['%HRMax']\n",
    "    combined_df['Thermal_Load'] = (combined_df['Body_Temp'] - 37.0) * combined_df['Duration']\n",
    "    combined_df['BMR'] = (\n",
    "        10 * combined_df['Weight']\n",
    "        + 6.25 * combined_df['Height']\n",
    "        - 5 * combined_df['Age']\n",
    "        + 5 * combined_df['male']\n",
    "        - 161 * combined_df['female']\n",
    "    )\n",
    "    combined_df['Keytel'] = combined_df['Duration'] * (\n",
    "        combined_df['Weight']     * (0.0475 * combined_df['male'] - 0.0302 * combined_df['female'])\n",
    "      + combined_df['Heart_Rate'] * (0.151  * combined_df['male'] + 0.107  * combined_df['female'])\n",
    "      - 13.17 * combined_df['male'] - 4.88 * combined_df['female']\n",
    "    )\n",
    "\n",
    "    num_cols  = combined_df.select_dtypes(['float64', 'int64']).drop(columns=[target]).columns\n",
    "    new_cols  = {}\n",
    "\n",
    "    \"\"\"for col1 in num_cols:\n",
    "        s1 = combined_df[col1]\n",
    "\n",
    "        new_cols[f'{col1}^2']      = s1 ** 2\n",
    "        new_cols[f'{col1}^3']      = s1 ** 3\n",
    "        new_cols[f'log1p({col1})'] = np.log1p(s1)\"\"\"\n",
    "\n",
    "    \"\"\"for col1, col2 in combinations(num_cols, 2):\n",
    "        s1, s2 = combined_df[col1], combined_df[col2]\n",
    "\n",
    "        new_cols[f'{col1}+{col2}'] = s1 + s2\n",
    "        new_cols[f'{col1}-{col2}'] = s1 - s2\n",
    "        new_cols[f'{col1}*{col2}'] = s1 * s2\n",
    "\n",
    "        if not (s2 == 0).any():\n",
    "            new_cols[f'{col1}/{col2}'] = s1 / s2\"\"\"\n",
    "\n",
    "\n",
    "    combined_df = pd.concat([combined_df, pd.DataFrame(new_cols, index=combined_df.index)], axis=1)\n",
    "\n",
    "    for c in combined_df.select_dtypes('float64'):\n",
    "        combined_df[c] = pd.to_numeric(combined_df[c], downcast='float')\n",
    "    for c in combined_df.select_dtypes('int64'):\n",
    "        combined_df[c] = pd.to_numeric(combined_df[c], downcast='integer')\n",
    "    combined_df = combined_df.drop(columns=['male'])\n",
    "    combined_df['female'] = combined_df['female'].astype('category')\n",
    "\n",
    "    train_df = combined_df.iloc[:len(train_df)].copy().set_index('id')\n",
    "    test_df  = combined_df.iloc[len(train_df):].copy().drop(columns=target).set_index('id')\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def handle_outliers(train_df, test_df, column):\n",
    "    q1 = train_df[column].quantile(0.25)\n",
    "    q3 = train_df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    train_df = train_df[(train_df[column] >= lower_bound) & (train_df[column] <= upper_bound)]\n",
    "    test_df[column] = test_df[column].clip(lower_bound, upper_bound)\n",
    "    return train_df, test_df\n",
    "\n",
    "def remove_outliers(df, column):\n",
    "    q1 = df[column].quantile(0.25)\n",
    "    q3 = df[column].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "\n",
    "train, test = pd.read_csv('data/train.csv'), pd.read_csv('data/test.csv')\n",
    "train, test = preprocess(train, test)\n",
    "\n",
    "target = 'Calories/Duration'\n",
    "train[target] = train['Calories'] / train['Duration']\n",
    "train = train.drop(columns=['Calories'])\n",
    "\n",
    "num_cols = [c for c in train.columns\n",
    "            if train[c].dtype.kind in \"fi\" and c != target]\n",
    "cat_cols = [c for c in train.columns\n",
    "            if train[c].dtype.name == \"category\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b309453",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CorrFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, threshold=0.99, sample_size=20_000, random_state=0):\n",
    "        self.threshold    = threshold\n",
    "        self.sample_size  = sample_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    # ---------- FIT ---------------------------------------------------\n",
    "    def fit(self, X, y=None):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "\n",
    "        if self.sample_size and len(X) > self.sample_size:\n",
    "            X = X.sample(self.sample_size, random_state=self.random_state)\n",
    "\n",
    "        corr  = X.corr(numeric_only=True).abs()\n",
    "        upper = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "        self.to_drop_ = [c for c in upper.columns if any(upper[c] > self.threshold)]\n",
    "\n",
    "        # remember original order\n",
    "        self.cols_     = X.columns.to_numpy()\n",
    "        self.drop_idx_ = [np.where(self.cols_ == c)[0][0] for c in self.to_drop_]\n",
    "        return self\n",
    "\n",
    "    # ---------- TRANSFORM ---------------------------------------------\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            return X.drop(columns=self.to_drop_, errors=\"ignore\")\n",
    "\n",
    "        keep_mask = np.ones(X.shape[1], dtype=bool)\n",
    "        keep_mask[self.drop_idx_] = False\n",
    "        return X[:, keep_mask]\n",
    "\n",
    "    # ---------- selector API ------------------------------------------\n",
    "    def get_support(self, indices=False):\n",
    "        mask = np.ones(len(self.cols_), dtype=bool)\n",
    "        mask[self.drop_idx_] = False\n",
    "        return np.where(mask)[0] if indices else mask\n",
    "\n",
    "    # ---------- NEW: feature-name API ---------------------------------\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        \"\"\"\n",
    "        Return the names of the columns that survive the correlation filter.\n",
    "        \"\"\"\n",
    "        # scikit-learn will pass input_features when it knows them;\n",
    "        # fall back to the order recorded in fit().\n",
    "        if input_features is None:\n",
    "            input_features = self.cols_\n",
    "        input_features = np.asarray(input_features, dtype=object)\n",
    "\n",
    "        mask = np.ones(len(input_features), dtype=bool)\n",
    "        mask[self.drop_idx_] = False\n",
    "        return input_features[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77c7b03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.compose      import ColumnTransformer\n",
    "from sklearn.preprocessing import (FunctionTransformer,\n",
    "                                   StandardScaler,\n",
    "                                   OneHotEncoder,\n",
    "                                   PolynomialFeatures,\n",
    "                                   QuantileTransformer)\n",
    "from sklearn.pipeline     import Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectFromModel\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import time, gc, traceback, sys, os\n",
    "from sklearn.base import clone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "import traceback\n",
    "from sklearn.base import clone\n",
    "\n",
    "def stability_mask(pipe,\n",
    "                           X, y,\n",
    "                           n_loop     = 100,\n",
    "                           frac       = 0.10,\n",
    "                           cutoff     = 0.40,\n",
    "                           seed       = 42,\n",
    "                           echo_every = 10):\n",
    "    \"\"\"\n",
    "    Bootstrap-based stability selection.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pipe        : sklearn Pipeline\n",
    "        Must end with a selector exposing get_support().\n",
    "    X, y        : pandas DataFrame / Series  (X MUST have column names)\n",
    "    n_loop      : int   – number of bootstrap iterations\n",
    "    frac        : float – fraction of rows per bootstrap sample (0–1)\n",
    "    cutoff      : float – keep features selected in ≥ cutoff fraction\n",
    "    seed        : int   – RNG seed\n",
    "    echo_every  : int   – print heartbeat every N iterations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    keep_mask : boolean array  (len = n_master_features)\n",
    "        True for columns that passed the cutoff.\n",
    "    freq      : float array\n",
    "        Selection frequency for every master feature.\n",
    "    \"\"\"\n",
    "    # ------------------------------------------------------------------\n",
    "    # 1. Fit the *prep* part once to know the master column list\n",
    "    #    (all steps before the final selector)\n",
    "    # ------------------------------------------------------------------\n",
    "    prep_only  = pipe[:-1]               # everything except last step\n",
    "    prep_only  = clone(prep_only).fit(X)\n",
    "    master_cols = prep_only.get_feature_names_out()\n",
    "    n_master    = len(master_cols)\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 2. Prepare the vote counter\n",
    "    # ------------------------------------------------------------------\n",
    "    votes  = np.zeros(n_master, dtype=int)\n",
    "    rng    = np.random.RandomState(seed)\n",
    "    t0     = time.time()\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 3. Bootstrap loop\n",
    "    # ------------------------------------------------------------------\n",
    "    for b in range(1, n_loop + 1):\n",
    "        try:\n",
    "            # ---- 3.1 sample rows -------------------------------------\n",
    "            idx = rng.choice(X.index, size=int(len(X) * frac), replace=True)\n",
    "            X_b, y_b = X.loc[idx], y.loc[idx]\n",
    "\n",
    "            # ---- 3.2 fit a fresh clone of the whole pipeline ---------\n",
    "            pipe_b = clone(pipe)\n",
    "            pipe_b.fit(X_b, y_b)\n",
    "\n",
    "            # ---- 3.3 columns that reached the selector --------------\n",
    "            surv_cols = pipe_b[:-1].get_feature_names_out()\n",
    "            mask_local = pipe_b.named_steps[pipe_b.steps[-1][0]].get_support()\n",
    "            selected_cols = surv_cols[mask_local]\n",
    "\n",
    "            # ---- 3.4 map to master index and add vote ---------------\n",
    "            votes += np.isin(master_cols, selected_cols)\n",
    "\n",
    "        except Exception:\n",
    "            print(f\"[{b}/{n_loop}] ⚠️  exception – skipped \"\n",
    "                  f\"(see stderr for details)\", file=sys.stderr)\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "\n",
    "        # ---- 3.5 heartbeat ------------------------------------------\n",
    "        if b % echo_every == 0 or b == n_loop:\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"[{time.strftime('%H:%M:%S')}] iteration {b}/{n_loop} \"\n",
    "                  f\"(elapsed {elapsed:,.1f}s)\")\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # 4. Final frequency & keep mask\n",
    "    # ------------------------------------------------------------------\n",
    "    freq = votes / n_loop\n",
    "    keep = freq >= cutoff\n",
    "    return keep, freq, master_cols\n",
    "\n",
    "def safe_log1p(X, eps: float = 1e-6):\n",
    "    # --- convert to ndarray without copying when possible --------------\n",
    "    if isinstance(X, (pd.Series, pd.DataFrame)):\n",
    "        arr = X.to_numpy(dtype=float, copy=False)\n",
    "    else:\n",
    "        arr = np.asarray(X, dtype=float)\n",
    "\n",
    "    # --- compute per-column shift -------------------------------------\n",
    "    col_min = arr.min(axis=0)                    # 1-D vector\n",
    "    shift   = np.where(col_min < -eps,           # only shift if <-eps\n",
    "                       col_min - eps,\n",
    "                       0.0)\n",
    "\n",
    "    # --- broadcast & transform ----------------------------------------\n",
    "    arr_shifted = arr - shift                   # row-wise broadcasting\n",
    "    return np.log1p(arr_shifted)\n",
    "\n",
    "log_branch = FunctionTransformer(safe_log1p, feature_names_out='one-to-one')\n",
    "\n",
    "\n",
    "recip_branch = FunctionTransformer(lambda X: 1/(X + 1e-6),\n",
    "                                   feature_names_out='one-to-one')\n",
    "\n",
    "poly_branch  = PolynomialFeatures(degree=2,\n",
    "                                  include_bias=False,\n",
    "                                  interaction_only=True)\n",
    "\n",
    "quant_branch = QuantileTransformer(output_distribution='uniform')\n",
    "\n",
    "num_union = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('raw',   'passthrough', num_cols),       # a, b, …\n",
    "        ('log',   log_branch,    num_cols),       # log(a), …\n",
    "        ('recip', recip_branch,  num_cols),       # 1/a, …\n",
    "        ('poly',  poly_branch,   num_cols),       # a*b, a*(1/b), …\n",
    "        ('quant', quant_branch, num_cols)         # quantiles of a, b, …\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "full = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_union, num_cols),\n",
    "        ('cat', 'passthrough', cat_cols)\n",
    "    ],\n",
    "    remainder='drop',\n",
    "    sparse_threshold=0.3\n",
    ")\n",
    "\n",
    "preselect = Pipeline([\n",
    "    ('prep',    full),\n",
    "    ('var',     VarianceThreshold(1e-4)),\n",
    "    ('corr',    CorrFilter(threshold=0.99, sample_size=10_000)),\n",
    "    ('scale',   StandardScaler(with_mean=False)),\n",
    "    ('sfrom',   SelectFromModel(\n",
    "        estimator=ElasticNetCV(l1_ratio=[.1,.5,.9,1],\n",
    "                               cv=5, max_iter=3000,\n",
    "                               tol=1e-3, n_jobs=1),\n",
    "        threshold='median'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e15fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:31:24] iteration 10/100 (elapsed 403.9s)\n",
      "[16:36:49] iteration 20/100 (elapsed 729.3s)\n",
      "[16:41:46] iteration 30/100 (elapsed 1,025.7s)\n",
      "[16:46:48] iteration 40/100 (elapsed 1,328.2s)\n",
      "[16:52:00] iteration 50/100 (elapsed 1,639.7s)\n",
      "[16:59:34] iteration 60/100 (elapsed 2,094.1s)\n",
      "[17:05:15] iteration 70/100 (elapsed 2,435.0s)\n",
      "[17:09:26] iteration 80/100 (elapsed 2,686.0s)\n",
      "[17:13:32] iteration 90/100 (elapsed 2,931.8s)\n",
      "[17:17:54] iteration 100/100 (elapsed 3,193.9s)\n"
     ]
    }
   ],
   "source": [
    "keep_mask, freq, master_cols = stability_mask(\n",
    "    pipe       = preselect,\n",
    "    X          = train.drop(columns=target),\n",
    "    y          = train[target],\n",
    "    n_loop     = 100,\n",
    "    frac       = 0.10,\n",
    "    cutoff     = 0.60,\n",
    "    echo_every = 10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81db85d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['num__raw__Age', 'num__raw__Height', 'num__raw__Weight',\n",
       "       'num__raw__Duration', 'num__raw__Heart_Rate',\n",
       "       'num__raw__Body_Temp', 'num__raw__BMI', 'num__raw__%HRMax',\n",
       "       'num__raw__HRR', 'num__raw__TRIMP', 'num__raw__BMR',\n",
       "       'num__raw__Keytel', 'num__log__Age', 'num__log__Duration',\n",
       "       'num__log__HRR', 'num__log__TRIMP', 'num__log__Keytel',\n",
       "       'num__recip__Age', 'num__recip__Duration', 'num__recip__%HRMax',\n",
       "       'num__recip__Thermal_Load', 'num__recip__Keytel',\n",
       "       'num__poly__Age Height', 'num__poly__Age Weight',\n",
       "       'num__poly__Age Duration', 'num__poly__Age Heart_Rate',\n",
       "       'num__poly__Age BMI', 'num__poly__Age HRR',\n",
       "       'num__poly__Age Keytel', 'num__poly__Height Duration',\n",
       "       'num__poly__Height Heart_Rate', 'num__poly__Height Body_Temp',\n",
       "       'num__poly__Height BMI', 'num__poly__Height HRMax',\n",
       "       'num__poly__Height %HRMax', 'num__poly__Height HRR',\n",
       "       'num__poly__Height TRIMP', 'num__poly__Weight Duration',\n",
       "       'num__poly__Weight Heart_Rate', 'num__poly__Weight HRMax',\n",
       "       'num__poly__Weight %HRMax', 'num__poly__Weight HRR',\n",
       "       'num__poly__Weight TRIMP', 'num__poly__Weight Keytel',\n",
       "       'num__poly__Duration HRMax', 'num__poly__Duration HRR',\n",
       "       'num__poly__Duration TRIMP', 'num__poly__Duration Thermal_Load',\n",
       "       'num__poly__Duration Keytel', 'num__poly__Heart_Rate BMI',\n",
       "       'num__poly__Heart_Rate BSA', 'num__poly__Heart_Rate HRMax',\n",
       "       'num__poly__Heart_Rate %HRMax', 'num__poly__Heart_Rate BMR',\n",
       "       'num__poly__Body_Temp BMI', 'num__poly__Body_Temp HRMax',\n",
       "       'num__poly__BMI HRMax', 'num__poly__BMI %HRMax',\n",
       "       'num__poly__BMI HRR', 'num__poly__BMI BMR', 'num__poly__BSA HRMax',\n",
       "       'num__poly__BSA %HRMax', 'num__poly__BSA HRR',\n",
       "       'num__poly__HRMax BMR', 'num__poly__HRMax Keytel',\n",
       "       'num__poly__%HRMax HRR', 'num__poly__%HRMax TRIMP',\n",
       "       'num__poly__%HRMax BMR', 'num__poly__%HRMax Keytel',\n",
       "       'num__poly__HRR Thermal_Load', 'num__poly__HRR Keytel',\n",
       "       'num__poly__TRIMP Keytel', 'num__quant__Body_Temp',\n",
       "       'num__quant__BMI', 'num__quant__%HRMax', 'num__quant__HRR',\n",
       "       'num__quant__Keytel', 'cat__female'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_cols[keep_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a247108f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "554fbe95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "169c6c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_cols[keep_mask])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningPyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
