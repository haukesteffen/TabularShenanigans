{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from config.yaml.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler\n",
    "\n",
    "from utils.config import load_config\n",
    "from utils.data import download_competition_data\n",
    "\n",
    "config = load_config(\"config.yaml\")\n",
    "sklearn.set_config(transform_output=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bc9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for competition 'playground-series-s5e8' already exists at 'data/playground-series-s5e8.zip'.\n"
     ]
    }
   ],
   "source": [
    "train, test = download_competition_data(\n",
    "    competition_name=config.competition_name,\n",
    "    data_path=config.data_path,\n",
    ")\n",
    "\n",
    "month_map = {\n",
    "    \"jan\": 1,\n",
    "    \"feb\": 2,\n",
    "    \"mar\": 3,\n",
    "    \"apr\": 4,\n",
    "    \"may\": 5,\n",
    "    \"jun\": 6,\n",
    "    \"jul\": 7,\n",
    "    \"aug\": 8,\n",
    "    \"sep\": 9,\n",
    "    \"oct\": 10,\n",
    "    \"nov\": 11,\n",
    "    \"dec\": 12,\n",
    "}\n",
    "train[\"month\"] = train[\"month\"].map(month_map)\n",
    "test[\"month\"] = test[\"month\"].map(month_map)\n",
    "\n",
    "train[\"sin_day\"] = np.sin(2 * np.pi * train[\"day\"] / 31)\n",
    "train[\"cos_day\"] = np.cos(2 * np.pi * train[\"day\"] / 31)\n",
    "test[\"sin_day\"] = np.sin(2 * np.pi * test[\"day\"] / 31)\n",
    "test[\"cos_day\"] = np.cos(2 * np.pi * test[\"day\"] / 31)\n",
    "train[\"sin_month\"] = np.sin(2 * np.pi * train[\"month\"] / 12)\n",
    "train[\"cos_month\"] = np.cos(2 * np.pi * train[\"month\"] / 12)\n",
    "test[\"sin_month\"] = np.sin(2 * np.pi * test[\"month\"] / 12)\n",
    "test[\"cos_month\"] = np.cos(2 * np.pi * test[\"month\"] / 12)\n",
    "\n",
    "train.drop(columns=[\"day\", \"month\"], inplace=True)\n",
    "test.drop(columns=[\"day\", \"month\"], inplace=True)\n",
    "\n",
    "train[\"never_contacted_before\"] = train.apply(\n",
    "    lambda row: 1 if row[\"pdays\"] == -1 else 0, axis=1\n",
    ")\n",
    "test[\"never_contacted_before\"] = test.apply(\n",
    "    lambda row: 1 if row[\"pdays\"] == -1 else 0, axis=1\n",
    ")\n",
    "max_pdays = train[\"pdays\"].max()\n",
    "train[\"pdays\"] = train[\"pdays\"].apply(lambda x: x if x != -1 else max_pdays)\n",
    "test[\"pdays\"] = test[\"pdays\"].apply(lambda x: x if x != -1 else max_pdays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecce9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = train.drop(columns=[config.target_column])\n",
    "y_train_raw = train[config.target_column]\n",
    "X_test_raw = test.copy()\n",
    "\n",
    "X_train_raw, X_val_raw, y_train_raw, y_val_raw = train_test_split(\n",
    "    X_train_raw, y_train_raw, test_size=0.1, random_state=42, stratify=y_train_raw\n",
    ")\n",
    "\n",
    "features = X_train_raw.drop(columns=[\"id\"]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ae4aa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_features = [\"default\", \"housing\", \"loan\"]\n",
    "categorical_features = [\n",
    "    \"job\",\n",
    "    \"marital\",\n",
    "    \"education\",\n",
    "    \"contact\",\n",
    "    \"poutcome\",\n",
    "]\n",
    "numerical_features = [\n",
    "    \"age\",\n",
    "    \"balance\",\n",
    "    \"duration\",\n",
    "    \"campaign\",\n",
    "    \"pdays\",\n",
    "    \"previous\",\n",
    "    \"sin_day\",\n",
    "    \"cos_day\",\n",
    "    \"sin_month\",\n",
    "    \"cos_month\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2e5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"column_transform\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"binary_encode\",\n",
    "                        OrdinalEncoder(\n",
    "                            handle_unknown=\"use_encoded_value\", unknown_value=np.nan\n",
    "                        ),\n",
    "                        binary_features,\n",
    "                    ),\n",
    "                    (\n",
    "                        \"categorical_encode\",\n",
    "                        OneHotEncoder(\n",
    "                            handle_unknown=\"ignore\",\n",
    "                            sparse_output=False,\n",
    "                            drop=\"first\",\n",
    "                        ),\n",
    "                        categorical_features,\n",
    "                    ),\n",
    "                    (\n",
    "                        \"scale_numerical\",\n",
    "                        StandardScaler(),\n",
    "                        numerical_features,\n",
    "                    ),\n",
    "                    # (\n",
    "                    #    \"passthrough\",\n",
    "                    #    \"passthrough\",\n",
    "                    #    numerical_features,\n",
    "                    # ),\n",
    "                ],\n",
    "                remainder=\"drop\",\n",
    "                verbose_feature_names_out=False,\n",
    "            ),\n",
    "        ),\n",
    "        # (\"scaler\", StandardScaler()),\n",
    "        # (\"imputer\", KNNImputer(n_neighbors=10, weights=\"distance\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train_raw)\n",
    "X_val = pipeline.transform(X_val_raw)\n",
    "X_test = pipeline.transform(X_test_raw)\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "y_train = oe.fit_transform(pd.DataFrame(y_train_raw)).iloc[:, 0]\n",
    "y_val = oe.transform(pd.DataFrame(y_val_raw)).iloc[:, 0]\n",
    "\n",
    "class_weights = compute_class_weight(\"balanced\", classes=y_train.unique(), y=y_train)\n",
    "torch_weights = torch.tensor(class_weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfNormalizingNN(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple self-normalizing neural network using SELU activations\n",
    "    and LeCun normal initialization for stable training.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_size, hidden_sizes, output_size, dropout_rate=0.05):\n",
    "        super(SelfNormalizingNN, self).__init__()\n",
    "\n",
    "        # Build layers\n",
    "        self.layers = nn.ModuleList()\n",
    "        layer_sizes = [input_size] + hidden_sizes + [output_size]\n",
    "\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layer = nn.Linear(layer_sizes[i], layer_sizes[i + 1])\n",
    "            # LeCun normal initialization for self-normalization\n",
    "            nn.init.normal_(\n",
    "                layer.weight,\n",
    "                mean=0,\n",
    "                std=1 / torch.sqrt(torch.tensor(layer_sizes[i], dtype=torch.float32)),\n",
    "            )\n",
    "            nn.init.zeros_(layer.bias)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "        # Alpha dropout for SELU (maintains self-normalizing property)\n",
    "        self.dropout = nn.AlphaDropout(p=dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply SELU activation to all hidden layers\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = layer(x)\n",
    "            x = F.selu(x)  # Self-normalizing activation\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        # Output layer (no activation for flexibility)\n",
    "        x = self.layers[-1](x)\n",
    "        return x\n",
    "\n",
    "\n",
    "sample_weights = torch.tensor([torch_weights[int(i)] for i in y_train.values])\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights, num_samples=len(sample_weights), replacement=True\n",
    ")\n",
    "\n",
    "\n",
    "def create_dataloader(X, y, batch_size=2**16, shuffle=True, sampler=None):\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    if sampler:\n",
    "        shuffle = False  # Sampler handles shuffling\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, sampler=sampler)\n",
    "\n",
    "\n",
    "# Create the dataloaders\n",
    "train_loader = create_dataloader(X_train, y_train, sampler=sampler)\n",
    "val_loader = create_dataloader(X_val, y_val, shuffle=False)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "model = SelfNormalizingNN(\n",
    "    input_size=X_train.shape[1],\n",
    "    hidden_sizes=[32, 64, 32],\n",
    "    output_size=1,\n",
    "    dropout_rate=0.2,\n",
    ")\n",
    "# model = torch.compile(model)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            with torch.autocast(device_type=device.type):\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}]\\nTraining Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "        validate_model(model, val_loader, criterion)\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    all_labels = []\n",
    "    all_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            all_outputs.extend(outputs.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / len(val_loader.dataset)\n",
    "    auroc = roc_auc_score(all_labels, all_outputs)\n",
    "    print(f\"Validation Loss: {epoch_loss:.4f}, AUROC: {auroc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dad44de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000]\n",
      "Training Loss: 0.6804\n",
      "Validation Loss: 0.3209, AUROC: 0.9461\n",
      "Epoch [2/1000]\n",
      "Training Loss: 0.2878\n",
      "Validation Loss: 0.3221, AUROC: 0.9460\n",
      "Epoch [3/1000]\n",
      "Training Loss: 0.2875\n",
      "Validation Loss: 0.3151, AUROC: 0.9460\n",
      "Epoch [4/1000]\n",
      "Training Loss: 0.2882\n",
      "Validation Loss: 0.3107, AUROC: 0.9460\n",
      "Epoch [5/1000]\n",
      "Training Loss: 0.2877\n",
      "Validation Loss: 0.3100, AUROC: 0.9461\n",
      "Epoch [6/1000]\n",
      "Training Loss: 0.2872\n",
      "Validation Loss: 0.3109, AUROC: 0.9461\n",
      "Epoch [7/1000]\n",
      "Training Loss: 0.2867\n",
      "Validation Loss: 0.3116, AUROC: 0.9462\n",
      "Epoch [8/1000]\n",
      "Training Loss: 0.2868\n",
      "Validation Loss: 0.3114, AUROC: 0.9462\n",
      "Epoch [9/1000]\n",
      "Training Loss: 0.2863\n",
      "Validation Loss: 0.3108, AUROC: 0.9462\n",
      "Epoch [10/1000]\n",
      "Training Loss: 0.2864\n",
      "Validation Loss: 0.3104, AUROC: 0.9462\n",
      "Epoch [11/1000]\n",
      "Training Loss: 0.2883\n",
      "Validation Loss: 0.3107, AUROC: 0.9462\n",
      "Epoch [12/1000]\n",
      "Training Loss: 0.2869\n",
      "Validation Loss: 0.3105, AUROC: 0.9463\n",
      "Epoch [13/1000]\n",
      "Training Loss: 0.2873\n",
      "Validation Loss: 0.3102, AUROC: 0.9463\n",
      "Epoch [14/1000]\n",
      "Training Loss: 0.2876\n",
      "Validation Loss: 0.3104, AUROC: 0.9463\n",
      "Epoch [15/1000]\n",
      "Training Loss: 0.2861\n",
      "Validation Loss: 0.3103, AUROC: 0.9463\n",
      "Epoch [16/1000]\n",
      "Training Loss: 0.2862\n",
      "Validation Loss: 0.3104, AUROC: 0.9463\n",
      "Epoch [17/1000]\n",
      "Training Loss: 0.2866\n",
      "Validation Loss: 0.3108, AUROC: 0.9463\n",
      "Epoch [18/1000]\n",
      "Training Loss: 0.2867\n",
      "Validation Loss: 0.3110, AUROC: 0.9463\n",
      "Epoch [19/1000]\n",
      "Training Loss: 0.2861\n",
      "Validation Loss: 0.3110, AUROC: 0.9463\n",
      "Epoch [20/1000]\n",
      "Training Loss: 0.2865\n",
      "Validation Loss: 0.3109, AUROC: 0.9464\n",
      "Epoch [21/1000]\n",
      "Training Loss: 0.2866\n",
      "Validation Loss: 0.3106, AUROC: 0.9464\n",
      "Epoch [22/1000]\n",
      "Training Loss: 0.2878\n",
      "Validation Loss: 0.3105, AUROC: 0.9464\n",
      "Epoch [23/1000]\n",
      "Training Loss: 0.2860\n",
      "Validation Loss: 0.3107, AUROC: 0.9464\n",
      "Epoch [24/1000]\n",
      "Training Loss: 0.2869\n",
      "Validation Loss: 0.3106, AUROC: 0.9464\n",
      "Epoch [25/1000]\n",
      "Training Loss: 0.2861\n",
      "Validation Loss: 0.3111, AUROC: 0.9464\n",
      "Epoch [26/1000]\n",
      "Training Loss: 0.2859\n",
      "Validation Loss: 0.3112, AUROC: 0.9464\n",
      "Epoch [27/1000]\n",
      "Training Loss: 0.2858\n",
      "Validation Loss: 0.3109, AUROC: 0.9464\n",
      "Epoch [28/1000]\n",
      "Training Loss: 0.2860\n",
      "Validation Loss: 0.3113, AUROC: 0.9464\n",
      "Epoch [29/1000]\n",
      "Training Loss: 0.2853\n",
      "Validation Loss: 0.3116, AUROC: 0.9464\n",
      "Epoch [30/1000]\n",
      "Training Loss: 0.2870\n",
      "Validation Loss: 0.3112, AUROC: 0.9465\n",
      "Epoch [31/1000]\n",
      "Training Loss: 0.2860\n",
      "Validation Loss: 0.3104, AUROC: 0.9465\n",
      "Epoch [32/1000]\n",
      "Training Loss: 0.2869\n",
      "Validation Loss: 0.3104, AUROC: 0.9465\n",
      "Epoch [33/1000]\n",
      "Training Loss: 0.2871\n",
      "Validation Loss: 0.3100, AUROC: 0.9465\n",
      "Epoch [34/1000]\n",
      "Training Loss: 0.2856\n",
      "Validation Loss: 0.3101, AUROC: 0.9465\n",
      "Epoch [35/1000]\n",
      "Training Loss: 0.2855\n",
      "Validation Loss: 0.3104, AUROC: 0.9465\n",
      "Epoch [36/1000]\n",
      "Training Loss: 0.2862\n",
      "Validation Loss: 0.3106, AUROC: 0.9465\n",
      "Epoch [37/1000]\n",
      "Training Loss: 0.2857\n",
      "Validation Loss: 0.3103, AUROC: 0.9465\n",
      "Epoch [38/1000]\n",
      "Training Loss: 0.2862\n",
      "Validation Loss: 0.3099, AUROC: 0.9466\n",
      "Epoch [39/1000]\n",
      "Training Loss: 0.2856\n",
      "Validation Loss: 0.3095, AUROC: 0.9466\n",
      "Epoch [40/1000]\n",
      "Training Loss: 0.2870\n",
      "Validation Loss: 0.3098, AUROC: 0.9466\n",
      "Epoch [41/1000]\n",
      "Training Loss: 0.2857\n",
      "Validation Loss: 0.3096, AUROC: 0.9466\n",
      "Epoch [42/1000]\n",
      "Training Loss: 0.2862\n",
      "Validation Loss: 0.3096, AUROC: 0.9466\n",
      "Epoch [43/1000]\n",
      "Training Loss: 0.2863\n",
      "Validation Loss: 0.3103, AUROC: 0.9466\n",
      "Epoch [44/1000]\n",
      "Training Loss: 0.2864\n",
      "Validation Loss: 0.3098, AUROC: 0.9466\n",
      "Epoch [45/1000]\n",
      "Training Loss: 0.2849\n",
      "Validation Loss: 0.3093, AUROC: 0.9466\n",
      "Epoch [46/1000]\n",
      "Training Loss: 0.2864\n",
      "Validation Loss: 0.3097, AUROC: 0.9466\n",
      "Epoch [47/1000]\n",
      "Training Loss: 0.2861\n",
      "Validation Loss: 0.3095, AUROC: 0.9467\n",
      "Epoch [48/1000]\n",
      "Training Loss: 0.2856\n",
      "Validation Loss: 0.3096, AUROC: 0.9467\n",
      "Epoch [49/1000]\n",
      "Training Loss: 0.2864\n",
      "Validation Loss: 0.3090, AUROC: 0.9467\n",
      "Epoch [50/1000]\n",
      "Training Loss: 0.2856\n",
      "Validation Loss: 0.3092, AUROC: 0.9467\n",
      "Epoch [51/1000]\n",
      "Training Loss: 0.2868\n",
      "Validation Loss: 0.3095, AUROC: 0.9467\n",
      "Epoch [52/1000]\n",
      "Training Loss: 0.2853\n",
      "Validation Loss: 0.3096, AUROC: 0.9467\n",
      "Epoch [53/1000]\n",
      "Training Loss: 0.2853\n",
      "Validation Loss: 0.3091, AUROC: 0.9467\n",
      "Epoch [54/1000]\n",
      "Training Loss: 0.2853\n",
      "Validation Loss: 0.3089, AUROC: 0.9467\n",
      "Epoch [55/1000]\n",
      "Training Loss: 0.2851\n",
      "Validation Loss: 0.3091, AUROC: 0.9468\n",
      "Epoch [56/1000]\n",
      "Training Loss: 0.2850\n",
      "Validation Loss: 0.3091, AUROC: 0.9468\n",
      "Epoch [57/1000]\n",
      "Training Loss: 0.2843\n",
      "Validation Loss: 0.3091, AUROC: 0.9468\n",
      "Epoch [58/1000]\n",
      "Training Loss: 0.2846\n",
      "Validation Loss: 0.3091, AUROC: 0.9468\n",
      "Epoch [59/1000]\n",
      "Training Loss: 0.2860\n",
      "Validation Loss: 0.3093, AUROC: 0.9468\n",
      "Epoch [60/1000]\n",
      "Training Loss: 0.2852\n",
      "Validation Loss: 0.3099, AUROC: 0.9468\n",
      "Epoch [61/1000]\n",
      "Training Loss: 0.2858\n",
      "Validation Loss: 0.3095, AUROC: 0.9468\n",
      "Epoch [62/1000]\n",
      "Training Loss: 0.2855\n",
      "Validation Loss: 0.3084, AUROC: 0.9468\n",
      "Epoch [63/1000]\n",
      "Training Loss: 0.2844\n",
      "Validation Loss: 0.3089, AUROC: 0.9468\n",
      "Epoch [64/1000]\n",
      "Training Loss: 0.2837\n",
      "Validation Loss: 0.3096, AUROC: 0.9469\n",
      "Epoch [65/1000]\n",
      "Training Loss: 0.2844\n",
      "Validation Loss: 0.3093, AUROC: 0.9469\n",
      "Epoch [66/1000]\n",
      "Training Loss: 0.2847\n",
      "Validation Loss: 0.3087, AUROC: 0.9469\n",
      "Epoch [67/1000]\n",
      "Training Loss: 0.2847\n",
      "Validation Loss: 0.3082, AUROC: 0.9469\n",
      "Epoch [68/1000]\n",
      "Training Loss: 0.2849\n",
      "Validation Loss: 0.3083, AUROC: 0.9469\n",
      "Epoch [69/1000]\n",
      "Training Loss: 0.2850\n",
      "Validation Loss: 0.3080, AUROC: 0.9469\n",
      "Epoch [70/1000]\n",
      "Training Loss: 0.2856\n",
      "Validation Loss: 0.3085, AUROC: 0.9469\n",
      "Epoch [71/1000]\n",
      "Training Loss: 0.2842\n",
      "Validation Loss: 0.3088, AUROC: 0.9469\n",
      "Epoch [72/1000]\n",
      "Training Loss: 0.2859\n",
      "Validation Loss: 0.3082, AUROC: 0.9469\n",
      "Epoch [73/1000]\n",
      "Training Loss: 0.2843\n",
      "Validation Loss: 0.3085, AUROC: 0.9470\n",
      "Epoch [74/1000]\n",
      "Training Loss: 0.2843\n",
      "Validation Loss: 0.3089, AUROC: 0.9470\n",
      "Epoch [75/1000]\n",
      "Training Loss: 0.2850\n",
      "Validation Loss: 0.3082, AUROC: 0.9470\n",
      "Epoch [76/1000]\n",
      "Training Loss: 0.2833\n",
      "Validation Loss: 0.3078, AUROC: 0.9470\n",
      "Epoch [77/1000]\n",
      "Training Loss: 0.2854\n",
      "Validation Loss: 0.3084, AUROC: 0.9470\n",
      "Epoch [78/1000]\n",
      "Training Loss: 0.2848\n",
      "Validation Loss: 0.3084, AUROC: 0.9470\n",
      "Epoch [79/1000]\n",
      "Training Loss: 0.2838\n",
      "Validation Loss: 0.3081, AUROC: 0.9470\n",
      "Epoch [80/1000]\n",
      "Training Loss: 0.2843\n",
      "Validation Loss: 0.3075, AUROC: 0.9470\n",
      "Epoch [81/1000]\n",
      "Training Loss: 0.2845\n",
      "Validation Loss: 0.3074, AUROC: 0.9470\n",
      "Epoch [82/1000]\n",
      "Training Loss: 0.2840\n",
      "Validation Loss: 0.3073, AUROC: 0.9471\n",
      "Epoch [83/1000]\n",
      "Training Loss: 0.2837\n",
      "Validation Loss: 0.3078, AUROC: 0.9471\n",
      "Epoch [84/1000]\n",
      "Training Loss: 0.2850\n",
      "Validation Loss: 0.3086, AUROC: 0.9471\n",
      "Epoch [85/1000]\n",
      "Training Loss: 0.2840\n",
      "Validation Loss: 0.3077, AUROC: 0.9471\n",
      "Epoch [86/1000]\n",
      "Training Loss: 0.2829\n",
      "Validation Loss: 0.3076, AUROC: 0.9471\n",
      "Epoch [87/1000]\n",
      "Training Loss: 0.2838\n",
      "Validation Loss: 0.3086, AUROC: 0.9471\n",
      "Epoch [88/1000]\n",
      "Training Loss: 0.2827\n",
      "Validation Loss: 0.3092, AUROC: 0.9471\n",
      "Epoch [89/1000]\n",
      "Training Loss: 0.2838\n",
      "Validation Loss: 0.3081, AUROC: 0.9471\n",
      "Epoch [90/1000]\n",
      "Training Loss: 0.2850\n",
      "Validation Loss: 0.3071, AUROC: 0.9471\n",
      "Epoch [91/1000]\n",
      "Training Loss: 0.2848\n",
      "Validation Loss: 0.3072, AUROC: 0.9472\n",
      "Epoch [92/1000]\n",
      "Training Loss: 0.2848\n",
      "Validation Loss: 0.3073, AUROC: 0.9472\n",
      "Epoch [93/1000]\n",
      "Training Loss: 0.2840\n",
      "Validation Loss: 0.3074, AUROC: 0.9472\n",
      "Epoch [94/1000]\n",
      "Training Loss: 0.2837\n",
      "Validation Loss: 0.3080, AUROC: 0.9472\n",
      "Epoch [95/1000]\n",
      "Training Loss: 0.2830\n",
      "Validation Loss: 0.3085, AUROC: 0.9472\n",
      "Epoch [96/1000]\n",
      "Training Loss: 0.2836\n",
      "Validation Loss: 0.3080, AUROC: 0.9472\n",
      "Epoch [97/1000]\n",
      "Training Loss: 0.2844\n",
      "Validation Loss: 0.3077, AUROC: 0.9472\n",
      "Epoch [98/1000]\n",
      "Training Loss: 0.2841\n",
      "Validation Loss: 0.3080, AUROC: 0.9472\n",
      "Epoch [99/1000]\n",
      "Training Loss: 0.2835\n",
      "Validation Loss: 0.3075, AUROC: 0.9473\n",
      "Epoch [100/1000]\n",
      "Training Loss: 0.2841\n",
      "Validation Loss: 0.3071, AUROC: 0.9473\n",
      "Epoch [101/1000]\n",
      "Training Loss: 0.2830\n",
      "Validation Loss: 0.3073, AUROC: 0.9473\n",
      "Epoch [102/1000]\n",
      "Training Loss: 0.2837\n",
      "Validation Loss: 0.3073, AUROC: 0.9473\n",
      "Epoch [103/1000]\n",
      "Training Loss: 0.2834\n",
      "Validation Loss: 0.3069, AUROC: 0.9473\n",
      "Epoch [104/1000]\n",
      "Training Loss: 0.2825\n",
      "Validation Loss: 0.3072, AUROC: 0.9473\n",
      "Epoch [105/1000]\n",
      "Training Loss: 0.2834\n",
      "Validation Loss: 0.3077, AUROC: 0.9473\n",
      "Epoch [106/1000]\n",
      "Training Loss: 0.2840\n",
      "Validation Loss: 0.3080, AUROC: 0.9473\n",
      "Epoch [107/1000]\n",
      "Training Loss: 0.2821\n",
      "Validation Loss: 0.3073, AUROC: 0.9474\n",
      "Epoch [108/1000]\n",
      "Training Loss: 0.2824\n",
      "Validation Loss: 0.3073, AUROC: 0.9474\n",
      "Epoch [109/1000]\n",
      "Training Loss: 0.2829\n",
      "Validation Loss: 0.3072, AUROC: 0.9474\n",
      "Epoch [110/1000]\n",
      "Training Loss: 0.2829\n",
      "Validation Loss: 0.3075, AUROC: 0.9474\n",
      "Epoch [111/1000]\n",
      "Training Loss: 0.2844\n",
      "Validation Loss: 0.3075, AUROC: 0.9474\n",
      "Epoch [112/1000]\n",
      "Training Loss: 0.2831\n",
      "Validation Loss: 0.3069, AUROC: 0.9474\n",
      "Epoch [113/1000]\n",
      "Training Loss: 0.2825\n",
      "Validation Loss: 0.3074, AUROC: 0.9474\n",
      "Epoch [114/1000]\n",
      "Training Loss: 0.2829\n",
      "Validation Loss: 0.3079, AUROC: 0.9474\n",
      "Epoch [115/1000]\n",
      "Training Loss: 0.2829\n",
      "Validation Loss: 0.3071, AUROC: 0.9474\n",
      "Epoch [116/1000]\n",
      "Training Loss: 0.2827\n",
      "Validation Loss: 0.3068, AUROC: 0.9475\n",
      "Epoch [117/1000]\n",
      "Training Loss: 0.2834\n",
      "Validation Loss: 0.3070, AUROC: 0.9475\n",
      "Epoch [118/1000]\n",
      "Training Loss: 0.2830\n",
      "Validation Loss: 0.3067, AUROC: 0.9475\n",
      "Epoch [119/1000]\n",
      "Training Loss: 0.2826\n",
      "Validation Loss: 0.3065, AUROC: 0.9475\n",
      "Epoch [120/1000]\n",
      "Training Loss: 0.2836\n",
      "Validation Loss: 0.3067, AUROC: 0.9475\n",
      "Epoch [121/1000]\n",
      "Training Loss: 0.2829\n",
      "Validation Loss: 0.3066, AUROC: 0.9475\n",
      "Epoch [122/1000]\n",
      "Training Loss: 0.2826\n",
      "Validation Loss: 0.3071, AUROC: 0.9475\n",
      "Epoch [123/1000]\n",
      "Training Loss: 0.2827\n",
      "Validation Loss: 0.3073, AUROC: 0.9475\n",
      "Epoch [124/1000]\n",
      "Training Loss: 0.2813\n",
      "Validation Loss: 0.3070, AUROC: 0.9476\n",
      "Epoch [125/1000]\n",
      "Training Loss: 0.2823\n",
      "Validation Loss: 0.3069, AUROC: 0.9476\n",
      "Epoch [126/1000]\n",
      "Training Loss: 0.2825\n",
      "Validation Loss: 0.3069, AUROC: 0.9476\n",
      "Epoch [127/1000]\n",
      "Training Loss: 0.2812\n",
      "Validation Loss: 0.3065, AUROC: 0.9476\n",
      "Epoch [128/1000]\n",
      "Training Loss: 0.2825\n",
      "Validation Loss: 0.3064, AUROC: 0.9476\n",
      "Epoch [129/1000]\n",
      "Training Loss: 0.2826\n",
      "Validation Loss: 0.3069, AUROC: 0.9476\n",
      "Epoch [130/1000]\n",
      "Training Loss: 0.2821\n",
      "Validation Loss: 0.3070, AUROC: 0.9476\n",
      "Epoch [131/1000]\n",
      "Training Loss: 0.2808\n",
      "Validation Loss: 0.3064, AUROC: 0.9476\n",
      "Epoch [132/1000]\n",
      "Training Loss: 0.2829\n",
      "Validation Loss: 0.3061, AUROC: 0.9476\n",
      "Epoch [133/1000]\n",
      "Training Loss: 0.2835\n",
      "Validation Loss: 0.3057, AUROC: 0.9477\n",
      "Epoch [134/1000]\n",
      "Training Loss: 0.2828\n",
      "Validation Loss: 0.3054, AUROC: 0.9477\n",
      "Epoch [135/1000]\n",
      "Training Loss: 0.2835\n",
      "Validation Loss: 0.3060, AUROC: 0.9477\n",
      "Epoch [136/1000]\n",
      "Training Loss: 0.2824\n",
      "Validation Loss: 0.3057, AUROC: 0.9477\n",
      "Epoch [137/1000]\n",
      "Training Loss: 0.2821\n",
      "Validation Loss: 0.3054, AUROC: 0.9477\n",
      "Epoch [138/1000]\n",
      "Training Loss: 0.2817\n",
      "Validation Loss: 0.3056, AUROC: 0.9477\n",
      "Epoch [139/1000]\n",
      "Training Loss: 0.2814\n",
      "Validation Loss: 0.3071, AUROC: 0.9477\n",
      "Epoch [140/1000]\n",
      "Training Loss: 0.2822\n",
      "Validation Loss: 0.3062, AUROC: 0.9477\n",
      "Epoch [141/1000]\n",
      "Training Loss: 0.2818\n",
      "Validation Loss: 0.3050, AUROC: 0.9478\n",
      "Epoch [142/1000]\n",
      "Training Loss: 0.2824\n",
      "Validation Loss: 0.3058, AUROC: 0.9478\n",
      "Epoch [143/1000]\n",
      "Training Loss: 0.2815\n",
      "Validation Loss: 0.3062, AUROC: 0.9478\n",
      "Epoch [144/1000]\n",
      "Training Loss: 0.2812\n",
      "Validation Loss: 0.3053, AUROC: 0.9478\n",
      "Epoch [145/1000]\n",
      "Training Loss: 0.2803\n",
      "Validation Loss: 0.3054, AUROC: 0.9478\n",
      "Epoch [146/1000]\n",
      "Training Loss: 0.2815\n",
      "Validation Loss: 0.3059, AUROC: 0.9478\n",
      "Epoch [147/1000]\n",
      "Training Loss: 0.2819\n",
      "Validation Loss: 0.3060, AUROC: 0.9478\n",
      "Epoch [148/1000]\n",
      "Training Loss: 0.2814\n",
      "Validation Loss: 0.3054, AUROC: 0.9478\n",
      "Epoch [149/1000]\n",
      "Training Loss: 0.2817\n",
      "Validation Loss: 0.3049, AUROC: 0.9479\n",
      "Epoch [150/1000]\n",
      "Training Loss: 0.2820\n",
      "Validation Loss: 0.3050, AUROC: 0.9479\n",
      "Epoch [151/1000]\n",
      "Training Loss: 0.2822\n",
      "Validation Loss: 0.3056, AUROC: 0.9479\n",
      "Epoch [152/1000]\n",
      "Training Loss: 0.2811\n",
      "Validation Loss: 0.3056, AUROC: 0.9479\n",
      "Epoch [153/1000]\n",
      "Training Loss: 0.2817\n",
      "Validation Loss: 0.3051, AUROC: 0.9479\n",
      "Epoch [154/1000]\n",
      "Training Loss: 0.2804\n",
      "Validation Loss: 0.3049, AUROC: 0.9479\n",
      "Epoch [155/1000]\n",
      "Training Loss: 0.2806\n",
      "Validation Loss: 0.3054, AUROC: 0.9479\n",
      "Epoch [156/1000]\n",
      "Training Loss: 0.2804\n",
      "Validation Loss: 0.3051, AUROC: 0.9479\n",
      "Epoch [157/1000]\n",
      "Training Loss: 0.2812\n",
      "Validation Loss: 0.3043, AUROC: 0.9479\n",
      "Epoch [158/1000]\n",
      "Training Loss: 0.2801\n",
      "Validation Loss: 0.3046, AUROC: 0.9480\n",
      "Epoch [159/1000]\n",
      "Training Loss: 0.2798\n",
      "Validation Loss: 0.3056, AUROC: 0.9480\n",
      "Epoch [160/1000]\n",
      "Training Loss: 0.2812\n",
      "Validation Loss: 0.3053, AUROC: 0.9480\n",
      "Epoch [161/1000]\n",
      "Training Loss: 0.2815\n",
      "Validation Loss: 0.3050, AUROC: 0.9480\n",
      "Epoch [162/1000]\n",
      "Training Loss: 0.2815\n",
      "Validation Loss: 0.3048, AUROC: 0.9480\n",
      "Epoch [163/1000]\n",
      "Training Loss: 0.2820\n",
      "Validation Loss: 0.3048, AUROC: 0.9480\n",
      "Epoch [164/1000]\n",
      "Training Loss: 0.2814\n",
      "Validation Loss: 0.3041, AUROC: 0.9480\n",
      "Epoch [165/1000]\n",
      "Training Loss: 0.2806\n",
      "Validation Loss: 0.3043, AUROC: 0.9481\n",
      "Epoch [166/1000]\n",
      "Training Loss: 0.2802\n",
      "Validation Loss: 0.3045, AUROC: 0.9481\n",
      "Epoch [167/1000]\n",
      "Training Loss: 0.2794\n",
      "Validation Loss: 0.3048, AUROC: 0.9481\n",
      "Epoch [168/1000]\n",
      "Training Loss: 0.2798\n",
      "Validation Loss: 0.3053, AUROC: 0.9481\n",
      "Epoch [169/1000]\n",
      "Training Loss: 0.2809\n",
      "Validation Loss: 0.3052, AUROC: 0.9481\n",
      "Epoch [170/1000]\n",
      "Training Loss: 0.2814\n",
      "Validation Loss: 0.3052, AUROC: 0.9481\n",
      "Epoch [171/1000]\n",
      "Training Loss: 0.2811\n",
      "Validation Loss: 0.3045, AUROC: 0.9481\n",
      "Epoch [172/1000]\n",
      "Training Loss: 0.2812\n",
      "Validation Loss: 0.3047, AUROC: 0.9481\n",
      "Epoch [173/1000]\n",
      "Training Loss: 0.2802\n",
      "Validation Loss: 0.3056, AUROC: 0.9481\n",
      "Epoch [174/1000]\n",
      "Training Loss: 0.2802\n",
      "Validation Loss: 0.3054, AUROC: 0.9482\n",
      "Epoch [175/1000]\n",
      "Training Loss: 0.2803\n",
      "Validation Loss: 0.3051, AUROC: 0.9482\n",
      "Epoch [176/1000]\n",
      "Training Loss: 0.2794\n",
      "Validation Loss: 0.3051, AUROC: 0.9482\n",
      "Epoch [177/1000]\n",
      "Training Loss: 0.2795\n",
      "Validation Loss: 0.3052, AUROC: 0.9482\n",
      "Epoch [178/1000]\n",
      "Training Loss: 0.2801\n",
      "Validation Loss: 0.3045, AUROC: 0.9482\n",
      "Epoch [179/1000]\n",
      "Training Loss: 0.2798\n",
      "Validation Loss: 0.3042, AUROC: 0.9482\n",
      "Epoch [180/1000]\n",
      "Training Loss: 0.2806\n",
      "Validation Loss: 0.3048, AUROC: 0.9482\n",
      "Epoch [181/1000]\n",
      "Training Loss: 0.2802\n",
      "Validation Loss: 0.3051, AUROC: 0.9482\n",
      "Epoch [182/1000]\n",
      "Training Loss: 0.2805\n",
      "Validation Loss: 0.3057, AUROC: 0.9483\n",
      "Epoch [183/1000]\n",
      "Training Loss: 0.2797\n",
      "Validation Loss: 0.3051, AUROC: 0.9483\n",
      "Epoch [184/1000]\n",
      "Training Loss: 0.2804\n",
      "Validation Loss: 0.3034, AUROC: 0.9483\n",
      "Epoch [185/1000]\n",
      "Training Loss: 0.2796\n",
      "Validation Loss: 0.3034, AUROC: 0.9483\n",
      "Epoch [186/1000]\n",
      "Training Loss: 0.2807\n",
      "Validation Loss: 0.3039, AUROC: 0.9483\n",
      "Epoch [187/1000]\n",
      "Training Loss: 0.2799\n",
      "Validation Loss: 0.3038, AUROC: 0.9483\n",
      "Epoch [188/1000]\n",
      "Training Loss: 0.2809\n",
      "Validation Loss: 0.3039, AUROC: 0.9483\n",
      "Epoch [189/1000]\n",
      "Training Loss: 0.2791\n",
      "Validation Loss: 0.3042, AUROC: 0.9483\n",
      "Epoch [190/1000]\n",
      "Training Loss: 0.2810\n",
      "Validation Loss: 0.3049, AUROC: 0.9484\n",
      "Epoch [191/1000]\n",
      "Training Loss: 0.2800\n",
      "Validation Loss: 0.3043, AUROC: 0.9484\n",
      "Epoch [192/1000]\n",
      "Training Loss: 0.2795\n",
      "Validation Loss: 0.3045, AUROC: 0.9484\n",
      "Epoch [193/1000]\n",
      "Training Loss: 0.2793\n",
      "Validation Loss: 0.3036, AUROC: 0.9484\n",
      "Epoch [194/1000]\n",
      "Training Loss: 0.2798\n",
      "Validation Loss: 0.3031, AUROC: 0.9484\n",
      "Epoch [195/1000]\n",
      "Training Loss: 0.2780\n",
      "Validation Loss: 0.3042, AUROC: 0.9484\n",
      "Epoch [196/1000]\n",
      "Training Loss: 0.2804\n",
      "Validation Loss: 0.3042, AUROC: 0.9484\n",
      "Epoch [197/1000]\n",
      "Training Loss: 0.2793\n",
      "Validation Loss: 0.3037, AUROC: 0.9484\n",
      "Epoch [198/1000]\n",
      "Training Loss: 0.2792\n",
      "Validation Loss: 0.3037, AUROC: 0.9485\n",
      "Epoch [199/1000]\n",
      "Training Loss: 0.2782\n",
      "Validation Loss: 0.3043, AUROC: 0.9485\n",
      "Epoch [200/1000]\n",
      "Training Loss: 0.2800\n",
      "Validation Loss: 0.3040, AUROC: 0.9485\n",
      "Epoch [201/1000]\n",
      "Training Loss: 0.2799\n",
      "Validation Loss: 0.3028, AUROC: 0.9485\n",
      "Epoch [202/1000]\n",
      "Training Loss: 0.2805\n",
      "Validation Loss: 0.3029, AUROC: 0.9485\n",
      "Epoch [203/1000]\n",
      "Training Loss: 0.2799\n",
      "Validation Loss: 0.3033, AUROC: 0.9485\n",
      "Epoch [204/1000]\n",
      "Training Loss: 0.2783\n",
      "Validation Loss: 0.3037, AUROC: 0.9485\n",
      "Epoch [205/1000]\n",
      "Training Loss: 0.2800\n",
      "Validation Loss: 0.3034, AUROC: 0.9485\n",
      "Epoch [206/1000]\n",
      "Training Loss: 0.2798\n",
      "Validation Loss: 0.3038, AUROC: 0.9486\n",
      "Epoch [207/1000]\n",
      "Training Loss: 0.2782\n",
      "Validation Loss: 0.3039, AUROC: 0.9486\n",
      "Epoch [208/1000]\n",
      "Training Loss: 0.2795\n",
      "Validation Loss: 0.3037, AUROC: 0.9486\n",
      "Epoch [209/1000]\n",
      "Training Loss: 0.2790\n",
      "Validation Loss: 0.3037, AUROC: 0.9486\n",
      "Epoch [210/1000]\n",
      "Training Loss: 0.2802\n",
      "Validation Loss: 0.3032, AUROC: 0.9486\n",
      "Epoch [211/1000]\n",
      "Training Loss: 0.2781\n",
      "Validation Loss: 0.3024, AUROC: 0.9486\n",
      "Epoch [212/1000]\n",
      "Training Loss: 0.2794\n",
      "Validation Loss: 0.3036, AUROC: 0.9486\n",
      "Epoch [213/1000]\n",
      "Training Loss: 0.2795\n",
      "Validation Loss: 0.3037, AUROC: 0.9486\n",
      "Epoch [214/1000]\n",
      "Training Loss: 0.2789\n",
      "Validation Loss: 0.3030, AUROC: 0.9487\n",
      "Epoch [215/1000]\n",
      "Training Loss: 0.2788\n",
      "Validation Loss: 0.3029, AUROC: 0.9487\n",
      "Epoch [216/1000]\n",
      "Training Loss: 0.2770\n",
      "Validation Loss: 0.3029, AUROC: 0.9487\n",
      "Epoch [217/1000]\n",
      "Training Loss: 0.2789\n",
      "Validation Loss: 0.3032, AUROC: 0.9487\n",
      "Epoch [218/1000]\n",
      "Training Loss: 0.2796\n",
      "Validation Loss: 0.3030, AUROC: 0.9487\n",
      "Epoch [219/1000]\n",
      "Training Loss: 0.2785\n",
      "Validation Loss: 0.3029, AUROC: 0.9487\n",
      "Epoch [220/1000]\n",
      "Training Loss: 0.2782\n",
      "Validation Loss: 0.3030, AUROC: 0.9487\n",
      "Epoch [221/1000]\n",
      "Training Loss: 0.2790\n",
      "Validation Loss: 0.3031, AUROC: 0.9487\n",
      "Epoch [222/1000]\n",
      "Training Loss: 0.2781\n",
      "Validation Loss: 0.3031, AUROC: 0.9488\n",
      "Epoch [223/1000]\n",
      "Training Loss: 0.2791\n",
      "Validation Loss: 0.3028, AUROC: 0.9488\n",
      "Epoch [224/1000]\n",
      "Training Loss: 0.2789\n",
      "Validation Loss: 0.3025, AUROC: 0.9488\n",
      "Epoch [225/1000]\n",
      "Training Loss: 0.2781\n",
      "Validation Loss: 0.3027, AUROC: 0.9488\n",
      "Epoch [226/1000]\n",
      "Training Loss: 0.2786\n",
      "Validation Loss: 0.3040, AUROC: 0.9488\n",
      "Epoch [227/1000]\n",
      "Training Loss: 0.2799\n",
      "Validation Loss: 0.3027, AUROC: 0.9488\n",
      "Epoch [228/1000]\n",
      "Training Loss: 0.2786\n",
      "Validation Loss: 0.3025, AUROC: 0.9488\n",
      "Epoch [229/1000]\n",
      "Training Loss: 0.2783\n",
      "Validation Loss: 0.3030, AUROC: 0.9488\n",
      "Epoch [230/1000]\n",
      "Training Loss: 0.2780\n",
      "Validation Loss: 0.3026, AUROC: 0.9489\n",
      "Epoch [231/1000]\n",
      "Training Loss: 0.2779\n",
      "Validation Loss: 0.3019, AUROC: 0.9489\n",
      "Epoch [232/1000]\n",
      "Training Loss: 0.2797\n",
      "Validation Loss: 0.3013, AUROC: 0.9489\n",
      "Epoch [233/1000]\n",
      "Training Loss: 0.2781\n",
      "Validation Loss: 0.3024, AUROC: 0.9489\n",
      "Epoch [234/1000]\n",
      "Training Loss: 0.2780\n",
      "Validation Loss: 0.3034, AUROC: 0.9489\n",
      "Epoch [235/1000]\n",
      "Training Loss: 0.2781\n",
      "Validation Loss: 0.3025, AUROC: 0.9489\n",
      "Epoch [236/1000]\n",
      "Training Loss: 0.2783\n",
      "Validation Loss: 0.3014, AUROC: 0.9489\n",
      "Epoch [237/1000]\n",
      "Training Loss: 0.2784\n",
      "Validation Loss: 0.3013, AUROC: 0.9489\n",
      "Epoch [238/1000]\n",
      "Training Loss: 0.2782\n",
      "Validation Loss: 0.3024, AUROC: 0.9490\n",
      "Epoch [239/1000]\n",
      "Training Loss: 0.2779\n",
      "Validation Loss: 0.3028, AUROC: 0.9490\n",
      "Epoch [240/1000]\n",
      "Training Loss: 0.2779\n",
      "Validation Loss: 0.3015, AUROC: 0.9490\n",
      "Epoch [241/1000]\n",
      "Training Loss: 0.2775\n",
      "Validation Loss: 0.3019, AUROC: 0.9490\n",
      "Epoch [242/1000]\n",
      "Training Loss: 0.2786\n",
      "Validation Loss: 0.3023, AUROC: 0.9490\n",
      "Epoch [243/1000]\n",
      "Training Loss: 0.2781\n",
      "Validation Loss: 0.3027, AUROC: 0.9490\n",
      "Epoch [244/1000]\n",
      "Training Loss: 0.2779\n",
      "Validation Loss: 0.3026, AUROC: 0.9490\n",
      "Epoch [245/1000]\n",
      "Training Loss: 0.2771\n",
      "Validation Loss: 0.3023, AUROC: 0.9490\n",
      "Epoch [246/1000]\n",
      "Training Loss: 0.2770\n",
      "Validation Loss: 0.3025, AUROC: 0.9491\n",
      "Epoch [247/1000]\n",
      "Training Loss: 0.2774\n",
      "Validation Loss: 0.3025, AUROC: 0.9491\n",
      "Epoch [248/1000]\n",
      "Training Loss: 0.2757\n",
      "Validation Loss: 0.3024, AUROC: 0.9491\n",
      "Epoch [249/1000]\n",
      "Training Loss: 0.2776\n",
      "Validation Loss: 0.3010, AUROC: 0.9491\n",
      "Epoch [250/1000]\n",
      "Training Loss: 0.2780\n",
      "Validation Loss: 0.3017, AUROC: 0.9491\n",
      "Epoch [251/1000]\n",
      "Training Loss: 0.2775\n",
      "Validation Loss: 0.3015, AUROC: 0.9491\n",
      "Epoch [252/1000]\n",
      "Training Loss: 0.2779\n",
      "Validation Loss: 0.3012, AUROC: 0.9491\n",
      "Epoch [253/1000]\n",
      "Training Loss: 0.2767\n",
      "Validation Loss: 0.3018, AUROC: 0.9491\n",
      "Epoch [254/1000]\n",
      "Training Loss: 0.2779\n",
      "Validation Loss: 0.3019, AUROC: 0.9492\n",
      "Epoch [255/1000]\n",
      "Training Loss: 0.2776\n",
      "Validation Loss: 0.3013, AUROC: 0.9492\n",
      "Epoch [256/1000]\n",
      "Training Loss: 0.2765\n",
      "Validation Loss: 0.3013, AUROC: 0.9492\n",
      "Epoch [257/1000]\n",
      "Training Loss: 0.2774\n",
      "Validation Loss: 0.3016, AUROC: 0.9492\n",
      "Epoch [258/1000]\n",
      "Training Loss: 0.2762\n",
      "Validation Loss: 0.3023, AUROC: 0.9492\n",
      "Epoch [259/1000]\n",
      "Training Loss: 0.2763\n",
      "Validation Loss: 0.3014, AUROC: 0.9492\n",
      "Epoch [260/1000]\n",
      "Training Loss: 0.2774\n",
      "Validation Loss: 0.3007, AUROC: 0.9492\n",
      "Epoch [261/1000]\n",
      "Training Loss: 0.2773\n",
      "Validation Loss: 0.3010, AUROC: 0.9493\n",
      "Epoch [262/1000]\n",
      "Training Loss: 0.2770\n",
      "Validation Loss: 0.3013, AUROC: 0.9493\n",
      "Epoch [263/1000]\n",
      "Training Loss: 0.2770\n",
      "Validation Loss: 0.3014, AUROC: 0.9493\n",
      "Epoch [264/1000]\n",
      "Training Loss: 0.2765\n",
      "Validation Loss: 0.3008, AUROC: 0.9493\n",
      "Epoch [265/1000]\n",
      "Training Loss: 0.2774\n",
      "Validation Loss: 0.3009, AUROC: 0.9493\n",
      "Epoch [266/1000]\n",
      "Training Loss: 0.2770\n",
      "Validation Loss: 0.3014, AUROC: 0.9493\n",
      "Epoch [267/1000]\n",
      "Training Loss: 0.2773\n",
      "Validation Loss: 0.3014, AUROC: 0.9493\n",
      "Epoch [268/1000]\n",
      "Training Loss: 0.2762\n",
      "Validation Loss: 0.3010, AUROC: 0.9493\n",
      "Epoch [269/1000]\n",
      "Training Loss: 0.2764\n",
      "Validation Loss: 0.3013, AUROC: 0.9494\n",
      "Epoch [270/1000]\n",
      "Training Loss: 0.2765\n",
      "Validation Loss: 0.3006, AUROC: 0.9494\n",
      "Epoch [271/1000]\n",
      "Training Loss: 0.2771\n",
      "Validation Loss: 0.3008, AUROC: 0.9494\n",
      "Epoch [272/1000]\n",
      "Training Loss: 0.2771\n",
      "Validation Loss: 0.3007, AUROC: 0.9494\n",
      "Epoch [273/1000]\n",
      "Training Loss: 0.2759\n",
      "Validation Loss: 0.3012, AUROC: 0.9494\n",
      "Epoch [274/1000]\n",
      "Training Loss: 0.2764\n",
      "Validation Loss: 0.3017, AUROC: 0.9494\n",
      "Epoch [275/1000]\n",
      "Training Loss: 0.2760\n",
      "Validation Loss: 0.3010, AUROC: 0.9494\n",
      "Epoch [276/1000]\n",
      "Training Loss: 0.2765\n",
      "Validation Loss: 0.3000, AUROC: 0.9495\n",
      "Epoch [277/1000]\n",
      "Training Loss: 0.2767\n",
      "Validation Loss: 0.3007, AUROC: 0.9495\n",
      "Epoch [278/1000]\n",
      "Training Loss: 0.2771\n",
      "Validation Loss: 0.3014, AUROC: 0.9495\n",
      "Epoch [279/1000]\n",
      "Training Loss: 0.2766\n",
      "Validation Loss: 0.3011, AUROC: 0.9495\n",
      "Epoch [280/1000]\n",
      "Training Loss: 0.2762\n",
      "Validation Loss: 0.3005, AUROC: 0.9495\n",
      "Epoch [281/1000]\n",
      "Training Loss: 0.2773\n",
      "Validation Loss: 0.2995, AUROC: 0.9495\n",
      "Epoch [282/1000]\n",
      "Training Loss: 0.2769\n",
      "Validation Loss: 0.3012, AUROC: 0.9495\n",
      "Epoch [283/1000]\n",
      "Training Loss: 0.2767\n",
      "Validation Loss: 0.3017, AUROC: 0.9495\n",
      "Epoch [284/1000]\n",
      "Training Loss: 0.2765\n",
      "Validation Loss: 0.3002, AUROC: 0.9496\n",
      "Epoch [285/1000]\n",
      "Training Loss: 0.2773\n",
      "Validation Loss: 0.2996, AUROC: 0.9496\n",
      "Epoch [286/1000]\n",
      "Training Loss: 0.2754\n",
      "Validation Loss: 0.3009, AUROC: 0.9496\n",
      "Epoch [287/1000]\n",
      "Training Loss: 0.2768\n",
      "Validation Loss: 0.2999, AUROC: 0.9496\n",
      "Epoch [288/1000]\n",
      "Training Loss: 0.2760\n",
      "Validation Loss: 0.2992, AUROC: 0.9496\n",
      "Epoch [289/1000]\n",
      "Training Loss: 0.2761\n",
      "Validation Loss: 0.3002, AUROC: 0.9496\n",
      "Epoch [290/1000]\n",
      "Training Loss: 0.2756\n",
      "Validation Loss: 0.3001, AUROC: 0.9496\n",
      "Epoch [291/1000]\n",
      "Training Loss: 0.2741\n",
      "Validation Loss: 0.2999, AUROC: 0.9496\n",
      "Epoch [292/1000]\n",
      "Training Loss: 0.2757\n",
      "Validation Loss: 0.3005, AUROC: 0.9496\n",
      "Epoch [293/1000]\n",
      "Training Loss: 0.2767\n",
      "Validation Loss: 0.2992, AUROC: 0.9497\n",
      "Epoch [294/1000]\n",
      "Training Loss: 0.2751\n",
      "Validation Loss: 0.2996, AUROC: 0.9497\n",
      "Epoch [295/1000]\n",
      "Training Loss: 0.2754\n",
      "Validation Loss: 0.2998, AUROC: 0.9497\n",
      "Epoch [296/1000]\n",
      "Training Loss: 0.2759\n",
      "Validation Loss: 0.2999, AUROC: 0.9497\n",
      "Epoch [297/1000]\n",
      "Training Loss: 0.2766\n",
      "Validation Loss: 0.3002, AUROC: 0.9497\n",
      "Epoch [298/1000]\n",
      "Training Loss: 0.2749\n",
      "Validation Loss: 0.3001, AUROC: 0.9497\n",
      "Epoch [299/1000]\n",
      "Training Loss: 0.2758\n",
      "Validation Loss: 0.2996, AUROC: 0.9498\n",
      "Epoch [300/1000]\n",
      "Training Loss: 0.2756\n",
      "Validation Loss: 0.2998, AUROC: 0.9498\n",
      "Epoch [301/1000]\n",
      "Training Loss: 0.2760\n",
      "Validation Loss: 0.2998, AUROC: 0.9498\n",
      "Epoch [302/1000]\n",
      "Training Loss: 0.2765\n",
      "Validation Loss: 0.2987, AUROC: 0.9498\n",
      "Epoch [303/1000]\n",
      "Training Loss: 0.2751\n",
      "Validation Loss: 0.2989, AUROC: 0.9498\n",
      "Epoch [304/1000]\n",
      "Training Loss: 0.2751\n",
      "Validation Loss: 0.2998, AUROC: 0.9498\n",
      "Epoch [305/1000]\n",
      "Training Loss: 0.2751\n",
      "Validation Loss: 0.2995, AUROC: 0.9498\n",
      "Epoch [306/1000]\n",
      "Training Loss: 0.2745\n",
      "Validation Loss: 0.2999, AUROC: 0.9498\n",
      "Epoch [307/1000]\n",
      "Training Loss: 0.2758\n",
      "Validation Loss: 0.3002, AUROC: 0.9498\n",
      "Epoch [308/1000]\n",
      "Training Loss: 0.2763\n",
      "Validation Loss: 0.2993, AUROC: 0.9499\n",
      "Epoch [309/1000]\n",
      "Training Loss: 0.2741\n",
      "Validation Loss: 0.2981, AUROC: 0.9499\n",
      "Epoch [310/1000]\n",
      "Training Loss: 0.2754\n",
      "Validation Loss: 0.2992, AUROC: 0.9499\n",
      "Epoch [311/1000]\n",
      "Training Loss: 0.2746\n",
      "Validation Loss: 0.2998, AUROC: 0.9499\n",
      "Epoch [312/1000]\n",
      "Training Loss: 0.2750\n",
      "Validation Loss: 0.2997, AUROC: 0.9499\n",
      "Epoch [313/1000]\n",
      "Training Loss: 0.2745\n",
      "Validation Loss: 0.2992, AUROC: 0.9499\n",
      "Epoch [314/1000]\n",
      "Training Loss: 0.2756\n",
      "Validation Loss: 0.2988, AUROC: 0.9499\n",
      "Epoch [315/1000]\n",
      "Training Loss: 0.2749\n",
      "Validation Loss: 0.2988, AUROC: 0.9500\n",
      "Epoch [316/1000]\n",
      "Training Loss: 0.2754\n",
      "Validation Loss: 0.2991, AUROC: 0.9500\n",
      "Epoch [317/1000]\n",
      "Training Loss: 0.2740\n",
      "Validation Loss: 0.2999, AUROC: 0.9500\n",
      "Epoch [318/1000]\n",
      "Training Loss: 0.2748\n",
      "Validation Loss: 0.2999, AUROC: 0.9500\n",
      "Epoch [319/1000]\n",
      "Training Loss: 0.2759\n",
      "Validation Loss: 0.2996, AUROC: 0.9500\n",
      "Epoch [320/1000]\n",
      "Training Loss: 0.2747\n",
      "Validation Loss: 0.2985, AUROC: 0.9500\n",
      "Epoch [321/1000]\n",
      "Training Loss: 0.2748\n",
      "Validation Loss: 0.2985, AUROC: 0.9500\n",
      "Epoch [322/1000]\n",
      "Training Loss: 0.2751\n",
      "Validation Loss: 0.2989, AUROC: 0.9500\n",
      "Epoch [323/1000]\n",
      "Training Loss: 0.2762\n",
      "Validation Loss: 0.2991, AUROC: 0.9501\n",
      "Epoch [324/1000]\n",
      "Training Loss: 0.2749\n",
      "Validation Loss: 0.2983, AUROC: 0.9501\n",
      "Epoch [325/1000]\n",
      "Training Loss: 0.2743\n",
      "Validation Loss: 0.2987, AUROC: 0.9501\n",
      "Epoch [326/1000]\n",
      "Training Loss: 0.2747\n",
      "Validation Loss: 0.2983, AUROC: 0.9501\n",
      "Epoch [327/1000]\n",
      "Training Loss: 0.2751\n",
      "Validation Loss: 0.2982, AUROC: 0.9501\n",
      "Epoch [328/1000]\n",
      "Training Loss: 0.2743\n",
      "Validation Loss: 0.2988, AUROC: 0.9501\n",
      "Epoch [329/1000]\n",
      "Training Loss: 0.2753\n",
      "Validation Loss: 0.2984, AUROC: 0.9501\n",
      "Epoch [330/1000]\n",
      "Training Loss: 0.2745\n",
      "Validation Loss: 0.2976, AUROC: 0.9502\n",
      "Epoch [331/1000]\n",
      "Training Loss: 0.2745\n",
      "Validation Loss: 0.2978, AUROC: 0.9502\n",
      "Epoch [332/1000]\n",
      "Training Loss: 0.2742\n",
      "Validation Loss: 0.2981, AUROC: 0.9502\n",
      "Epoch [333/1000]\n",
      "Training Loss: 0.2745\n",
      "Validation Loss: 0.2975, AUROC: 0.9502\n",
      "Epoch [334/1000]\n",
      "Training Loss: 0.2744\n",
      "Validation Loss: 0.2983, AUROC: 0.9502\n",
      "Epoch [335/1000]\n",
      "Training Loss: 0.2732\n",
      "Validation Loss: 0.2993, AUROC: 0.9502\n",
      "Epoch [336/1000]\n",
      "Training Loss: 0.2748\n",
      "Validation Loss: 0.2989, AUROC: 0.9502\n",
      "Epoch [337/1000]\n",
      "Training Loss: 0.2743\n",
      "Validation Loss: 0.2979, AUROC: 0.9502\n",
      "Epoch [338/1000]\n",
      "Training Loss: 0.2741\n",
      "Validation Loss: 0.2980, AUROC: 0.9503\n",
      "Epoch [339/1000]\n",
      "Training Loss: 0.2738\n",
      "Validation Loss: 0.2983, AUROC: 0.9503\n",
      "Epoch [340/1000]\n",
      "Training Loss: 0.2741\n",
      "Validation Loss: 0.2987, AUROC: 0.9503\n",
      "Epoch [341/1000]\n",
      "Training Loss: 0.2745\n",
      "Validation Loss: 0.2985, AUROC: 0.9503\n",
      "Epoch [342/1000]\n",
      "Training Loss: 0.2736\n",
      "Validation Loss: 0.2984, AUROC: 0.9503\n",
      "Epoch [343/1000]\n",
      "Training Loss: 0.2736\n",
      "Validation Loss: 0.2981, AUROC: 0.9503\n",
      "Epoch [344/1000]\n",
      "Training Loss: 0.2744\n",
      "Validation Loss: 0.2984, AUROC: 0.9503\n",
      "Epoch [345/1000]\n",
      "Training Loss: 0.2733\n",
      "Validation Loss: 0.2977, AUROC: 0.9503\n",
      "Epoch [346/1000]\n",
      "Training Loss: 0.2739\n",
      "Validation Loss: 0.2971, AUROC: 0.9504\n",
      "Epoch [347/1000]\n",
      "Training Loss: 0.2729\n",
      "Validation Loss: 0.2982, AUROC: 0.9504\n",
      "Epoch [348/1000]\n",
      "Training Loss: 0.2743\n",
      "Validation Loss: 0.2985, AUROC: 0.9504\n",
      "Epoch [349/1000]\n",
      "Training Loss: 0.2746\n",
      "Validation Loss: 0.2978, AUROC: 0.9504\n",
      "Epoch [350/1000]\n",
      "Training Loss: 0.2735\n",
      "Validation Loss: 0.2976, AUROC: 0.9504\n",
      "Epoch [351/1000]\n",
      "Training Loss: 0.2741\n",
      "Validation Loss: 0.2974, AUROC: 0.9504\n",
      "Epoch [352/1000]\n",
      "Training Loss: 0.2733\n",
      "Validation Loss: 0.2978, AUROC: 0.9504\n",
      "Epoch [353/1000]\n",
      "Training Loss: 0.2739\n",
      "Validation Loss: 0.2981, AUROC: 0.9504\n",
      "Epoch [354/1000]\n",
      "Training Loss: 0.2728\n",
      "Validation Loss: 0.2994, AUROC: 0.9505\n",
      "Epoch [355/1000]\n",
      "Training Loss: 0.2732\n",
      "Validation Loss: 0.2975, AUROC: 0.9505\n",
      "Epoch [356/1000]\n",
      "Training Loss: 0.2734\n",
      "Validation Loss: 0.2970, AUROC: 0.9505\n",
      "Epoch [357/1000]\n",
      "Training Loss: 0.2738\n",
      "Validation Loss: 0.2974, AUROC: 0.9505\n",
      "Epoch [358/1000]\n",
      "Training Loss: 0.2738\n",
      "Validation Loss: 0.2978, AUROC: 0.9505\n",
      "Epoch [359/1000]\n",
      "Training Loss: 0.2719\n",
      "Validation Loss: 0.2986, AUROC: 0.9505\n",
      "Epoch [360/1000]\n",
      "Training Loss: 0.2745\n",
      "Validation Loss: 0.2977, AUROC: 0.9505\n",
      "Epoch [361/1000]\n",
      "Training Loss: 0.2729\n",
      "Validation Loss: 0.2972, AUROC: 0.9505\n",
      "Epoch [362/1000]\n",
      "Training Loss: 0.2738\n",
      "Validation Loss: 0.2975, AUROC: 0.9506\n",
      "Epoch [363/1000]\n",
      "Training Loss: 0.2746\n",
      "Validation Loss: 0.2974, AUROC: 0.9506\n",
      "Epoch [364/1000]\n",
      "Training Loss: 0.2737\n",
      "Validation Loss: 0.2970, AUROC: 0.9506\n",
      "Epoch [365/1000]\n",
      "Training Loss: 0.2740\n",
      "Validation Loss: 0.2964, AUROC: 0.9506\n",
      "Epoch [366/1000]\n",
      "Training Loss: 0.2742\n",
      "Validation Loss: 0.2963, AUROC: 0.9506\n",
      "Epoch [367/1000]\n",
      "Training Loss: 0.2720\n",
      "Validation Loss: 0.2971, AUROC: 0.9506\n",
      "Epoch [368/1000]\n",
      "Training Loss: 0.2737\n",
      "Validation Loss: 0.2977, AUROC: 0.9506\n",
      "Epoch [369/1000]\n",
      "Training Loss: 0.2724\n",
      "Validation Loss: 0.2973, AUROC: 0.9507\n",
      "Epoch [370/1000]\n",
      "Training Loss: 0.2742\n",
      "Validation Loss: 0.2963, AUROC: 0.9507\n",
      "Epoch [371/1000]\n",
      "Training Loss: 0.2734\n",
      "Validation Loss: 0.2975, AUROC: 0.9507\n",
      "Epoch [372/1000]\n",
      "Training Loss: 0.2739\n",
      "Validation Loss: 0.2976, AUROC: 0.9507\n",
      "Epoch [373/1000]\n",
      "Training Loss: 0.2724\n",
      "Validation Loss: 0.2976, AUROC: 0.9507\n",
      "Epoch [374/1000]\n",
      "Training Loss: 0.2726\n",
      "Validation Loss: 0.2963, AUROC: 0.9507\n",
      "Epoch [375/1000]\n",
      "Training Loss: 0.2729\n",
      "Validation Loss: 0.2958, AUROC: 0.9507\n",
      "Epoch [376/1000]\n",
      "Training Loss: 0.2723\n",
      "Validation Loss: 0.2973, AUROC: 0.9507\n",
      "Epoch [377/1000]\n",
      "Training Loss: 0.2732\n",
      "Validation Loss: 0.2974, AUROC: 0.9507\n",
      "Epoch [378/1000]\n",
      "Training Loss: 0.2725\n",
      "Validation Loss: 0.2969, AUROC: 0.9508\n",
      "Epoch [379/1000]\n",
      "Training Loss: 0.2730\n",
      "Validation Loss: 0.2963, AUROC: 0.9508\n",
      "Epoch [380/1000]\n",
      "Training Loss: 0.2725\n",
      "Validation Loss: 0.2971, AUROC: 0.9508\n",
      "Epoch [381/1000]\n",
      "Training Loss: 0.2728\n",
      "Validation Loss: 0.2975, AUROC: 0.9508\n",
      "Epoch [382/1000]\n",
      "Training Loss: 0.2731\n",
      "Validation Loss: 0.2961, AUROC: 0.9508\n",
      "Epoch [383/1000]\n",
      "Training Loss: 0.2718\n",
      "Validation Loss: 0.2956, AUROC: 0.9508\n",
      "Epoch [384/1000]\n",
      "Training Loss: 0.2726\n",
      "Validation Loss: 0.2965, AUROC: 0.9508\n",
      "Epoch [385/1000]\n",
      "Training Loss: 0.2726\n",
      "Validation Loss: 0.2964, AUROC: 0.9509\n",
      "Epoch [386/1000]\n",
      "Training Loss: 0.2720\n",
      "Validation Loss: 0.2962, AUROC: 0.9509\n",
      "Epoch [387/1000]\n",
      "Training Loss: 0.2724\n",
      "Validation Loss: 0.2967, AUROC: 0.9509\n",
      "Epoch [388/1000]\n",
      "Training Loss: 0.2726\n",
      "Validation Loss: 0.2971, AUROC: 0.9509\n",
      "Epoch [389/1000]\n",
      "Training Loss: 0.2707\n",
      "Validation Loss: 0.2962, AUROC: 0.9509\n",
      "Epoch [390/1000]\n",
      "Training Loss: 0.2722\n",
      "Validation Loss: 0.2961, AUROC: 0.9509\n",
      "Epoch [391/1000]\n",
      "Training Loss: 0.2721\n",
      "Validation Loss: 0.2963, AUROC: 0.9509\n",
      "Epoch [392/1000]\n",
      "Training Loss: 0.2716\n",
      "Validation Loss: 0.2963, AUROC: 0.9509\n",
      "Epoch [393/1000]\n",
      "Training Loss: 0.2724\n",
      "Validation Loss: 0.2958, AUROC: 0.9509\n",
      "Epoch [394/1000]\n",
      "Training Loss: 0.2722\n",
      "Validation Loss: 0.2959, AUROC: 0.9510\n",
      "Epoch [395/1000]\n",
      "Training Loss: 0.2719\n",
      "Validation Loss: 0.2968, AUROC: 0.9510\n",
      "Epoch [396/1000]\n",
      "Training Loss: 0.2734\n",
      "Validation Loss: 0.2962, AUROC: 0.9510\n",
      "Epoch [397/1000]\n",
      "Training Loss: 0.2724\n",
      "Validation Loss: 0.2944, AUROC: 0.9510\n",
      "Epoch [398/1000]\n",
      "Training Loss: 0.2716\n",
      "Validation Loss: 0.2957, AUROC: 0.9510\n",
      "Epoch [399/1000]\n",
      "Training Loss: 0.2717\n",
      "Validation Loss: 0.2967, AUROC: 0.9510\n",
      "Epoch [400/1000]\n",
      "Training Loss: 0.2717\n",
      "Validation Loss: 0.2966, AUROC: 0.9510\n",
      "Epoch [401/1000]\n",
      "Training Loss: 0.2710\n",
      "Validation Loss: 0.2959, AUROC: 0.9510\n",
      "Epoch [402/1000]\n",
      "Training Loss: 0.2713\n",
      "Validation Loss: 0.2963, AUROC: 0.9511\n",
      "Epoch [403/1000]\n",
      "Training Loss: 0.2724\n",
      "Validation Loss: 0.2960, AUROC: 0.9511\n",
      "Epoch [404/1000]\n",
      "Training Loss: 0.2712\n",
      "Validation Loss: 0.2958, AUROC: 0.9511\n",
      "Epoch [405/1000]\n",
      "Training Loss: 0.2712\n",
      "Validation Loss: 0.2963, AUROC: 0.9511\n",
      "Epoch [406/1000]\n",
      "Training Loss: 0.2713\n",
      "Validation Loss: 0.2959, AUROC: 0.9511\n",
      "Epoch [407/1000]\n",
      "Training Loss: 0.2717\n",
      "Validation Loss: 0.2968, AUROC: 0.9511\n",
      "Epoch [408/1000]\n",
      "Training Loss: 0.2708\n",
      "Validation Loss: 0.2962, AUROC: 0.9511\n",
      "Epoch [409/1000]\n",
      "Training Loss: 0.2714\n",
      "Validation Loss: 0.2948, AUROC: 0.9511\n",
      "Epoch [410/1000]\n",
      "Training Loss: 0.2727\n",
      "Validation Loss: 0.2948, AUROC: 0.9512\n",
      "Epoch [411/1000]\n",
      "Training Loss: 0.2725\n",
      "Validation Loss: 0.2954, AUROC: 0.9512\n",
      "Epoch [412/1000]\n",
      "Training Loss: 0.2722\n",
      "Validation Loss: 0.2950, AUROC: 0.9512\n",
      "Epoch [413/1000]\n",
      "Training Loss: 0.2709\n",
      "Validation Loss: 0.2949, AUROC: 0.9512\n",
      "Epoch [414/1000]\n",
      "Training Loss: 0.2706\n",
      "Validation Loss: 0.2950, AUROC: 0.9512\n",
      "Epoch [415/1000]\n",
      "Training Loss: 0.2714\n",
      "Validation Loss: 0.2947, AUROC: 0.9512\n",
      "Epoch [416/1000]\n",
      "Training Loss: 0.2703\n",
      "Validation Loss: 0.2958, AUROC: 0.9512\n",
      "Epoch [417/1000]\n",
      "Training Loss: 0.2714\n",
      "Validation Loss: 0.2963, AUROC: 0.9512\n",
      "Epoch [418/1000]\n",
      "Training Loss: 0.2714\n",
      "Validation Loss: 0.2953, AUROC: 0.9513\n",
      "Epoch [419/1000]\n",
      "Training Loss: 0.2713\n",
      "Validation Loss: 0.2946, AUROC: 0.9513\n",
      "Epoch [420/1000]\n",
      "Training Loss: 0.2715\n",
      "Validation Loss: 0.2952, AUROC: 0.9513\n",
      "Epoch [421/1000]\n",
      "Training Loss: 0.2705\n",
      "Validation Loss: 0.2953, AUROC: 0.9513\n",
      "Epoch [422/1000]\n",
      "Training Loss: 0.2714\n",
      "Validation Loss: 0.2951, AUROC: 0.9513\n",
      "Epoch [423/1000]\n",
      "Training Loss: 0.2713\n",
      "Validation Loss: 0.2949, AUROC: 0.9513\n",
      "Epoch [424/1000]\n",
      "Training Loss: 0.2711\n",
      "Validation Loss: 0.2954, AUROC: 0.9513\n",
      "Epoch [425/1000]\n",
      "Training Loss: 0.2703\n",
      "Validation Loss: 0.2951, AUROC: 0.9513\n",
      "Epoch [426/1000]\n",
      "Training Loss: 0.2709\n",
      "Validation Loss: 0.2958, AUROC: 0.9514\n",
      "Epoch [427/1000]\n",
      "Training Loss: 0.2716\n",
      "Validation Loss: 0.2945, AUROC: 0.9514\n",
      "Epoch [428/1000]\n",
      "Training Loss: 0.2707\n",
      "Validation Loss: 0.2941, AUROC: 0.9514\n",
      "Epoch [429/1000]\n",
      "Training Loss: 0.2714\n",
      "Validation Loss: 0.2947, AUROC: 0.9514\n",
      "Epoch [430/1000]\n",
      "Training Loss: 0.2711\n",
      "Validation Loss: 0.2946, AUROC: 0.9514\n",
      "Epoch [431/1000]\n",
      "Training Loss: 0.2708\n",
      "Validation Loss: 0.2945, AUROC: 0.9514\n",
      "Epoch [432/1000]\n",
      "Training Loss: 0.2706\n",
      "Validation Loss: 0.2948, AUROC: 0.9514\n",
      "Epoch [433/1000]\n",
      "Training Loss: 0.2716\n",
      "Validation Loss: 0.2940, AUROC: 0.9514\n",
      "Epoch [434/1000]\n",
      "Training Loss: 0.2714\n",
      "Validation Loss: 0.2940, AUROC: 0.9515\n",
      "Epoch [435/1000]\n",
      "Training Loss: 0.2701\n",
      "Validation Loss: 0.2941, AUROC: 0.9515\n",
      "Epoch [436/1000]\n",
      "Training Loss: 0.2715\n",
      "Validation Loss: 0.2944, AUROC: 0.9515\n",
      "Epoch [437/1000]\n",
      "Training Loss: 0.2705\n",
      "Validation Loss: 0.2938, AUROC: 0.9515\n",
      "Epoch [438/1000]\n",
      "Training Loss: 0.2713\n",
      "Validation Loss: 0.2941, AUROC: 0.9515\n",
      "Epoch [439/1000]\n",
      "Training Loss: 0.2703\n",
      "Validation Loss: 0.2938, AUROC: 0.9515\n",
      "Epoch [440/1000]\n",
      "Training Loss: 0.2702\n",
      "Validation Loss: 0.2948, AUROC: 0.9515\n",
      "Epoch [441/1000]\n",
      "Training Loss: 0.2705\n",
      "Validation Loss: 0.2950, AUROC: 0.9515\n",
      "Epoch [442/1000]\n",
      "Training Loss: 0.2705\n",
      "Validation Loss: 0.2949, AUROC: 0.9515\n",
      "Epoch [443/1000]\n",
      "Training Loss: 0.2710\n",
      "Validation Loss: 0.2935, AUROC: 0.9516\n",
      "Epoch [444/1000]\n",
      "Training Loss: 0.2695\n",
      "Validation Loss: 0.2943, AUROC: 0.9516\n",
      "Epoch [445/1000]\n",
      "Training Loss: 0.2706\n",
      "Validation Loss: 0.2956, AUROC: 0.9516\n",
      "Epoch [446/1000]\n",
      "Training Loss: 0.2689\n",
      "Validation Loss: 0.2953, AUROC: 0.9516\n",
      "Epoch [447/1000]\n",
      "Training Loss: 0.2705\n",
      "Validation Loss: 0.2938, AUROC: 0.9516\n",
      "Epoch [448/1000]\n",
      "Training Loss: 0.2706\n",
      "Validation Loss: 0.2939, AUROC: 0.9516\n",
      "Epoch [449/1000]\n",
      "Training Loss: 0.2701\n",
      "Validation Loss: 0.2944, AUROC: 0.9516\n",
      "Epoch [450/1000]\n",
      "Training Loss: 0.2703\n",
      "Validation Loss: 0.2931, AUROC: 0.9516\n",
      "Epoch [451/1000]\n",
      "Training Loss: 0.2700\n",
      "Validation Loss: 0.2937, AUROC: 0.9517\n",
      "Epoch [452/1000]\n",
      "Training Loss: 0.2693\n",
      "Validation Loss: 0.2943, AUROC: 0.9517\n",
      "Epoch [453/1000]\n",
      "Training Loss: 0.2698\n",
      "Validation Loss: 0.2941, AUROC: 0.9517\n",
      "Epoch [454/1000]\n",
      "Training Loss: 0.2706\n",
      "Validation Loss: 0.2931, AUROC: 0.9517\n",
      "Epoch [455/1000]\n",
      "Training Loss: 0.2698\n",
      "Validation Loss: 0.2931, AUROC: 0.9517\n",
      "Epoch [456/1000]\n",
      "Training Loss: 0.2704\n",
      "Validation Loss: 0.2943, AUROC: 0.9517\n",
      "Epoch [457/1000]\n",
      "Training Loss: 0.2703\n",
      "Validation Loss: 0.2937, AUROC: 0.9517\n",
      "Epoch [458/1000]\n",
      "Training Loss: 0.2706\n",
      "Validation Loss: 0.2933, AUROC: 0.9517\n",
      "Epoch [459/1000]\n",
      "Training Loss: 0.2688\n",
      "Validation Loss: 0.2928, AUROC: 0.9518\n",
      "Epoch [460/1000]\n",
      "Training Loss: 0.2694\n",
      "Validation Loss: 0.2940, AUROC: 0.9518\n",
      "Epoch [461/1000]\n",
      "Training Loss: 0.2706\n",
      "Validation Loss: 0.2942, AUROC: 0.9518\n",
      "Epoch [462/1000]\n",
      "Training Loss: 0.2689\n",
      "Validation Loss: 0.2940, AUROC: 0.9518\n",
      "Epoch [463/1000]\n",
      "Training Loss: 0.2699\n",
      "Validation Loss: 0.2932, AUROC: 0.9518\n",
      "Epoch [464/1000]\n",
      "Training Loss: 0.2694\n",
      "Validation Loss: 0.2927, AUROC: 0.9518\n",
      "Epoch [465/1000]\n",
      "Training Loss: 0.2694\n",
      "Validation Loss: 0.2934, AUROC: 0.9518\n",
      "Epoch [466/1000]\n",
      "Training Loss: 0.2686\n",
      "Validation Loss: 0.2934, AUROC: 0.9518\n",
      "Epoch [467/1000]\n",
      "Training Loss: 0.2700\n",
      "Validation Loss: 0.2926, AUROC: 0.9518\n",
      "Epoch [468/1000]\n",
      "Training Loss: 0.2709\n",
      "Validation Loss: 0.2924, AUROC: 0.9519\n",
      "Epoch [469/1000]\n",
      "Training Loss: 0.2694\n",
      "Validation Loss: 0.2932, AUROC: 0.9519\n",
      "Epoch [470/1000]\n",
      "Training Loss: 0.2701\n",
      "Validation Loss: 0.2932, AUROC: 0.9519\n",
      "Epoch [471/1000]\n",
      "Training Loss: 0.2691\n",
      "Validation Loss: 0.2933, AUROC: 0.9519\n",
      "Epoch [472/1000]\n",
      "Training Loss: 0.2692\n",
      "Validation Loss: 0.2926, AUROC: 0.9519\n",
      "Epoch [473/1000]\n",
      "Training Loss: 0.2700\n",
      "Validation Loss: 0.2922, AUROC: 0.9519\n",
      "Epoch [474/1000]\n",
      "Training Loss: 0.2691\n",
      "Validation Loss: 0.2932, AUROC: 0.9519\n",
      "Epoch [475/1000]\n",
      "Training Loss: 0.2693\n",
      "Validation Loss: 0.2932, AUROC: 0.9519\n",
      "Epoch [476/1000]\n",
      "Training Loss: 0.2703\n",
      "Validation Loss: 0.2924, AUROC: 0.9520\n",
      "Epoch [477/1000]\n",
      "Training Loss: 0.2700\n",
      "Validation Loss: 0.2926, AUROC: 0.9520\n",
      "Epoch [478/1000]\n",
      "Training Loss: 0.2694\n",
      "Validation Loss: 0.2939, AUROC: 0.9520\n",
      "Epoch [479/1000]\n",
      "Training Loss: 0.2682\n",
      "Validation Loss: 0.2938, AUROC: 0.9520\n",
      "Epoch [480/1000]\n",
      "Training Loss: 0.2682\n",
      "Validation Loss: 0.2932, AUROC: 0.9520\n",
      "Epoch [481/1000]\n",
      "Training Loss: 0.2696\n",
      "Validation Loss: 0.2928, AUROC: 0.9520\n",
      "Epoch [482/1000]\n",
      "Training Loss: 0.2695\n",
      "Validation Loss: 0.2932, AUROC: 0.9520\n",
      "Epoch [483/1000]\n",
      "Training Loss: 0.2686\n",
      "Validation Loss: 0.2934, AUROC: 0.9520\n",
      "Epoch [484/1000]\n",
      "Training Loss: 0.2697\n",
      "Validation Loss: 0.2930, AUROC: 0.9520\n",
      "Epoch [485/1000]\n",
      "Training Loss: 0.2690\n",
      "Validation Loss: 0.2928, AUROC: 0.9521\n",
      "Epoch [486/1000]\n",
      "Training Loss: 0.2695\n",
      "Validation Loss: 0.2917, AUROC: 0.9521\n",
      "Epoch [487/1000]\n",
      "Training Loss: 0.2683\n",
      "Validation Loss: 0.2921, AUROC: 0.9521\n",
      "Epoch [488/1000]\n",
      "Training Loss: 0.2692\n",
      "Validation Loss: 0.2943, AUROC: 0.9521\n",
      "Epoch [489/1000]\n",
      "Training Loss: 0.2677\n",
      "Validation Loss: 0.2942, AUROC: 0.9521\n",
      "Epoch [490/1000]\n",
      "Training Loss: 0.2691\n",
      "Validation Loss: 0.2935, AUROC: 0.9521\n",
      "Epoch [491/1000]\n",
      "Training Loss: 0.2695\n",
      "Validation Loss: 0.2917, AUROC: 0.9521\n",
      "Epoch [492/1000]\n",
      "Training Loss: 0.2696\n",
      "Validation Loss: 0.2922, AUROC: 0.9521\n",
      "Epoch [493/1000]\n",
      "Training Loss: 0.2709\n",
      "Validation Loss: 0.2914, AUROC: 0.9522\n",
      "Epoch [494/1000]\n",
      "Training Loss: 0.2693\n",
      "Validation Loss: 0.2913, AUROC: 0.9522\n",
      "Epoch [495/1000]\n",
      "Training Loss: 0.2684\n",
      "Validation Loss: 0.2927, AUROC: 0.9522\n",
      "Epoch [496/1000]\n",
      "Training Loss: 0.2676\n",
      "Validation Loss: 0.2939, AUROC: 0.9522\n",
      "Epoch [497/1000]\n",
      "Training Loss: 0.2678\n",
      "Validation Loss: 0.2934, AUROC: 0.9522\n",
      "Epoch [498/1000]\n",
      "Training Loss: 0.2686\n",
      "Validation Loss: 0.2919, AUROC: 0.9522\n",
      "Epoch [499/1000]\n",
      "Training Loss: 0.2678\n",
      "Validation Loss: 0.2912, AUROC: 0.9522\n",
      "Epoch [500/1000]\n",
      "Training Loss: 0.2690\n",
      "Validation Loss: 0.2929, AUROC: 0.9522\n",
      "Epoch [501/1000]\n",
      "Training Loss: 0.2667\n",
      "Validation Loss: 0.2937, AUROC: 0.9522\n",
      "Epoch [502/1000]\n",
      "Training Loss: 0.2685\n",
      "Validation Loss: 0.2926, AUROC: 0.9522\n",
      "Epoch [503/1000]\n",
      "Training Loss: 0.2686\n",
      "Validation Loss: 0.2921, AUROC: 0.9523\n",
      "Epoch [504/1000]\n",
      "Training Loss: 0.2681\n",
      "Validation Loss: 0.2921, AUROC: 0.9523\n",
      "Epoch [505/1000]\n",
      "Training Loss: 0.2684\n",
      "Validation Loss: 0.2921, AUROC: 0.9523\n",
      "Epoch [506/1000]\n",
      "Training Loss: 0.2684\n",
      "Validation Loss: 0.2927, AUROC: 0.9523\n",
      "Epoch [507/1000]\n",
      "Training Loss: 0.2679\n",
      "Validation Loss: 0.2924, AUROC: 0.9523\n",
      "Epoch [508/1000]\n",
      "Training Loss: 0.2693\n",
      "Validation Loss: 0.2919, AUROC: 0.9523\n",
      "Epoch [509/1000]\n",
      "Training Loss: 0.2664\n",
      "Validation Loss: 0.2908, AUROC: 0.9523\n",
      "Epoch [510/1000]\n",
      "Training Loss: 0.2681\n",
      "Validation Loss: 0.2911, AUROC: 0.9523\n",
      "Epoch [511/1000]\n",
      "Training Loss: 0.2670\n",
      "Validation Loss: 0.2923, AUROC: 0.9524\n",
      "Epoch [512/1000]\n",
      "Training Loss: 0.2692\n",
      "Validation Loss: 0.2918, AUROC: 0.9524\n",
      "Epoch [513/1000]\n",
      "Training Loss: 0.2687\n",
      "Validation Loss: 0.2914, AUROC: 0.9524\n",
      "Epoch [514/1000]\n",
      "Training Loss: 0.2668\n",
      "Validation Loss: 0.2911, AUROC: 0.9524\n",
      "Epoch [515/1000]\n",
      "Training Loss: 0.2679\n",
      "Validation Loss: 0.2912, AUROC: 0.9524\n",
      "Epoch [516/1000]\n",
      "Training Loss: 0.2685\n",
      "Validation Loss: 0.2923, AUROC: 0.9524\n",
      "Epoch [517/1000]\n",
      "Training Loss: 0.2682\n",
      "Validation Loss: 0.2928, AUROC: 0.9524\n",
      "Epoch [518/1000]\n",
      "Training Loss: 0.2690\n",
      "Validation Loss: 0.2916, AUROC: 0.9524\n",
      "Epoch [519/1000]\n",
      "Training Loss: 0.2688\n",
      "Validation Loss: 0.2912, AUROC: 0.9525\n",
      "Epoch [520/1000]\n",
      "Training Loss: 0.2675\n",
      "Validation Loss: 0.2920, AUROC: 0.9525\n",
      "Epoch [521/1000]\n",
      "Training Loss: 0.2680\n",
      "Validation Loss: 0.2919, AUROC: 0.9525\n",
      "Epoch [522/1000]\n",
      "Training Loss: 0.2675\n",
      "Validation Loss: 0.2912, AUROC: 0.9525\n",
      "Epoch [523/1000]\n",
      "Training Loss: 0.2673\n",
      "Validation Loss: 0.2918, AUROC: 0.9525\n",
      "Epoch [524/1000]\n",
      "Training Loss: 0.2679\n",
      "Validation Loss: 0.2922, AUROC: 0.9525\n",
      "Epoch [525/1000]\n",
      "Training Loss: 0.2684\n",
      "Validation Loss: 0.2917, AUROC: 0.9525\n",
      "Epoch [526/1000]\n",
      "Training Loss: 0.2674\n",
      "Validation Loss: 0.2912, AUROC: 0.9525\n",
      "Epoch [527/1000]\n",
      "Training Loss: 0.2680\n",
      "Validation Loss: 0.2915, AUROC: 0.9525\n",
      "Epoch [528/1000]\n",
      "Training Loss: 0.2685\n",
      "Validation Loss: 0.2901, AUROC: 0.9526\n",
      "Epoch [529/1000]\n",
      "Training Loss: 0.2683\n",
      "Validation Loss: 0.2904, AUROC: 0.9526\n",
      "Epoch [530/1000]\n",
      "Training Loss: 0.2681\n",
      "Validation Loss: 0.2919, AUROC: 0.9526\n",
      "Epoch [531/1000]\n",
      "Training Loss: 0.2680\n",
      "Validation Loss: 0.2914, AUROC: 0.9526\n",
      "Epoch [532/1000]\n",
      "Training Loss: 0.2676\n",
      "Validation Loss: 0.2913, AUROC: 0.9526\n",
      "Epoch [533/1000]\n",
      "Training Loss: 0.2659\n",
      "Validation Loss: 0.2919, AUROC: 0.9526\n",
      "Epoch [534/1000]\n",
      "Training Loss: 0.2682\n",
      "Validation Loss: 0.2915, AUROC: 0.9526\n",
      "Epoch [535/1000]\n",
      "Training Loss: 0.2671\n",
      "Validation Loss: 0.2905, AUROC: 0.9526\n",
      "Epoch [536/1000]\n",
      "Training Loss: 0.2676\n",
      "Validation Loss: 0.2905, AUROC: 0.9526\n",
      "Epoch [537/1000]\n",
      "Training Loss: 0.2676\n",
      "Validation Loss: 0.2914, AUROC: 0.9526\n",
      "Epoch [538/1000]\n",
      "Training Loss: 0.2680\n",
      "Validation Loss: 0.2916, AUROC: 0.9527\n",
      "Epoch [539/1000]\n",
      "Training Loss: 0.2673\n",
      "Validation Loss: 0.2910, AUROC: 0.9527\n",
      "Epoch [540/1000]\n",
      "Training Loss: 0.2674\n",
      "Validation Loss: 0.2904, AUROC: 0.9527\n",
      "Epoch [541/1000]\n",
      "Training Loss: 0.2663\n",
      "Validation Loss: 0.2909, AUROC: 0.9527\n",
      "Epoch [542/1000]\n",
      "Training Loss: 0.2662\n",
      "Validation Loss: 0.2907, AUROC: 0.9527\n",
      "Epoch [543/1000]\n",
      "Training Loss: 0.2670\n",
      "Validation Loss: 0.2907, AUROC: 0.9527\n",
      "Epoch [544/1000]\n",
      "Training Loss: 0.2677\n",
      "Validation Loss: 0.2902, AUROC: 0.9527\n",
      "Epoch [545/1000]\n",
      "Training Loss: 0.2676\n",
      "Validation Loss: 0.2900, AUROC: 0.9527\n",
      "Epoch [546/1000]\n",
      "Training Loss: 0.2674\n",
      "Validation Loss: 0.2907, AUROC: 0.9527\n",
      "Epoch [547/1000]\n",
      "Training Loss: 0.2665\n",
      "Validation Loss: 0.2914, AUROC: 0.9528\n",
      "Epoch [548/1000]\n",
      "Training Loss: 0.2680\n",
      "Validation Loss: 0.2909, AUROC: 0.9528\n",
      "Epoch [549/1000]\n",
      "Training Loss: 0.2670\n",
      "Validation Loss: 0.2906, AUROC: 0.9528\n",
      "Epoch [550/1000]\n",
      "Training Loss: 0.2663\n",
      "Validation Loss: 0.2907, AUROC: 0.9528\n",
      "Epoch [551/1000]\n",
      "Training Loss: 0.2659\n",
      "Validation Loss: 0.2912, AUROC: 0.9528\n",
      "Epoch [552/1000]\n",
      "Training Loss: 0.2669\n",
      "Validation Loss: 0.2903, AUROC: 0.9528\n",
      "Epoch [553/1000]\n",
      "Training Loss: 0.2663\n",
      "Validation Loss: 0.2905, AUROC: 0.9528\n",
      "Epoch [554/1000]\n",
      "Training Loss: 0.2659\n",
      "Validation Loss: 0.2907, AUROC: 0.9528\n",
      "Epoch [555/1000]\n",
      "Training Loss: 0.2666\n",
      "Validation Loss: 0.2902, AUROC: 0.9528\n",
      "Epoch [556/1000]\n",
      "Training Loss: 0.2661\n",
      "Validation Loss: 0.2906, AUROC: 0.9528\n",
      "Epoch [557/1000]\n",
      "Training Loss: 0.2675\n",
      "Validation Loss: 0.2898, AUROC: 0.9529\n",
      "Epoch [558/1000]\n",
      "Training Loss: 0.2661\n",
      "Validation Loss: 0.2899, AUROC: 0.9529\n",
      "Epoch [559/1000]\n",
      "Training Loss: 0.2658\n",
      "Validation Loss: 0.2907, AUROC: 0.9529\n",
      "Epoch [560/1000]\n",
      "Training Loss: 0.2660\n",
      "Validation Loss: 0.2909, AUROC: 0.9529\n",
      "Epoch [561/1000]\n",
      "Training Loss: 0.2669\n",
      "Validation Loss: 0.2906, AUROC: 0.9529\n",
      "Epoch [562/1000]\n",
      "Training Loss: 0.2653\n",
      "Validation Loss: 0.2896, AUROC: 0.9529\n",
      "Epoch [563/1000]\n",
      "Training Loss: 0.2662\n",
      "Validation Loss: 0.2902, AUROC: 0.9529\n",
      "Epoch [564/1000]\n",
      "Training Loss: 0.2667\n",
      "Validation Loss: 0.2900, AUROC: 0.9529\n",
      "Epoch [565/1000]\n",
      "Training Loss: 0.2675\n",
      "Validation Loss: 0.2900, AUROC: 0.9529\n",
      "Epoch [566/1000]\n",
      "Training Loss: 0.2672\n",
      "Validation Loss: 0.2902, AUROC: 0.9530\n",
      "Epoch [567/1000]\n",
      "Training Loss: 0.2653\n",
      "Validation Loss: 0.2914, AUROC: 0.9530\n",
      "Epoch [568/1000]\n",
      "Training Loss: 0.2655\n",
      "Validation Loss: 0.2900, AUROC: 0.9530\n",
      "Epoch [569/1000]\n",
      "Training Loss: 0.2667\n",
      "Validation Loss: 0.2900, AUROC: 0.9530\n",
      "Epoch [570/1000]\n",
      "Training Loss: 0.2662\n",
      "Validation Loss: 0.2893, AUROC: 0.9530\n",
      "Epoch [571/1000]\n",
      "Training Loss: 0.2653\n",
      "Validation Loss: 0.2898, AUROC: 0.9530\n",
      "Epoch [572/1000]\n",
      "Training Loss: 0.2664\n",
      "Validation Loss: 0.2905, AUROC: 0.9530\n",
      "Epoch [573/1000]\n",
      "Training Loss: 0.2654\n",
      "Validation Loss: 0.2897, AUROC: 0.9530\n",
      "Epoch [574/1000]\n",
      "Training Loss: 0.2652\n",
      "Validation Loss: 0.2908, AUROC: 0.9530\n",
      "Epoch [575/1000]\n",
      "Training Loss: 0.2669\n",
      "Validation Loss: 0.2904, AUROC: 0.9531\n",
      "Epoch [576/1000]\n",
      "Training Loss: 0.2658\n",
      "Validation Loss: 0.2897, AUROC: 0.9531\n",
      "Epoch [577/1000]\n",
      "Training Loss: 0.2663\n",
      "Validation Loss: 0.2897, AUROC: 0.9531\n",
      "Epoch [578/1000]\n",
      "Training Loss: 0.2654\n",
      "Validation Loss: 0.2895, AUROC: 0.9531\n",
      "Epoch [579/1000]\n",
      "Training Loss: 0.2654\n",
      "Validation Loss: 0.2900, AUROC: 0.9531\n",
      "Epoch [580/1000]\n",
      "Training Loss: 0.2656\n",
      "Validation Loss: 0.2894, AUROC: 0.9531\n",
      "Epoch [581/1000]\n",
      "Training Loss: 0.2665\n",
      "Validation Loss: 0.2896, AUROC: 0.9531\n",
      "Epoch [582/1000]\n",
      "Training Loss: 0.2672\n",
      "Validation Loss: 0.2890, AUROC: 0.9531\n",
      "Epoch [583/1000]\n",
      "Training Loss: 0.2657\n",
      "Validation Loss: 0.2892, AUROC: 0.9531\n",
      "Epoch [584/1000]\n",
      "Training Loss: 0.2651\n",
      "Validation Loss: 0.2891, AUROC: 0.9532\n",
      "Epoch [585/1000]\n",
      "Training Loss: 0.2662\n",
      "Validation Loss: 0.2900, AUROC: 0.9532\n",
      "Epoch [586/1000]\n",
      "Training Loss: 0.2663\n",
      "Validation Loss: 0.2899, AUROC: 0.9532\n",
      "Epoch [587/1000]\n",
      "Training Loss: 0.2664\n",
      "Validation Loss: 0.2895, AUROC: 0.9532\n",
      "Epoch [588/1000]\n",
      "Training Loss: 0.2651\n",
      "Validation Loss: 0.2889, AUROC: 0.9532\n",
      "Epoch [589/1000]\n",
      "Training Loss: 0.2649\n",
      "Validation Loss: 0.2896, AUROC: 0.9532\n",
      "Epoch [590/1000]\n",
      "Training Loss: 0.2645\n",
      "Validation Loss: 0.2895, AUROC: 0.9532\n",
      "Epoch [591/1000]\n",
      "Training Loss: 0.2658\n",
      "Validation Loss: 0.2897, AUROC: 0.9532\n",
      "Epoch [592/1000]\n",
      "Training Loss: 0.2659\n",
      "Validation Loss: 0.2899, AUROC: 0.9532\n",
      "Epoch [593/1000]\n",
      "Training Loss: 0.2661\n",
      "Validation Loss: 0.2888, AUROC: 0.9532\n",
      "Epoch [594/1000]\n",
      "Training Loss: 0.2658\n",
      "Validation Loss: 0.2888, AUROC: 0.9533\n",
      "Epoch [595/1000]\n",
      "Training Loss: 0.2658\n",
      "Validation Loss: 0.2891, AUROC: 0.9533\n",
      "Epoch [596/1000]\n",
      "Training Loss: 0.2647\n",
      "Validation Loss: 0.2889, AUROC: 0.9533\n",
      "Epoch [597/1000]\n",
      "Training Loss: 0.2660\n",
      "Validation Loss: 0.2894, AUROC: 0.9533\n",
      "Epoch [598/1000]\n",
      "Training Loss: 0.2657\n",
      "Validation Loss: 0.2895, AUROC: 0.9533\n",
      "Epoch [599/1000]\n",
      "Training Loss: 0.2657\n",
      "Validation Loss: 0.2890, AUROC: 0.9533\n",
      "Epoch [600/1000]\n",
      "Training Loss: 0.2661\n",
      "Validation Loss: 0.2889, AUROC: 0.9533\n",
      "Epoch [601/1000]\n",
      "Training Loss: 0.2647\n",
      "Validation Loss: 0.2889, AUROC: 0.9533\n",
      "Epoch [602/1000]\n",
      "Training Loss: 0.2651\n",
      "Validation Loss: 0.2886, AUROC: 0.9533\n",
      "Epoch [603/1000]\n",
      "Training Loss: 0.2654\n",
      "Validation Loss: 0.2890, AUROC: 0.9533\n",
      "Epoch [604/1000]\n",
      "Training Loss: 0.2651\n",
      "Validation Loss: 0.2892, AUROC: 0.9534\n",
      "Epoch [605/1000]\n",
      "Training Loss: 0.2647\n",
      "Validation Loss: 0.2896, AUROC: 0.9534\n",
      "Epoch [606/1000]\n",
      "Training Loss: 0.2654\n",
      "Validation Loss: 0.2893, AUROC: 0.9534\n",
      "Epoch [607/1000]\n",
      "Training Loss: 0.2653\n",
      "Validation Loss: 0.2893, AUROC: 0.9534\n",
      "Epoch [608/1000]\n",
      "Training Loss: 0.2652\n",
      "Validation Loss: 0.2891, AUROC: 0.9534\n",
      "Epoch [609/1000]\n",
      "Training Loss: 0.2656\n",
      "Validation Loss: 0.2895, AUROC: 0.9534\n",
      "Epoch [610/1000]\n",
      "Training Loss: 0.2642\n",
      "Validation Loss: 0.2891, AUROC: 0.9534\n",
      "Epoch [611/1000]\n",
      "Training Loss: 0.2648\n",
      "Validation Loss: 0.2878, AUROC: 0.9534\n",
      "Epoch [612/1000]\n",
      "Training Loss: 0.2656\n",
      "Validation Loss: 0.2880, AUROC: 0.9534\n",
      "Epoch [613/1000]\n",
      "Training Loss: 0.2645\n",
      "Validation Loss: 0.2894, AUROC: 0.9534\n",
      "Epoch [614/1000]\n",
      "Training Loss: 0.2667\n",
      "Validation Loss: 0.2892, AUROC: 0.9535\n",
      "Epoch [615/1000]\n",
      "Training Loss: 0.2655\n",
      "Validation Loss: 0.2875, AUROC: 0.9535\n",
      "Epoch [616/1000]\n",
      "Training Loss: 0.2650\n",
      "Validation Loss: 0.2883, AUROC: 0.9535\n",
      "Epoch [617/1000]\n",
      "Training Loss: 0.2654\n",
      "Validation Loss: 0.2890, AUROC: 0.9535\n",
      "Epoch [618/1000]\n",
      "Training Loss: 0.2646\n",
      "Validation Loss: 0.2874, AUROC: 0.9535\n",
      "Epoch [619/1000]\n",
      "Training Loss: 0.2646\n",
      "Validation Loss: 0.2882, AUROC: 0.9535\n",
      "Epoch [620/1000]\n",
      "Training Loss: 0.2647\n",
      "Validation Loss: 0.2888, AUROC: 0.9535\n",
      "Epoch [621/1000]\n",
      "Training Loss: 0.2644\n",
      "Validation Loss: 0.2885, AUROC: 0.9535\n",
      "Epoch [622/1000]\n",
      "Training Loss: 0.2638\n",
      "Validation Loss: 0.2894, AUROC: 0.9535\n",
      "Epoch [623/1000]\n",
      "Training Loss: 0.2642\n",
      "Validation Loss: 0.2887, AUROC: 0.9535\n",
      "Epoch [624/1000]\n",
      "Training Loss: 0.2642\n",
      "Validation Loss: 0.2881, AUROC: 0.9536\n",
      "Epoch [625/1000]\n",
      "Training Loss: 0.2647\n",
      "Validation Loss: 0.2881, AUROC: 0.9536\n",
      "Epoch [626/1000]\n",
      "Training Loss: 0.2662\n",
      "Validation Loss: 0.2879, AUROC: 0.9536\n",
      "Epoch [627/1000]\n",
      "Training Loss: 0.2649\n",
      "Validation Loss: 0.2866, AUROC: 0.9536\n",
      "Epoch [628/1000]\n",
      "Training Loss: 0.2656\n",
      "Validation Loss: 0.2878, AUROC: 0.9536\n",
      "Epoch [629/1000]\n",
      "Training Loss: 0.2646\n",
      "Validation Loss: 0.2891, AUROC: 0.9536\n",
      "Epoch [630/1000]\n",
      "Training Loss: 0.2652\n",
      "Validation Loss: 0.2878, AUROC: 0.9536\n",
      "Epoch [631/1000]\n",
      "Training Loss: 0.2651\n",
      "Validation Loss: 0.2878, AUROC: 0.9536\n",
      "Epoch [632/1000]\n",
      "Training Loss: 0.2646\n",
      "Validation Loss: 0.2882, AUROC: 0.9537\n",
      "Epoch [633/1000]\n",
      "Training Loss: 0.2650\n",
      "Validation Loss: 0.2875, AUROC: 0.9537\n",
      "Epoch [634/1000]\n",
      "Training Loss: 0.2633\n",
      "Validation Loss: 0.2887, AUROC: 0.9537\n",
      "Epoch [635/1000]\n",
      "Training Loss: 0.2633\n",
      "Validation Loss: 0.2886, AUROC: 0.9537\n",
      "Epoch [636/1000]\n",
      "Training Loss: 0.2638\n",
      "Validation Loss: 0.2872, AUROC: 0.9537\n",
      "Epoch [637/1000]\n",
      "Training Loss: 0.2646\n",
      "Validation Loss: 0.2874, AUROC: 0.9537\n",
      "Epoch [638/1000]\n",
      "Training Loss: 0.2657\n",
      "Validation Loss: 0.2885, AUROC: 0.9537\n",
      "Epoch [639/1000]\n",
      "Training Loss: 0.2635\n",
      "Validation Loss: 0.2882, AUROC: 0.9537\n",
      "Epoch [640/1000]\n",
      "Training Loss: 0.2644\n",
      "Validation Loss: 0.2875, AUROC: 0.9537\n",
      "Epoch [641/1000]\n",
      "Training Loss: 0.2636\n",
      "Validation Loss: 0.2868, AUROC: 0.9537\n",
      "Epoch [642/1000]\n",
      "Training Loss: 0.2652\n",
      "Validation Loss: 0.2877, AUROC: 0.9537\n",
      "Epoch [643/1000]\n",
      "Training Loss: 0.2649\n",
      "Validation Loss: 0.2865, AUROC: 0.9538\n",
      "Epoch [644/1000]\n",
      "Training Loss: 0.2646\n",
      "Validation Loss: 0.2866, AUROC: 0.9538\n",
      "Epoch [645/1000]\n",
      "Training Loss: 0.2642\n",
      "Validation Loss: 0.2882, AUROC: 0.9538\n",
      "Epoch [646/1000]\n",
      "Training Loss: 0.2639\n",
      "Validation Loss: 0.2880, AUROC: 0.9538\n",
      "Epoch [647/1000]\n",
      "Training Loss: 0.2637\n",
      "Validation Loss: 0.2872, AUROC: 0.9538\n",
      "Epoch [648/1000]\n",
      "Training Loss: 0.2632\n",
      "Validation Loss: 0.2879, AUROC: 0.9538\n",
      "Epoch [649/1000]\n",
      "Training Loss: 0.2654\n",
      "Validation Loss: 0.2879, AUROC: 0.9538\n",
      "Epoch [650/1000]\n",
      "Training Loss: 0.2630\n",
      "Validation Loss: 0.2880, AUROC: 0.9538\n",
      "Epoch [651/1000]\n",
      "Training Loss: 0.2646\n",
      "Validation Loss: 0.2880, AUROC: 0.9538\n",
      "Epoch [652/1000]\n",
      "Training Loss: 0.2639\n",
      "Validation Loss: 0.2876, AUROC: 0.9538\n",
      "Epoch [653/1000]\n",
      "Training Loss: 0.2640\n",
      "Validation Loss: 0.2879, AUROC: 0.9538\n",
      "Epoch [654/1000]\n",
      "Training Loss: 0.2625\n",
      "Validation Loss: 0.2890, AUROC: 0.9539\n",
      "Epoch [655/1000]\n",
      "Training Loss: 0.2643\n",
      "Validation Loss: 0.2880, AUROC: 0.9539\n",
      "Epoch [656/1000]\n",
      "Training Loss: 0.2633\n",
      "Validation Loss: 0.2864, AUROC: 0.9539\n",
      "Epoch [657/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2880, AUROC: 0.9539\n",
      "Epoch [658/1000]\n",
      "Training Loss: 0.2628\n",
      "Validation Loss: 0.2895, AUROC: 0.9539\n",
      "Epoch [659/1000]\n",
      "Training Loss: 0.2623\n",
      "Validation Loss: 0.2875, AUROC: 0.9539\n",
      "Epoch [660/1000]\n",
      "Training Loss: 0.2635\n",
      "Validation Loss: 0.2869, AUROC: 0.9539\n",
      "Epoch [661/1000]\n",
      "Training Loss: 0.2634\n",
      "Validation Loss: 0.2872, AUROC: 0.9539\n",
      "Epoch [662/1000]\n",
      "Training Loss: 0.2619\n",
      "Validation Loss: 0.2879, AUROC: 0.9539\n",
      "Epoch [663/1000]\n",
      "Training Loss: 0.2634\n",
      "Validation Loss: 0.2877, AUROC: 0.9539\n",
      "Epoch [664/1000]\n",
      "Training Loss: 0.2643\n",
      "Validation Loss: 0.2863, AUROC: 0.9540\n",
      "Epoch [665/1000]\n",
      "Training Loss: 0.2635\n",
      "Validation Loss: 0.2864, AUROC: 0.9540\n",
      "Epoch [666/1000]\n",
      "Training Loss: 0.2630\n",
      "Validation Loss: 0.2872, AUROC: 0.9540\n",
      "Epoch [667/1000]\n",
      "Training Loss: 0.2633\n",
      "Validation Loss: 0.2878, AUROC: 0.9540\n",
      "Epoch [668/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2882, AUROC: 0.9540\n",
      "Epoch [669/1000]\n",
      "Training Loss: 0.2648\n",
      "Validation Loss: 0.2866, AUROC: 0.9540\n",
      "Epoch [670/1000]\n",
      "Training Loss: 0.2644\n",
      "Validation Loss: 0.2862, AUROC: 0.9540\n",
      "Epoch [671/1000]\n",
      "Training Loss: 0.2632\n",
      "Validation Loss: 0.2865, AUROC: 0.9540\n",
      "Epoch [672/1000]\n",
      "Training Loss: 0.2626\n",
      "Validation Loss: 0.2874, AUROC: 0.9540\n",
      "Epoch [673/1000]\n",
      "Training Loss: 0.2638\n",
      "Validation Loss: 0.2865, AUROC: 0.9540\n",
      "Epoch [674/1000]\n",
      "Training Loss: 0.2637\n",
      "Validation Loss: 0.2868, AUROC: 0.9540\n",
      "Epoch [675/1000]\n",
      "Training Loss: 0.2620\n",
      "Validation Loss: 0.2869, AUROC: 0.9540\n",
      "Epoch [676/1000]\n",
      "Training Loss: 0.2642\n",
      "Validation Loss: 0.2855, AUROC: 0.9541\n",
      "Epoch [677/1000]\n",
      "Training Loss: 0.2628\n",
      "Validation Loss: 0.2866, AUROC: 0.9541\n",
      "Epoch [678/1000]\n",
      "Training Loss: 0.2635\n",
      "Validation Loss: 0.2880, AUROC: 0.9541\n",
      "Epoch [679/1000]\n",
      "Training Loss: 0.2631\n",
      "Validation Loss: 0.2861, AUROC: 0.9541\n",
      "Epoch [680/1000]\n",
      "Training Loss: 0.2640\n",
      "Validation Loss: 0.2861, AUROC: 0.9541\n",
      "Epoch [681/1000]\n",
      "Training Loss: 0.2629\n",
      "Validation Loss: 0.2868, AUROC: 0.9541\n",
      "Epoch [682/1000]\n",
      "Training Loss: 0.2638\n",
      "Validation Loss: 0.2869, AUROC: 0.9541\n",
      "Epoch [683/1000]\n",
      "Training Loss: 0.2623\n",
      "Validation Loss: 0.2865, AUROC: 0.9541\n",
      "Epoch [684/1000]\n",
      "Training Loss: 0.2625\n",
      "Validation Loss: 0.2867, AUROC: 0.9541\n",
      "Epoch [685/1000]\n",
      "Training Loss: 0.2622\n",
      "Validation Loss: 0.2859, AUROC: 0.9541\n",
      "Epoch [686/1000]\n",
      "Training Loss: 0.2622\n",
      "Validation Loss: 0.2862, AUROC: 0.9541\n",
      "Epoch [687/1000]\n",
      "Training Loss: 0.2631\n",
      "Validation Loss: 0.2860, AUROC: 0.9542\n",
      "Epoch [688/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2870, AUROC: 0.9542\n",
      "Epoch [689/1000]\n",
      "Training Loss: 0.2632\n",
      "Validation Loss: 0.2868, AUROC: 0.9542\n",
      "Epoch [690/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2856, AUROC: 0.9542\n",
      "Epoch [691/1000]\n",
      "Training Loss: 0.2629\n",
      "Validation Loss: 0.2871, AUROC: 0.9542\n",
      "Epoch [692/1000]\n",
      "Training Loss: 0.2631\n",
      "Validation Loss: 0.2871, AUROC: 0.9542\n",
      "Epoch [693/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2862, AUROC: 0.9542\n",
      "Epoch [694/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2869, AUROC: 0.9542\n",
      "Epoch [695/1000]\n",
      "Training Loss: 0.2631\n",
      "Validation Loss: 0.2866, AUROC: 0.9542\n",
      "Epoch [696/1000]\n",
      "Training Loss: 0.2609\n",
      "Validation Loss: 0.2871, AUROC: 0.9542\n",
      "Epoch [697/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2860, AUROC: 0.9542\n",
      "Epoch [698/1000]\n",
      "Training Loss: 0.2636\n",
      "Validation Loss: 0.2852, AUROC: 0.9543\n",
      "Epoch [699/1000]\n",
      "Training Loss: 0.2638\n",
      "Validation Loss: 0.2856, AUROC: 0.9543\n",
      "Epoch [700/1000]\n",
      "Training Loss: 0.2635\n",
      "Validation Loss: 0.2876, AUROC: 0.9543\n",
      "Epoch [701/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2872, AUROC: 0.9543\n",
      "Epoch [702/1000]\n",
      "Training Loss: 0.2618\n",
      "Validation Loss: 0.2856, AUROC: 0.9543\n",
      "Epoch [703/1000]\n",
      "Training Loss: 0.2628\n",
      "Validation Loss: 0.2863, AUROC: 0.9543\n",
      "Epoch [704/1000]\n",
      "Training Loss: 0.2625\n",
      "Validation Loss: 0.2872, AUROC: 0.9543\n",
      "Epoch [705/1000]\n",
      "Training Loss: 0.2638\n",
      "Validation Loss: 0.2852, AUROC: 0.9543\n",
      "Epoch [706/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2850, AUROC: 0.9543\n",
      "Epoch [707/1000]\n",
      "Training Loss: 0.2621\n",
      "Validation Loss: 0.2866, AUROC: 0.9543\n",
      "Epoch [708/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2870, AUROC: 0.9544\n",
      "Epoch [709/1000]\n",
      "Training Loss: 0.2626\n",
      "Validation Loss: 0.2853, AUROC: 0.9544\n",
      "Epoch [710/1000]\n",
      "Training Loss: 0.2612\n",
      "Validation Loss: 0.2856, AUROC: 0.9544\n",
      "Epoch [711/1000]\n",
      "Training Loss: 0.2619\n",
      "Validation Loss: 0.2871, AUROC: 0.9544\n",
      "Epoch [712/1000]\n",
      "Training Loss: 0.2631\n",
      "Validation Loss: 0.2860, AUROC: 0.9544\n",
      "Epoch [713/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2859, AUROC: 0.9544\n",
      "Epoch [714/1000]\n",
      "Training Loss: 0.2621\n",
      "Validation Loss: 0.2851, AUROC: 0.9544\n",
      "Epoch [715/1000]\n",
      "Training Loss: 0.2624\n",
      "Validation Loss: 0.2855, AUROC: 0.9544\n",
      "Epoch [716/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2864, AUROC: 0.9544\n",
      "Epoch [717/1000]\n",
      "Training Loss: 0.2619\n",
      "Validation Loss: 0.2867, AUROC: 0.9544\n",
      "Epoch [718/1000]\n",
      "Training Loss: 0.2623\n",
      "Validation Loss: 0.2856, AUROC: 0.9544\n",
      "Epoch [719/1000]\n",
      "Training Loss: 0.2630\n",
      "Validation Loss: 0.2847, AUROC: 0.9545\n",
      "Epoch [720/1000]\n",
      "Training Loss: 0.2621\n",
      "Validation Loss: 0.2852, AUROC: 0.9545\n",
      "Epoch [721/1000]\n",
      "Training Loss: 0.2625\n",
      "Validation Loss: 0.2856, AUROC: 0.9545\n",
      "Epoch [722/1000]\n",
      "Training Loss: 0.2615\n",
      "Validation Loss: 0.2848, AUROC: 0.9545\n",
      "Epoch [723/1000]\n",
      "Training Loss: 0.2632\n",
      "Validation Loss: 0.2862, AUROC: 0.9545\n",
      "Epoch [724/1000]\n",
      "Training Loss: 0.2622\n",
      "Validation Loss: 0.2846, AUROC: 0.9545\n",
      "Epoch [725/1000]\n",
      "Training Loss: 0.2631\n",
      "Validation Loss: 0.2838, AUROC: 0.9545\n",
      "Epoch [726/1000]\n",
      "Training Loss: 0.2620\n",
      "Validation Loss: 0.2850, AUROC: 0.9545\n",
      "Epoch [727/1000]\n",
      "Training Loss: 0.2616\n",
      "Validation Loss: 0.2862, AUROC: 0.9545\n",
      "Epoch [728/1000]\n",
      "Training Loss: 0.2616\n",
      "Validation Loss: 0.2850, AUROC: 0.9545\n",
      "Epoch [729/1000]\n",
      "Training Loss: 0.2602\n",
      "Validation Loss: 0.2849, AUROC: 0.9545\n",
      "Epoch [730/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2854, AUROC: 0.9545\n",
      "Epoch [731/1000]\n",
      "Training Loss: 0.2624\n",
      "Validation Loss: 0.2850, AUROC: 0.9546\n",
      "Epoch [732/1000]\n",
      "Training Loss: 0.2613\n",
      "Validation Loss: 0.2859, AUROC: 0.9546\n",
      "Epoch [733/1000]\n",
      "Training Loss: 0.2629\n",
      "Validation Loss: 0.2851, AUROC: 0.9546\n",
      "Epoch [734/1000]\n",
      "Training Loss: 0.2626\n",
      "Validation Loss: 0.2847, AUROC: 0.9546\n",
      "Epoch [735/1000]\n",
      "Training Loss: 0.2623\n",
      "Validation Loss: 0.2848, AUROC: 0.9546\n",
      "Epoch [736/1000]\n",
      "Training Loss: 0.2616\n",
      "Validation Loss: 0.2853, AUROC: 0.9546\n",
      "Epoch [737/1000]\n",
      "Training Loss: 0.2610\n",
      "Validation Loss: 0.2860, AUROC: 0.9546\n",
      "Epoch [738/1000]\n",
      "Training Loss: 0.2614\n",
      "Validation Loss: 0.2845, AUROC: 0.9546\n",
      "Epoch [739/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2852, AUROC: 0.9546\n",
      "Epoch [740/1000]\n",
      "Training Loss: 0.2618\n",
      "Validation Loss: 0.2856, AUROC: 0.9546\n",
      "Epoch [741/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2859, AUROC: 0.9546\n",
      "Epoch [742/1000]\n",
      "Training Loss: 0.2612\n",
      "Validation Loss: 0.2849, AUROC: 0.9546\n",
      "Epoch [743/1000]\n",
      "Training Loss: 0.2613\n",
      "Validation Loss: 0.2844, AUROC: 0.9546\n",
      "Epoch [744/1000]\n",
      "Training Loss: 0.2619\n",
      "Validation Loss: 0.2841, AUROC: 0.9547\n",
      "Epoch [745/1000]\n",
      "Training Loss: 0.2624\n",
      "Validation Loss: 0.2849, AUROC: 0.9547\n",
      "Epoch [746/1000]\n",
      "Training Loss: 0.2630\n",
      "Validation Loss: 0.2857, AUROC: 0.9547\n",
      "Epoch [747/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2848, AUROC: 0.9547\n",
      "Epoch [748/1000]\n",
      "Training Loss: 0.2627\n",
      "Validation Loss: 0.2852, AUROC: 0.9547\n",
      "Epoch [749/1000]\n",
      "Training Loss: 0.2620\n",
      "Validation Loss: 0.2857, AUROC: 0.9547\n",
      "Epoch [750/1000]\n",
      "Training Loss: 0.2625\n",
      "Validation Loss: 0.2842, AUROC: 0.9547\n",
      "Epoch [751/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2839, AUROC: 0.9547\n",
      "Epoch [752/1000]\n",
      "Training Loss: 0.2613\n",
      "Validation Loss: 0.2852, AUROC: 0.9547\n",
      "Epoch [753/1000]\n",
      "Training Loss: 0.2606\n",
      "Validation Loss: 0.2850, AUROC: 0.9547\n",
      "Epoch [754/1000]\n",
      "Training Loss: 0.2622\n",
      "Validation Loss: 0.2849, AUROC: 0.9547\n",
      "Epoch [755/1000]\n",
      "Training Loss: 0.2626\n",
      "Validation Loss: 0.2848, AUROC: 0.9548\n",
      "Epoch [756/1000]\n",
      "Training Loss: 0.2620\n",
      "Validation Loss: 0.2836, AUROC: 0.9548\n",
      "Epoch [757/1000]\n",
      "Training Loss: 0.2624\n",
      "Validation Loss: 0.2840, AUROC: 0.9548\n",
      "Epoch [758/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2855, AUROC: 0.9548\n",
      "Epoch [759/1000]\n",
      "Training Loss: 0.2620\n",
      "Validation Loss: 0.2844, AUROC: 0.9548\n",
      "Epoch [760/1000]\n",
      "Training Loss: 0.2616\n",
      "Validation Loss: 0.2836, AUROC: 0.9548\n",
      "Epoch [761/1000]\n",
      "Training Loss: 0.2603\n",
      "Validation Loss: 0.2856, AUROC: 0.9548\n",
      "Epoch [762/1000]\n",
      "Training Loss: 0.2611\n",
      "Validation Loss: 0.2846, AUROC: 0.9548\n",
      "Epoch [763/1000]\n",
      "Training Loss: 0.2619\n",
      "Validation Loss: 0.2844, AUROC: 0.9548\n",
      "Epoch [764/1000]\n",
      "Training Loss: 0.2608\n",
      "Validation Loss: 0.2845, AUROC: 0.9548\n",
      "Epoch [765/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2849, AUROC: 0.9548\n",
      "Epoch [766/1000]\n",
      "Training Loss: 0.2618\n",
      "Validation Loss: 0.2842, AUROC: 0.9548\n",
      "Epoch [767/1000]\n",
      "Training Loss: 0.2604\n",
      "Validation Loss: 0.2838, AUROC: 0.9549\n",
      "Epoch [768/1000]\n",
      "Training Loss: 0.2605\n",
      "Validation Loss: 0.2851, AUROC: 0.9549\n",
      "Epoch [769/1000]\n",
      "Training Loss: 0.2600\n",
      "Validation Loss: 0.2849, AUROC: 0.9549\n",
      "Epoch [770/1000]\n",
      "Training Loss: 0.2612\n",
      "Validation Loss: 0.2840, AUROC: 0.9549\n",
      "Epoch [771/1000]\n",
      "Training Loss: 0.2605\n",
      "Validation Loss: 0.2832, AUROC: 0.9549\n",
      "Epoch [772/1000]\n",
      "Training Loss: 0.2616\n",
      "Validation Loss: 0.2842, AUROC: 0.9549\n",
      "Epoch [773/1000]\n",
      "Training Loss: 0.2612\n",
      "Validation Loss: 0.2835, AUROC: 0.9549\n",
      "Epoch [774/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2838, AUROC: 0.9549\n",
      "Epoch [775/1000]\n",
      "Training Loss: 0.2609\n",
      "Validation Loss: 0.2842, AUROC: 0.9549\n",
      "Epoch [776/1000]\n",
      "Training Loss: 0.2615\n",
      "Validation Loss: 0.2838, AUROC: 0.9549\n",
      "Epoch [777/1000]\n",
      "Training Loss: 0.2598\n",
      "Validation Loss: 0.2849, AUROC: 0.9549\n",
      "Epoch [778/1000]\n",
      "Training Loss: 0.2617\n",
      "Validation Loss: 0.2844, AUROC: 0.9549\n",
      "Epoch [779/1000]\n",
      "Training Loss: 0.2606\n",
      "Validation Loss: 0.2839, AUROC: 0.9549\n",
      "Epoch [780/1000]\n",
      "Training Loss: 0.2597\n",
      "Validation Loss: 0.2851, AUROC: 0.9549\n",
      "Epoch [781/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2846, AUROC: 0.9550\n",
      "Epoch [782/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2833, AUROC: 0.9550\n",
      "Epoch [783/1000]\n",
      "Training Loss: 0.2603\n",
      "Validation Loss: 0.2845, AUROC: 0.9550\n",
      "Epoch [784/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2841, AUROC: 0.9550\n",
      "Epoch [785/1000]\n",
      "Training Loss: 0.2597\n",
      "Validation Loss: 0.2839, AUROC: 0.9550\n",
      "Epoch [786/1000]\n",
      "Training Loss: 0.2598\n",
      "Validation Loss: 0.2841, AUROC: 0.9550\n",
      "Epoch [787/1000]\n",
      "Training Loss: 0.2592\n",
      "Validation Loss: 0.2843, AUROC: 0.9550\n",
      "Epoch [788/1000]\n",
      "Training Loss: 0.2609\n",
      "Validation Loss: 0.2834, AUROC: 0.9550\n",
      "Epoch [789/1000]\n",
      "Training Loss: 0.2604\n",
      "Validation Loss: 0.2843, AUROC: 0.9550\n",
      "Epoch [790/1000]\n",
      "Training Loss: 0.2612\n",
      "Validation Loss: 0.2832, AUROC: 0.9550\n",
      "Epoch [791/1000]\n",
      "Training Loss: 0.2615\n",
      "Validation Loss: 0.2837, AUROC: 0.9550\n",
      "Epoch [792/1000]\n",
      "Training Loss: 0.2599\n",
      "Validation Loss: 0.2839, AUROC: 0.9550\n",
      "Epoch [793/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2844, AUROC: 0.9550\n",
      "Epoch [794/1000]\n",
      "Training Loss: 0.2608\n",
      "Validation Loss: 0.2836, AUROC: 0.9551\n",
      "Epoch [795/1000]\n",
      "Training Loss: 0.2597\n",
      "Validation Loss: 0.2834, AUROC: 0.9551\n",
      "Epoch [796/1000]\n",
      "Training Loss: 0.2606\n",
      "Validation Loss: 0.2836, AUROC: 0.9551\n",
      "Epoch [797/1000]\n",
      "Training Loss: 0.2602\n",
      "Validation Loss: 0.2834, AUROC: 0.9551\n",
      "Epoch [798/1000]\n",
      "Training Loss: 0.2602\n",
      "Validation Loss: 0.2836, AUROC: 0.9551\n",
      "Epoch [799/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2834, AUROC: 0.9551\n",
      "Epoch [800/1000]\n",
      "Training Loss: 0.2604\n",
      "Validation Loss: 0.2839, AUROC: 0.9551\n",
      "Epoch [801/1000]\n",
      "Training Loss: 0.2613\n",
      "Validation Loss: 0.2837, AUROC: 0.9551\n",
      "Epoch [802/1000]\n",
      "Training Loss: 0.2604\n",
      "Validation Loss: 0.2838, AUROC: 0.9551\n",
      "Epoch [803/1000]\n",
      "Training Loss: 0.2603\n",
      "Validation Loss: 0.2823, AUROC: 0.9551\n",
      "Epoch [804/1000]\n",
      "Training Loss: 0.2599\n",
      "Validation Loss: 0.2829, AUROC: 0.9551\n",
      "Epoch [805/1000]\n",
      "Training Loss: 0.2599\n",
      "Validation Loss: 0.2835, AUROC: 0.9551\n",
      "Epoch [806/1000]\n",
      "Training Loss: 0.2604\n",
      "Validation Loss: 0.2834, AUROC: 0.9552\n",
      "Epoch [807/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2832, AUROC: 0.9552\n",
      "Epoch [808/1000]\n",
      "Training Loss: 0.2606\n",
      "Validation Loss: 0.2835, AUROC: 0.9552\n",
      "Epoch [809/1000]\n",
      "Training Loss: 0.2598\n",
      "Validation Loss: 0.2836, AUROC: 0.9552\n",
      "Epoch [810/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2833, AUROC: 0.9552\n",
      "Epoch [811/1000]\n",
      "Training Loss: 0.2595\n",
      "Validation Loss: 0.2833, AUROC: 0.9552\n",
      "Epoch [812/1000]\n",
      "Training Loss: 0.2609\n",
      "Validation Loss: 0.2833, AUROC: 0.9552\n",
      "Epoch [813/1000]\n",
      "Training Loss: 0.2600\n",
      "Validation Loss: 0.2830, AUROC: 0.9552\n",
      "Epoch [814/1000]\n",
      "Training Loss: 0.2588\n",
      "Validation Loss: 0.2836, AUROC: 0.9552\n",
      "Epoch [815/1000]\n",
      "Training Loss: 0.2593\n",
      "Validation Loss: 0.2838, AUROC: 0.9552\n",
      "Epoch [816/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2834, AUROC: 0.9552\n",
      "Epoch [817/1000]\n",
      "Training Loss: 0.2603\n",
      "Validation Loss: 0.2828, AUROC: 0.9552\n",
      "Epoch [818/1000]\n",
      "Training Loss: 0.2604\n",
      "Validation Loss: 0.2830, AUROC: 0.9552\n",
      "Epoch [819/1000]\n",
      "Training Loss: 0.2599\n",
      "Validation Loss: 0.2835, AUROC: 0.9552\n",
      "Epoch [820/1000]\n",
      "Training Loss: 0.2593\n",
      "Validation Loss: 0.2837, AUROC: 0.9553\n",
      "Epoch [821/1000]\n",
      "Training Loss: 0.2591\n",
      "Validation Loss: 0.2827, AUROC: 0.9553\n",
      "Epoch [822/1000]\n",
      "Training Loss: 0.2615\n",
      "Validation Loss: 0.2821, AUROC: 0.9553\n",
      "Epoch [823/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2817, AUROC: 0.9553\n",
      "Epoch [824/1000]\n",
      "Training Loss: 0.2609\n",
      "Validation Loss: 0.2826, AUROC: 0.9553\n",
      "Epoch [825/1000]\n",
      "Training Loss: 0.2600\n",
      "Validation Loss: 0.2824, AUROC: 0.9553\n",
      "Epoch [826/1000]\n",
      "Training Loss: 0.2597\n",
      "Validation Loss: 0.2835, AUROC: 0.9553\n",
      "Epoch [827/1000]\n",
      "Training Loss: 0.2601\n",
      "Validation Loss: 0.2835, AUROC: 0.9553\n",
      "Epoch [828/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2826, AUROC: 0.9553\n",
      "Epoch [829/1000]\n",
      "Training Loss: 0.2597\n",
      "Validation Loss: 0.2823, AUROC: 0.9553\n",
      "Epoch [830/1000]\n",
      "Training Loss: 0.2594\n",
      "Validation Loss: 0.2834, AUROC: 0.9553\n",
      "Epoch [831/1000]\n",
      "Training Loss: 0.2594\n",
      "Validation Loss: 0.2828, AUROC: 0.9553\n",
      "Epoch [832/1000]\n",
      "Training Loss: 0.2598\n",
      "Validation Loss: 0.2823, AUROC: 0.9554\n",
      "Epoch [833/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2829, AUROC: 0.9554\n",
      "Epoch [834/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2834, AUROC: 0.9554\n",
      "Epoch [835/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2831, AUROC: 0.9554\n",
      "Epoch [836/1000]\n",
      "Training Loss: 0.2607\n",
      "Validation Loss: 0.2818, AUROC: 0.9554\n",
      "Epoch [837/1000]\n",
      "Training Loss: 0.2595\n",
      "Validation Loss: 0.2832, AUROC: 0.9554\n",
      "Epoch [838/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2835, AUROC: 0.9554\n",
      "Epoch [839/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2820, AUROC: 0.9554\n",
      "Epoch [840/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2823, AUROC: 0.9554\n",
      "Epoch [841/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2830, AUROC: 0.9554\n",
      "Epoch [842/1000]\n",
      "Training Loss: 0.2602\n",
      "Validation Loss: 0.2820, AUROC: 0.9554\n",
      "Epoch [843/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2831, AUROC: 0.9554\n",
      "Epoch [844/1000]\n",
      "Training Loss: 0.2593\n",
      "Validation Loss: 0.2831, AUROC: 0.9554\n",
      "Epoch [845/1000]\n",
      "Training Loss: 0.2600\n",
      "Validation Loss: 0.2818, AUROC: 0.9554\n",
      "Epoch [846/1000]\n",
      "Training Loss: 0.2594\n",
      "Validation Loss: 0.2829, AUROC: 0.9554\n",
      "Epoch [847/1000]\n",
      "Training Loss: 0.2601\n",
      "Validation Loss: 0.2817, AUROC: 0.9555\n",
      "Epoch [848/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2827, AUROC: 0.9555\n",
      "Epoch [849/1000]\n",
      "Training Loss: 0.2594\n",
      "Validation Loss: 0.2828, AUROC: 0.9555\n",
      "Epoch [850/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2812, AUROC: 0.9555\n",
      "Epoch [851/1000]\n",
      "Training Loss: 0.2599\n",
      "Validation Loss: 0.2820, AUROC: 0.9555\n",
      "Epoch [852/1000]\n",
      "Training Loss: 0.2593\n",
      "Validation Loss: 0.2834, AUROC: 0.9555\n",
      "Epoch [853/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2818, AUROC: 0.9555\n",
      "Epoch [854/1000]\n",
      "Training Loss: 0.2601\n",
      "Validation Loss: 0.2814, AUROC: 0.9555\n",
      "Epoch [855/1000]\n",
      "Training Loss: 0.2597\n",
      "Validation Loss: 0.2821, AUROC: 0.9555\n",
      "Epoch [856/1000]\n",
      "Training Loss: 0.2592\n",
      "Validation Loss: 0.2822, AUROC: 0.9555\n",
      "Epoch [857/1000]\n",
      "Training Loss: 0.2583\n",
      "Validation Loss: 0.2820, AUROC: 0.9555\n",
      "Epoch [858/1000]\n",
      "Training Loss: 0.2585\n",
      "Validation Loss: 0.2813, AUROC: 0.9555\n",
      "Epoch [859/1000]\n",
      "Training Loss: 0.2583\n",
      "Validation Loss: 0.2817, AUROC: 0.9555\n",
      "Epoch [860/1000]\n",
      "Training Loss: 0.2591\n",
      "Validation Loss: 0.2824, AUROC: 0.9555\n",
      "Epoch [861/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2829, AUROC: 0.9556\n",
      "Epoch [862/1000]\n",
      "Training Loss: 0.2593\n",
      "Validation Loss: 0.2826, AUROC: 0.9556\n",
      "Epoch [863/1000]\n",
      "Training Loss: 0.2598\n",
      "Validation Loss: 0.2823, AUROC: 0.9556\n",
      "Epoch [864/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2825, AUROC: 0.9556\n",
      "Epoch [865/1000]\n",
      "Training Loss: 0.2603\n",
      "Validation Loss: 0.2817, AUROC: 0.9556\n",
      "Epoch [866/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2822, AUROC: 0.9556\n",
      "Epoch [867/1000]\n",
      "Training Loss: 0.2590\n",
      "Validation Loss: 0.2830, AUROC: 0.9556\n",
      "Epoch [868/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2824, AUROC: 0.9556\n",
      "Epoch [869/1000]\n",
      "Training Loss: 0.2577\n",
      "Validation Loss: 0.2824, AUROC: 0.9556\n",
      "Epoch [870/1000]\n",
      "Training Loss: 0.2602\n",
      "Validation Loss: 0.2814, AUROC: 0.9556\n",
      "Epoch [871/1000]\n",
      "Training Loss: 0.2595\n",
      "Validation Loss: 0.2822, AUROC: 0.9556\n",
      "Epoch [872/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2822, AUROC: 0.9556\n",
      "Epoch [873/1000]\n",
      "Training Loss: 0.2581\n",
      "Validation Loss: 0.2824, AUROC: 0.9556\n",
      "Epoch [874/1000]\n",
      "Training Loss: 0.2584\n",
      "Validation Loss: 0.2827, AUROC: 0.9557\n",
      "Epoch [875/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2813, AUROC: 0.9557\n",
      "Epoch [876/1000]\n",
      "Training Loss: 0.2600\n",
      "Validation Loss: 0.2811, AUROC: 0.9557\n",
      "Epoch [877/1000]\n",
      "Training Loss: 0.2591\n",
      "Validation Loss: 0.2815, AUROC: 0.9557\n",
      "Epoch [878/1000]\n",
      "Training Loss: 0.2593\n",
      "Validation Loss: 0.2824, AUROC: 0.9557\n",
      "Epoch [879/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2812, AUROC: 0.9557\n",
      "Epoch [880/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2824, AUROC: 0.9557\n",
      "Epoch [881/1000]\n",
      "Training Loss: 0.2586\n",
      "Validation Loss: 0.2815, AUROC: 0.9557\n",
      "Epoch [882/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2814, AUROC: 0.9557\n",
      "Epoch [883/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2815, AUROC: 0.9557\n",
      "Epoch [884/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2821, AUROC: 0.9557\n",
      "Epoch [885/1000]\n",
      "Training Loss: 0.2597\n",
      "Validation Loss: 0.2817, AUROC: 0.9557\n",
      "Epoch [886/1000]\n",
      "Training Loss: 0.2590\n",
      "Validation Loss: 0.2804, AUROC: 0.9557\n",
      "Epoch [887/1000]\n",
      "Training Loss: 0.2588\n",
      "Validation Loss: 0.2811, AUROC: 0.9557\n",
      "Epoch [888/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2809, AUROC: 0.9557\n",
      "Epoch [889/1000]\n",
      "Training Loss: 0.2579\n",
      "Validation Loss: 0.2818, AUROC: 0.9557\n",
      "Epoch [890/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2821, AUROC: 0.9557\n",
      "Epoch [891/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2814, AUROC: 0.9557\n",
      "Epoch [892/1000]\n",
      "Training Loss: 0.2583\n",
      "Validation Loss: 0.2822, AUROC: 0.9558\n",
      "Epoch [893/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2827, AUROC: 0.9558\n",
      "Epoch [894/1000]\n",
      "Training Loss: 0.2580\n",
      "Validation Loss: 0.2812, AUROC: 0.9558\n",
      "Epoch [895/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2814, AUROC: 0.9558\n",
      "Epoch [896/1000]\n",
      "Training Loss: 0.2596\n",
      "Validation Loss: 0.2815, AUROC: 0.9558\n",
      "Epoch [897/1000]\n",
      "Training Loss: 0.2591\n",
      "Validation Loss: 0.2808, AUROC: 0.9558\n",
      "Epoch [898/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2802, AUROC: 0.9558\n",
      "Epoch [899/1000]\n",
      "Training Loss: 0.2580\n",
      "Validation Loss: 0.2823, AUROC: 0.9558\n",
      "Epoch [900/1000]\n",
      "Training Loss: 0.2585\n",
      "Validation Loss: 0.2826, AUROC: 0.9558\n",
      "Epoch [901/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2810, AUROC: 0.9558\n",
      "Epoch [902/1000]\n",
      "Training Loss: 0.2587\n",
      "Validation Loss: 0.2807, AUROC: 0.9558\n",
      "Epoch [903/1000]\n",
      "Training Loss: 0.2588\n",
      "Validation Loss: 0.2814, AUROC: 0.9558\n",
      "Epoch [904/1000]\n",
      "Training Loss: 0.2572\n",
      "Validation Loss: 0.2813, AUROC: 0.9558\n",
      "Epoch [905/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2808, AUROC: 0.9558\n",
      "Epoch [906/1000]\n",
      "Training Loss: 0.2583\n",
      "Validation Loss: 0.2807, AUROC: 0.9559\n",
      "Epoch [907/1000]\n",
      "Training Loss: 0.2580\n",
      "Validation Loss: 0.2817, AUROC: 0.9559\n",
      "Epoch [908/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2816, AUROC: 0.9559\n",
      "Epoch [909/1000]\n",
      "Training Loss: 0.2593\n",
      "Validation Loss: 0.2807, AUROC: 0.9559\n",
      "Epoch [910/1000]\n",
      "Training Loss: 0.2577\n",
      "Validation Loss: 0.2813, AUROC: 0.9559\n",
      "Epoch [911/1000]\n",
      "Training Loss: 0.2579\n",
      "Validation Loss: 0.2815, AUROC: 0.9559\n",
      "Epoch [912/1000]\n",
      "Training Loss: 0.2579\n",
      "Validation Loss: 0.2808, AUROC: 0.9559\n",
      "Epoch [913/1000]\n",
      "Training Loss: 0.2571\n",
      "Validation Loss: 0.2823, AUROC: 0.9559\n",
      "Epoch [914/1000]\n",
      "Training Loss: 0.2585\n",
      "Validation Loss: 0.2808, AUROC: 0.9559\n",
      "Epoch [915/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2803, AUROC: 0.9559\n",
      "Epoch [916/1000]\n",
      "Training Loss: 0.2577\n",
      "Validation Loss: 0.2808, AUROC: 0.9559\n",
      "Epoch [917/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2817, AUROC: 0.9559\n",
      "Epoch [918/1000]\n",
      "Training Loss: 0.2584\n",
      "Validation Loss: 0.2800, AUROC: 0.9559\n",
      "Epoch [919/1000]\n",
      "Training Loss: 0.2581\n",
      "Validation Loss: 0.2803, AUROC: 0.9559\n",
      "Epoch [920/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2811, AUROC: 0.9559\n",
      "Epoch [921/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2808, AUROC: 0.9559\n",
      "Epoch [922/1000]\n",
      "Training Loss: 0.2581\n",
      "Validation Loss: 0.2798, AUROC: 0.9559\n",
      "Epoch [923/1000]\n",
      "Training Loss: 0.2574\n",
      "Validation Loss: 0.2805, AUROC: 0.9560\n",
      "Epoch [924/1000]\n",
      "Training Loss: 0.2574\n",
      "Validation Loss: 0.2813, AUROC: 0.9560\n",
      "Epoch [925/1000]\n",
      "Training Loss: 0.2588\n",
      "Validation Loss: 0.2804, AUROC: 0.9560\n",
      "Epoch [926/1000]\n",
      "Training Loss: 0.2572\n",
      "Validation Loss: 0.2809, AUROC: 0.9560\n",
      "Epoch [927/1000]\n",
      "Training Loss: 0.2581\n",
      "Validation Loss: 0.2812, AUROC: 0.9560\n",
      "Epoch [928/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2806, AUROC: 0.9560\n",
      "Epoch [929/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2819, AUROC: 0.9560\n",
      "Epoch [930/1000]\n",
      "Training Loss: 0.2577\n",
      "Validation Loss: 0.2805, AUROC: 0.9560\n",
      "Epoch [931/1000]\n",
      "Training Loss: 0.2581\n",
      "Validation Loss: 0.2791, AUROC: 0.9560\n",
      "Epoch [932/1000]\n",
      "Training Loss: 0.2585\n",
      "Validation Loss: 0.2806, AUROC: 0.9560\n",
      "Epoch [933/1000]\n",
      "Training Loss: 0.2594\n",
      "Validation Loss: 0.2800, AUROC: 0.9560\n",
      "Epoch [934/1000]\n",
      "Training Loss: 0.2577\n",
      "Validation Loss: 0.2806, AUROC: 0.9560\n",
      "Epoch [935/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2805, AUROC: 0.9560\n",
      "Epoch [936/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2804, AUROC: 0.9560\n",
      "Epoch [937/1000]\n",
      "Training Loss: 0.2586\n",
      "Validation Loss: 0.2808, AUROC: 0.9560\n",
      "Epoch [938/1000]\n",
      "Training Loss: 0.2589\n",
      "Validation Loss: 0.2792, AUROC: 0.9561\n",
      "Epoch [939/1000]\n",
      "Training Loss: 0.2582\n",
      "Validation Loss: 0.2805, AUROC: 0.9561\n",
      "Epoch [940/1000]\n",
      "Training Loss: 0.2572\n",
      "Validation Loss: 0.2799, AUROC: 0.9561\n",
      "Epoch [941/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2807, AUROC: 0.9561\n",
      "Epoch [942/1000]\n",
      "Training Loss: 0.2570\n",
      "Validation Loss: 0.2817, AUROC: 0.9561\n",
      "Epoch [943/1000]\n",
      "Training Loss: 0.2562\n",
      "Validation Loss: 0.2804, AUROC: 0.9561\n",
      "Epoch [944/1000]\n",
      "Training Loss: 0.2570\n",
      "Validation Loss: 0.2810, AUROC: 0.9561\n",
      "Epoch [945/1000]\n",
      "Training Loss: 0.2580\n",
      "Validation Loss: 0.2800, AUROC: 0.9561\n",
      "Epoch [946/1000]\n",
      "Training Loss: 0.2574\n",
      "Validation Loss: 0.2796, AUROC: 0.9561\n",
      "Epoch [947/1000]\n",
      "Training Loss: 0.2581\n",
      "Validation Loss: 0.2808, AUROC: 0.9561\n",
      "Epoch [948/1000]\n",
      "Training Loss: 0.2567\n",
      "Validation Loss: 0.2799, AUROC: 0.9561\n",
      "Epoch [949/1000]\n",
      "Training Loss: 0.2573\n",
      "Validation Loss: 0.2805, AUROC: 0.9561\n",
      "Epoch [950/1000]\n",
      "Training Loss: 0.2571\n",
      "Validation Loss: 0.2802, AUROC: 0.9561\n",
      "Epoch [951/1000]\n",
      "Training Loss: 0.2570\n",
      "Validation Loss: 0.2792, AUROC: 0.9561\n",
      "Epoch [952/1000]\n",
      "Training Loss: 0.2583\n",
      "Validation Loss: 0.2794, AUROC: 0.9561\n",
      "Epoch [953/1000]\n",
      "Training Loss: 0.2568\n",
      "Validation Loss: 0.2807, AUROC: 0.9561\n",
      "Epoch [954/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2807, AUROC: 0.9561\n",
      "Epoch [955/1000]\n",
      "Training Loss: 0.2562\n",
      "Validation Loss: 0.2795, AUROC: 0.9561\n",
      "Epoch [956/1000]\n",
      "Training Loss: 0.2573\n",
      "Validation Loss: 0.2806, AUROC: 0.9561\n",
      "Epoch [957/1000]\n",
      "Training Loss: 0.2578\n",
      "Validation Loss: 0.2805, AUROC: 0.9561\n",
      "Epoch [958/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2801, AUROC: 0.9562\n",
      "Epoch [959/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2799, AUROC: 0.9562\n",
      "Epoch [960/1000]\n",
      "Training Loss: 0.2569\n",
      "Validation Loss: 0.2807, AUROC: 0.9562\n",
      "Epoch [961/1000]\n",
      "Training Loss: 0.2578\n",
      "Validation Loss: 0.2804, AUROC: 0.9562\n",
      "Epoch [962/1000]\n",
      "Training Loss: 0.2579\n",
      "Validation Loss: 0.2800, AUROC: 0.9562\n",
      "Epoch [963/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2797, AUROC: 0.9562\n",
      "Epoch [964/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2792, AUROC: 0.9562\n",
      "Epoch [965/1000]\n",
      "Training Loss: 0.2568\n",
      "Validation Loss: 0.2795, AUROC: 0.9562\n",
      "Epoch [966/1000]\n",
      "Training Loss: 0.2573\n",
      "Validation Loss: 0.2809, AUROC: 0.9562\n",
      "Epoch [967/1000]\n",
      "Training Loss: 0.2577\n",
      "Validation Loss: 0.2803, AUROC: 0.9562\n",
      "Epoch [968/1000]\n",
      "Training Loss: 0.2569\n",
      "Validation Loss: 0.2795, AUROC: 0.9562\n",
      "Epoch [969/1000]\n",
      "Training Loss: 0.2570\n",
      "Validation Loss: 0.2803, AUROC: 0.9562\n",
      "Epoch [970/1000]\n",
      "Training Loss: 0.2559\n",
      "Validation Loss: 0.2802, AUROC: 0.9562\n",
      "Epoch [971/1000]\n",
      "Training Loss: 0.2563\n",
      "Validation Loss: 0.2799, AUROC: 0.9562\n",
      "Epoch [972/1000]\n",
      "Training Loss: 0.2571\n",
      "Validation Loss: 0.2802, AUROC: 0.9562\n",
      "Epoch [973/1000]\n",
      "Training Loss: 0.2572\n",
      "Validation Loss: 0.2801, AUROC: 0.9562\n",
      "Epoch [974/1000]\n",
      "Training Loss: 0.2569\n",
      "Validation Loss: 0.2798, AUROC: 0.9562\n",
      "Epoch [975/1000]\n",
      "Training Loss: 0.2558\n",
      "Validation Loss: 0.2800, AUROC: 0.9562\n",
      "Epoch [976/1000]\n",
      "Training Loss: 0.2579\n",
      "Validation Loss: 0.2787, AUROC: 0.9563\n",
      "Epoch [977/1000]\n",
      "Training Loss: 0.2566\n",
      "Validation Loss: 0.2799, AUROC: 0.9563\n",
      "Epoch [978/1000]\n",
      "Training Loss: 0.2576\n",
      "Validation Loss: 0.2788, AUROC: 0.9563\n",
      "Epoch [979/1000]\n",
      "Training Loss: 0.2579\n",
      "Validation Loss: 0.2794, AUROC: 0.9563\n",
      "Epoch [980/1000]\n",
      "Training Loss: 0.2571\n",
      "Validation Loss: 0.2801, AUROC: 0.9563\n",
      "Epoch [981/1000]\n",
      "Training Loss: 0.2564\n",
      "Validation Loss: 0.2792, AUROC: 0.9563\n",
      "Epoch [982/1000]\n",
      "Training Loss: 0.2552\n",
      "Validation Loss: 0.2799, AUROC: 0.9563\n",
      "Epoch [983/1000]\n",
      "Training Loss: 0.2559\n",
      "Validation Loss: 0.2802, AUROC: 0.9563\n",
      "Epoch [984/1000]\n",
      "Training Loss: 0.2575\n",
      "Validation Loss: 0.2800, AUROC: 0.9563\n",
      "Epoch [985/1000]\n",
      "Training Loss: 0.2558\n",
      "Validation Loss: 0.2803, AUROC: 0.9563\n",
      "Epoch [986/1000]\n",
      "Training Loss: 0.2574\n",
      "Validation Loss: 0.2801, AUROC: 0.9563\n",
      "Epoch [987/1000]\n",
      "Training Loss: 0.2572\n",
      "Validation Loss: 0.2790, AUROC: 0.9563\n",
      "Epoch [988/1000]\n",
      "Training Loss: 0.2561\n",
      "Validation Loss: 0.2797, AUROC: 0.9563\n",
      "Epoch [989/1000]\n",
      "Training Loss: 0.2563\n",
      "Validation Loss: 0.2805, AUROC: 0.9563\n",
      "Epoch [990/1000]\n",
      "Training Loss: 0.2561\n",
      "Validation Loss: 0.2801, AUROC: 0.9563\n",
      "Epoch [991/1000]\n",
      "Training Loss: 0.2561\n",
      "Validation Loss: 0.2796, AUROC: 0.9563\n",
      "Epoch [992/1000]\n",
      "Training Loss: 0.2571\n",
      "Validation Loss: 0.2791, AUROC: 0.9563\n",
      "Epoch [993/1000]\n",
      "Training Loss: 0.2568\n",
      "Validation Loss: 0.2794, AUROC: 0.9564\n",
      "Epoch [994/1000]\n",
      "Training Loss: 0.2562\n",
      "Validation Loss: 0.2814, AUROC: 0.9563\n",
      "Epoch [995/1000]\n",
      "Training Loss: 0.2572\n",
      "Validation Loss: 0.2799, AUROC: 0.9564\n",
      "Epoch [996/1000]\n",
      "Training Loss: 0.2562\n",
      "Validation Loss: 0.2788, AUROC: 0.9564\n",
      "Epoch [997/1000]\n",
      "Training Loss: 0.2566\n",
      "Validation Loss: 0.2799, AUROC: 0.9564\n",
      "Epoch [998/1000]\n",
      "Training Loss: 0.2574\n",
      "Validation Loss: 0.2787, AUROC: 0.9564\n",
      "Epoch [999/1000]\n",
      "Training Loss: 0.2571\n",
      "Validation Loss: 0.2793, AUROC: 0.9564\n",
      "Epoch [1000/1000]\n",
      "Training Loss: 0.2569\n",
      "Validation Loss: 0.2794, AUROC: 0.9564\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d3c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02921791, 0.8046558 , 0.00224506, ..., 0.89249635, 0.01050335,\n",
       "       0.72527885], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = X_test_tensor.to(device)\n",
    "    test_outputs = torch.sigmoid(model(X_test_tensor).cpu()).flatten().numpy()\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission[\"id\"] = test[\"id\"]\n",
    "submission[config.target_column] = test_outputs\n",
    "submission.to_csv(config.data_path / config.submission_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningPyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
