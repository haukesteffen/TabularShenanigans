{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3597323",
   "metadata": {},
   "source": [
    "## PROJECT INIT\n",
    "\n",
    "- Handle imports and settings\n",
    "- Initialize DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30aa7356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from /Users/haukesteffen/dev/TabularShenanigans/config.yaml.\n",
      "Table 'competitions' already exists in the database.\n",
      "Competition 'playground-series-s5e8' already exists in the database.\n",
      "Table 'datasets' already exists in the database.\n",
      "Dataset 'playground-series-s5e8-train' already exists in the 'datasets' table.\n",
      "Dataset 'playground-series-s5e8-test' already exists in the 'datasets' table.\n",
      "Downloading data for competition 'playground-series-s5e8'...\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import holidays\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler,\n",
    "    PolynomialFeatures,\n",
    ")\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from utils.config import load_config\n",
    "from utils.data import initialize_project\n",
    "\n",
    "config_path = pathlib.Path.cwd().parent / \"config.yaml\"\n",
    "config = load_config(config_path)\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "db_uri = initialize_project(config=config, init_db=True)\n",
    "engine = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c405a78",
   "metadata": {},
   "source": [
    "## FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7bc9332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r7/1qf9bs6920bgntn0wmtsp71m0000gn/T/ipykernel_6540/1480945169.py:93: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  train[\"is_holiday\"] = train[\"date\"].isin(portugal_holidays).astype(int)\n",
      "/var/folders/r7/1qf9bs6920bgntn0wmtsp71m0000gn/T/ipykernel_6540/1480945169.py:94: FutureWarning: The behavior of 'isin' with dtype=datetime64[ns] and castable values (e.g. strings) is deprecated. In a future version, these will not be considered matching by isin. Explicitly cast to the appropriate dtype before calling isin instead.\n",
      "  test[\"is_holiday\"] = test[\"date\"].isin(portugal_holidays).astype(int)\n"
     ]
    }
   ],
   "source": [
    "with engine.begin() as connection:\n",
    "    train = pd.read_sql(\n",
    "        sql=f\"SELECT * FROM [{config.competition_name}-train]\", con=connection\n",
    "    ).convert_dtypes()\n",
    "    test = pd.read_sql(\n",
    "        sql=f\"SELECT * FROM [{config.competition_name}-test]\", con=connection\n",
    "    ).convert_dtypes()\n",
    "\n",
    "train_index = train[config.id_column]\n",
    "test_index = test[config.id_column]\n",
    "train = train.drop(columns=[config.id_column])\n",
    "test = test.drop(columns=[config.id_column])\n",
    "\n",
    "binary_features = [\"default\", \"housing\", \"loan\"]\n",
    "categorical_features = [\"job\", \"marital\", \"education\", \"contact\", \"poutcome\"]\n",
    "numerical_features = [\n",
    "    \"age\",\n",
    "    \"balance\",\n",
    "    \"duration\",\n",
    "    \"campaign\",\n",
    "    \"pdays\",\n",
    "    \"previous\",\n",
    "]\n",
    "\n",
    "# map months from string to integer\n",
    "month_map = {\n",
    "    \"jan\": 1,\n",
    "    \"feb\": 2,\n",
    "    \"mar\": 3,\n",
    "    \"apr\": 4,\n",
    "    \"may\": 5,\n",
    "    \"jun\": 6,\n",
    "    \"jul\": 7,\n",
    "    \"aug\": 8,\n",
    "    \"sep\": 9,\n",
    "    \"oct\": 10,\n",
    "    \"nov\": 11,\n",
    "    \"dec\": 12,\n",
    "}\n",
    "train[\"month\"] = train[\"month\"].map(month_map)\n",
    "test[\"month\"] = test[\"month\"].map(month_map)\n",
    "\n",
    "\n",
    "# fix invalid day/month combinations\n",
    "def fix_days_and_months(row):\n",
    "    if row[\"day\"] == 31 and row[\"month\"] in [4, 6, 9, 11]:\n",
    "        row[\"day\"] = 30\n",
    "    if row[\"day\"] >= 29 and row[\"month\"] == 2:\n",
    "        row[\"day\"] = 28\n",
    "    return row\n",
    "\n",
    "\n",
    "train = train.apply(fix_days_and_months, axis=1)\n",
    "test = test.apply(fix_days_and_months, axis=1)\n",
    "\n",
    "\n",
    "# convert day and month to datetime and add date-related features\n",
    "train[\"date\"] = pd.to_datetime(\n",
    "    dict(year=2023, month=train[\"month\"], day=train[\"day\"]), errors=\"coerce\"\n",
    ")\n",
    "test[\"date\"] = pd.to_datetime(\n",
    "    dict(year=2023, month=test[\"month\"], day=test[\"day\"]), errors=\"coerce\"\n",
    ")\n",
    "train[\"day_of_year\"] = train[\"date\"].dt.dayofyear\n",
    "test[\"day_of_year\"] = test[\"date\"].dt.dayofyear\n",
    "train[\"day_of_week\"] = train[\"date\"].dt.dayofweek\n",
    "test[\"day_of_week\"] = test[\"date\"].dt.dayofweek\n",
    "train[\"week_of_year\"] = train[\"date\"].dt.isocalendar().week\n",
    "test[\"week_of_year\"] = test[\"date\"].dt.isocalendar().week\n",
    "train[\"quarter\"] = train[\"date\"].dt.quarter\n",
    "test[\"quarter\"] = test[\"date\"].dt.quarter\n",
    "\n",
    "\n",
    "# extract season from month\n",
    "def get_season(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return \"Winter\"\n",
    "    elif month in [3, 4, 5]:\n",
    "        return \"Spring\"\n",
    "    elif month in [6, 7, 8]:\n",
    "        return \"Summer\"\n",
    "    else:\n",
    "        return \"Autumn\"\n",
    "\n",
    "\n",
    "train[\"season\"] = train[\"month\"].apply(get_season)\n",
    "test[\"season\"] = test[\"month\"].apply(get_season)\n",
    "categorical_features += [\"season\"]\n",
    "\n",
    "\n",
    "# extract holiday from date\n",
    "portugal_holidays = holidays.Portugal(years=2023)\n",
    "train[\"is_holiday\"] = train[\"date\"].isin(portugal_holidays).astype(int)\n",
    "test[\"is_holiday\"] = test[\"date\"].isin(portugal_holidays).astype(int)\n",
    "binary_features += [\"is_holiday\"]\n",
    "\n",
    "\n",
    "# create cyclical features for date-related features\n",
    "def create_cyclical_features(train, test, col):\n",
    "    train[col + \"_sin\"] = np.sin(2 * np.pi * train[col] / train[col].max())\n",
    "    train[col + \"_cos\"] = np.cos(2 * np.pi * train[col] / train[col].max())\n",
    "    test[col + \"_sin\"] = np.sin(2 * np.pi * test[col] / train[col].max())\n",
    "    test[col + \"_cos\"] = np.cos(2 * np.pi * test[col] / train[col].max())\n",
    "    return train, test\n",
    "\n",
    "\n",
    "train, test = create_cyclical_features(train, test, \"day_of_week\")\n",
    "train, test = create_cyclical_features(train, test, \"day\")\n",
    "train, test = create_cyclical_features(train, test, \"day_of_year\")\n",
    "train, test = create_cyclical_features(train, test, \"week_of_year\")\n",
    "train, test = create_cyclical_features(train, test, \"month\")\n",
    "train, test = create_cyclical_features(train, test, \"quarter\")\n",
    "numerical_features += [\n",
    "    \"day_of_week_sin\",\n",
    "    \"day_of_week_cos\",\n",
    "    \"day_sin\",\n",
    "    \"day_cos\",\n",
    "    \"day_of_year_sin\",\n",
    "    \"day_of_year_cos\",\n",
    "    \"week_of_year_sin\",\n",
    "    \"week_of_year_cos\",\n",
    "    \"month_sin\",\n",
    "    \"month_cos\",\n",
    "    \"quarter_sin\",\n",
    "    \"quarter_cos\",\n",
    "]\n",
    "\n",
    "\n",
    "# create flag if the client has been contacted before\n",
    "# and map pdays to a more meaningful value\n",
    "train[\"never_contacted_before\"] = train.apply(\n",
    "    lambda row: 1 if row[\"pdays\"] == -1 else 0, axis=1\n",
    ")\n",
    "test[\"never_contacted_before\"] = test.apply(\n",
    "    lambda row: 1 if row[\"pdays\"] == -1 else 0, axis=1\n",
    ")\n",
    "binary_features += [\"never_contacted_before\"]\n",
    "max_pdays = train[\"pdays\"].max()\n",
    "train[\"pdays\"] = train[\"pdays\"].apply(lambda x: x if x != -1 else max_pdays)\n",
    "test[\"pdays\"] = test[\"pdays\"].apply(lambda x: x if x != -1 else max_pdays)\n",
    "\n",
    "\n",
    "# create features based on interactions\n",
    "train[\"balance_per_age\"] = train[\"balance\"] / (train[\"age\"])\n",
    "test[\"balance_per_age\"] = test[\"balance\"] / (test[\"age\"])\n",
    "numerical_features += [\"balance_per_age\"]\n",
    "train[\"housing_and_loan\"] = train.apply(\n",
    "    lambda row: \"yes\" if row[\"housing\"] == \"yes\" and row[\"loan\"] == \"yes\" else \"no\",\n",
    "    axis=1,\n",
    ")\n",
    "test[\"housing_and_loan\"] = test.apply(\n",
    "    lambda row: \"yes\" if row[\"housing\"] == \"yes\" and row[\"loan\"] == \"yes\" else \"no\",\n",
    "    axis=1,\n",
    ")\n",
    "binary_features += [\"housing_and_loan\"]\n",
    "\n",
    "# drop original date-related features\n",
    "train = train.drop(\n",
    "    columns=[\n",
    "        \"day\",\n",
    "        \"month\",\n",
    "        \"date\",\n",
    "        \"day_of_year\",\n",
    "        \"day_of_week\",\n",
    "        \"week_of_year\",\n",
    "        \"quarter\",\n",
    "    ],\n",
    ")\n",
    "test = test.drop(\n",
    "    columns=[\n",
    "        \"day\",\n",
    "        \"month\",\n",
    "        \"date\",\n",
    "        \"day_of_year\",\n",
    "        \"day_of_week\",\n",
    "        \"week_of_year\",\n",
    "        \"quarter\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# add polynomials of numerical features\n",
    "poly = PolynomialFeatures(degree=(2, 2), interaction_only=True)\n",
    "poly_train = poly.fit_transform(train[numerical_features]).drop(columns=[\"1\"])\n",
    "poly_test = poly.transform(test[numerical_features]).drop(columns=[\"1\"])\n",
    "train = pd.concat([train, poly_train], axis=1).copy(deep=True)\n",
    "test = pd.concat([test, poly_test], axis=1).copy(deep=True)\n",
    "numerical_features += poly_train.columns.to_list()\n",
    "\n",
    "# feature consistency checks\n",
    "features = train.drop(columns=[config.target_column]).columns.tolist()\n",
    "\n",
    "# assert every feature is in one of the feature categories\n",
    "assert set(features) == set(binary_features + categorical_features + numerical_features)\n",
    "\n",
    "# assert every feature is in only one feature category\n",
    "assert len(set(numerical_features) & set(binary_features)) == 0\n",
    "assert len(set(binary_features) & set(categorical_features)) == 0\n",
    "assert len(set(categorical_features) & set(numerical_features)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b2e5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split datasets into features/target, as well as train/validation\n",
    "X_train_raw = train.drop(columns=[config.target_column])\n",
    "y_train_raw = train[config.target_column]\n",
    "X_test_raw = test.copy()\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\n",
    "            \"column_transform\",\n",
    "            ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"binary_encode\",\n",
    "                        OrdinalEncoder(\n",
    "                            handle_unknown=\"use_encoded_value\", unknown_value=np.nan\n",
    "                        ),\n",
    "                        binary_features,\n",
    "                    ),\n",
    "                    (\n",
    "                        \"categorical_encode\",\n",
    "                        OneHotEncoder(\n",
    "                            handle_unknown=\"ignore\",\n",
    "                            sparse_output=False,\n",
    "                            drop=\"first\",\n",
    "                        ),\n",
    "                        categorical_features,\n",
    "                    ),\n",
    "                    (\n",
    "                        \"scale_numerical\",\n",
    "                        StandardScaler(),\n",
    "                        numerical_features,\n",
    "                    ),\n",
    "                ],\n",
    "                remainder=\"drop\",\n",
    "                verbose_feature_names_out=False,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train = pipeline.fit_transform(X_train_raw)\n",
    "X_test = pipeline.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "352e6a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed = pd.concat([train_index, X_train, y_train_raw], axis=1)\n",
    "test_preprocessed = pd.concat([test_index, X_test], axis=1)\n",
    "\n",
    "with engine.begin() as connection:\n",
    "    train_preprocessed.to_sql(\n",
    "        config.competition_name + \"-train-preprocessed\",\n",
    "        connection,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "    )\n",
    "    test_preprocessed.to_sql(\n",
    "        config.competition_name + \"-test-preprocessed\",\n",
    "        connection,\n",
    "        if_exists=\"replace\",\n",
    "        index=False,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabularshenanigans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
