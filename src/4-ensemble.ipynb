{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57fc5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haukesteffen/dev/TabularShenanigans/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from /Users/haukesteffen/dev/TabularShenanigans/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import joblib\n",
    "\n",
    "# ==== imports / setup ====\n",
    "import mlflow\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sqlalchemy import create_engine\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utils.config import load_config\n",
    "from utils.data import initialize_project\n",
    "\n",
    "# point to the same tracking URI you used during base tuning\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "BASE_EXPERIMENT = \"base-models\"\n",
    "STACKING_EXPERIMENT = \"meta-model\"\n",
    "joblib.parallel_backend(\"threading\")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "SCORING = \"roc_auc\"\n",
    "\n",
    "\n",
    "config_path = pathlib.Path.cwd().parent / \"config.yaml\"\n",
    "config = load_config(config_path)\n",
    "sklearn.set_config(transform_output=\"pandas\")\n",
    "\n",
    "db_uri = initialize_project(config=config, init_db=False)\n",
    "engine = create_engine(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f17e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== helpers: find + load base models from MLflow ====\n",
    "\n",
    "\n",
    "def find_parent_run_id(model_name: str, experiment_name: str) -> str:\n",
    "    \"\"\"Find the most recent parent run for <model_name> (e.g., 'XGBoost_tuning').\"\"\"\n",
    "    exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "    if exp is None:\n",
    "        raise ValueError(f\"Experiment not found: {experiment_name}\")\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_ids=[exp.experiment_id],\n",
    "        filter_string=f\"attributes.run_name = '{model_name}_tuning'\",\n",
    "        order_by=[\"attributes.start_time DESC\"],\n",
    "        max_results=1,\n",
    "    )\n",
    "    if runs.empty:\n",
    "        raise ValueError(f\"No parent run found for {model_name}_tuning\")\n",
    "    return runs.iloc[0][\"run_id\"]\n",
    "\n",
    "\n",
    "def load_base_estimator(model_name: str, experiment_name: str):\n",
    "    \"\"\"\n",
    "    Load the fitted best model artifact we logged in base tuning.\n",
    "    Returns an unfitted clone-equivalent (sklearn will re-fit anyway).\n",
    "    \"\"\"\n",
    "    run_id = find_parent_run_id(model_name, experiment_name)\n",
    "    artifact_name = f\"{model_name}_best_model\"  # how we logged it earlier\n",
    "\n",
    "    if model_name == \"XGBoost\":\n",
    "        # XGBoost models logged with mlflow.xgboost\n",
    "        model = mlflow.xgboost.load_model(f\"runs:/{run_id}/{artifact_name}\")\n",
    "    else:\n",
    "        # sklearn flavor (MLP, KNN)\n",
    "        model = mlflow.sklearn.load_model(f\"runs:/{run_id}/{artifact_name}\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52e6ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as connection:\n",
    "    train = (\n",
    "        pd.read_sql(\n",
    "            sql=f\"SELECT * FROM [{config.competition_name}-train-preprocessed]\",\n",
    "            con=connection,\n",
    "        )\n",
    "        .convert_dtypes()\n",
    "        .sample(frac=1.0)\n",
    "    )\n",
    "    test = (\n",
    "        pd.read_sql(\n",
    "            sql=f\"SELECT * FROM [{config.competition_name}-test-preprocessed]\",\n",
    "            con=connection,\n",
    "        )\n",
    "        .convert_dtypes()\n",
    "        .sample(frac=1.0)\n",
    "    )\n",
    "\n",
    "train = train.set_index(config.id_column)\n",
    "\n",
    "# subsample for faster experiments\n",
    "train = train.sample(n=200_000)\n",
    "\n",
    "X_train = train.drop(columns=[config.target_column])\n",
    "y_train = train[config.target_column]\n",
    "\n",
    "test = test.set_index(config.id_column)\n",
    "X_test = test\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b8f178",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 3101.64it/s] \n",
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 3472.11it/s] \n",
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 168.21it/s]  \n"
     ]
    }
   ],
   "source": [
    "# ==== build base estimators from MLflow ====\n",
    "xgb_base = load_base_estimator(\"XGBoost\", BASE_EXPERIMENT)\n",
    "mlp_base = load_base_estimator(\"MLPClassifier\", BASE_EXPERIMENT)\n",
    "knn_base = load_base_estimator(\"KNeighborsClassifier\", BASE_EXPERIMENT)\n",
    "\n",
    "BASE_ESTIMATORS = [\n",
    "    (\"xgb\", xgb_base),\n",
    "    (\"mlp\", mlp_base),\n",
    "    (\"knn\", knn_base),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "717ed2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Optuna objective: tune XGBoost meta learner ====\n",
    "def meta_objective(trial):\n",
    "    meta = XGBClassifier(\n",
    "        n_estimators=trial.suggest_int(\"meta_n_estimators\", 50, 400),\n",
    "        max_depth=trial.suggest_int(\"meta_max_depth\", 2, 6),\n",
    "        learning_rate=trial.suggest_float(\"meta_lr\", 1e-3, 0.3, log=True),\n",
    "        subsample=trial.suggest_float(\"meta_subsample\", 0.6, 1.0),\n",
    "        colsample_bytree=trial.suggest_float(\"meta_colsample_bytree\", 0.6, 1.0),\n",
    "        reg_lambda=trial.suggest_float(\"meta_reg_lambda\", 1e-3, 10.0, log=True),\n",
    "        reg_alpha=trial.suggest_float(\"meta_reg_alpha\", 1e-4, 1.0, log=True),\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    stack = StackingClassifier(\n",
    "        estimators=BASE_ESTIMATORS,\n",
    "        final_estimator=meta,\n",
    "        stack_method=\"predict_proba\",  # AUC needs probabilities\n",
    "        passthrough=False,  # hard-coded: let meta see original features as well\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # X_train, y_train must be in scope from your data-prep earlier\n",
    "    score = cross_val_score(\n",
    "        stack, X_train, y_train, cv=cv, scoring=SCORING, n_jobs=-1\n",
    "    ).mean()\n",
    "\n",
    "    # log each trial (nested)\n",
    "    with mlflow.start_run(nested=True):\n",
    "        mlflow.set_tag(\"model\", \"StackingClassifier\")\n",
    "        mlflow.set_tag(\"meta_family\", \"XGBoost\")\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metric(\"cv_roc_auc\", score)\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d8cb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-27 12:31:52,850] A new study created in memory with name: no-name-cc131cd8-6852-4519-8c4e-1dea2b6c6c44\n",
      "[I 2025-08-27 12:51:41,573] Trial 0 finished with value: 0.962938404834141 and parameters: {'meta_n_estimators': 374, 'meta_max_depth': 2, 'meta_lr': 0.016898405694014965, 'meta_subsample': 0.6927097358536879, 'meta_colsample_bytree': 0.9377691910068838, 'meta_reg_lambda': 0.15549239597877748, 'meta_reg_alpha': 0.003055869878616567}. Best is trial 0 with value: 0.962938404834141.\n",
      "[I 2025-08-27 13:11:35,568] Trial 1 finished with value: 0.9629531696320882 and parameters: {'meta_n_estimators': 110, 'meta_max_depth': 3, 'meta_lr': 0.07830184497345524, 'meta_subsample': 0.8176498232304393, 'meta_colsample_bytree': 0.9168373789461088, 'meta_reg_lambda': 0.001757597264298947, 'meta_reg_alpha': 0.9786016024534376}. Best is trial 1 with value: 0.9629531696320882.\n",
      "[I 2025-08-27 13:31:45,642] Trial 2 finished with value: 0.9588099592564857 and parameters: {'meta_n_estimators': 187, 'meta_max_depth': 2, 'meta_lr': 0.0016216790262956627, 'meta_subsample': 0.8344111173559264, 'meta_colsample_bytree': 0.6912776478122501, 'meta_reg_lambda': 0.18160549110336477, 'meta_reg_alpha': 0.013996082112338628}. Best is trial 1 with value: 0.9629531696320882.\n",
      "[I 2025-08-27 13:51:50,104] Trial 3 finished with value: 0.961384737606361 and parameters: {'meta_n_estimators': 338, 'meta_max_depth': 5, 'meta_lr': 0.0031574795084355657, 'meta_subsample': 0.6398349338844771, 'meta_colsample_bytree': 0.6150161784143513, 'meta_reg_lambda': 0.1346375836705796, 'meta_reg_alpha': 0.019099472060569042}. Best is trial 1 with value: 0.9629531696320882.\n",
      "[I 2025-08-27 14:12:19,852] Trial 4 finished with value: 0.9616888767495848 and parameters: {'meta_n_estimators': 295, 'meta_max_depth': 3, 'meta_lr': 0.24575172891561392, 'meta_subsample': 0.6363442016309877, 'meta_colsample_bytree': 0.7089578293667327, 'meta_reg_lambda': 0.4078833039259666, 'meta_reg_alpha': 0.0005988182817362546}. Best is trial 1 with value: 0.9629531696320882.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "# ==== run the study and log the final fitted stack ====\n",
    "def run_meta_study(n_trials=50):\n",
    "    mlflow.set_experiment(STACKING_EXPERIMENT)\n",
    "    with mlflow.start_run(run_name=\"stacking_meta_xgb\"):\n",
    "        mlflow.set_tag(\"phase\", \"stacking_tuning_started\")\n",
    "        mlflow.log_param(\"n_trials\", n_trials)\n",
    "        mlflow.log_param(\"base_models\", \",\".join([name for name, _ in BASE_ESTIMATORS]))\n",
    "        mlflow.log_param(\"passthrough\", False)\n",
    "        mlflow.set_tag(\"meta_family\", \"XGBoost\")\n",
    "\n",
    "        study = optuna.create_study(direction=\"maximize\")\n",
    "        study.optimize(meta_objective, n_trials=n_trials)\n",
    "\n",
    "        # summarize best\n",
    "        mlflow.log_metric(\"best_cv_roc_auc\", study.best_value)\n",
    "        mlflow.log_params({f\"best_{k}\": v for k, v in study.best_trial.params.items()})\n",
    "\n",
    "        # rebuild best meta, best stack, fit full train, log the model\n",
    "        bp = study.best_trial.params\n",
    "        best_meta = XGBClassifier(\n",
    "            n_estimators=bp[\"meta_n_estimators\"],\n",
    "            max_depth=bp[\"meta_max_depth\"],\n",
    "            learning_rate=bp[\"meta_lr\"],\n",
    "            subsample=bp[\"meta_subsample\"],\n",
    "            colsample_bytree=bp[\"meta_colsample_bytree\"],\n",
    "            reg_lambda=bp[\"meta_reg_lambda\"],\n",
    "            reg_alpha=bp[\"meta_reg_alpha\"],\n",
    "            eval_metric=\"logloss\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        best_stack = StackingClassifier(\n",
    "            estimators=BASE_ESTIMATORS,\n",
    "            final_estimator=best_meta,\n",
    "            stack_method=\"predict_proba\",\n",
    "            passthrough=False,\n",
    "            cv=cv,\n",
    "            n_jobs=-1,\n",
    "        )\n",
    "        best_stack.fit(X_train, y_train)\n",
    "        mlflow.sklearn.log_model(\n",
    "            best_stack, name=\"StackingClassifier_best_model\", input_example=X_train[:5]\n",
    "        )\n",
    "\n",
    "    return study\n",
    "\n",
    "\n",
    "study = run_meta_study(n_trials=50)\n",
    "print(\"Best meta params:\", study.best_trial.params, \"AUC:\", study.best_value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tabularshenanigans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
