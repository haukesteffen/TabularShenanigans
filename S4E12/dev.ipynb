{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rmsle import ag_rmsle_clamped_scorer\n",
    "\n",
    "train = pd.read_csv('train.csv', index_col='id')\n",
    "test = pd.read_csv('test.csv', index_col='id')\n",
    "label = 'Premium Amount'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **AutoGluon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241228_163852\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.12.2\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.1.0: Thu Oct 10 21:03:15 PDT 2024; root:xnu-11215.41.3~2/RELEASE_ARM64_T6000\n",
      "CPU Count:          8\n",
      "Memory Avail:       5.26 GB / 16.00 GB (32.9%)\n",
      "Disk Space Avail:   222.96 GB / 460.43 GB (48.4%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 2700s of the 10800s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-12-28 17:38:54,371\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/Users/haukesteffen/dev/TabularShenanigans/S4E12/AutogluonModels/ag-20241228_163852/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Beginning AutoGluon training ... Time limit = 2698s\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m AutoGluon will save models to \"/Users/haukesteffen/dev/TabularShenanigans/S4E12/AutogluonModels/ag-20241228_163852/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Train Data Rows:    1066666\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Train Data Columns: 19\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Label Column:       Premium Amount\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Problem Type:       regression\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tAvailable Memory:                    6037.16 MB\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTrain Data (Original)  Memory Usage: 695.30 MB (11.5% of available memory)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tWarning: Data size prior to feature transformation consumes 11.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t('float', [])                      :  8 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t('object', [])                     : 10 | ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', ...]\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t('object', ['datetime_as_object']) :  1 | ['Policy Start Date']\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t('category', [])             : 8 | ['Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', ...]\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t('float', [])                : 8 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t('int', ['bool'])            : 2 | ['Gender', 'Smoking Status']\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t\t('int', ['datetime_as_int']) : 5 | ['Policy Start Date', 'Policy Start Date.year', 'Policy Start Date.month', 'Policy Start Date.day', 'Policy Start Date.dayofweek']\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t4.3s = Fit runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t19 features in original data used to generate 23 features in processed data.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTrain Data (Processed) Memory Usage: 115.97 MB (1.9% of available memory)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Data preprocessing and feature engineering runtime = 4.47s ...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1795.23s of the 2693.51s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-942.0198\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t1.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t3.1s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1789.24s of the 2687.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-967.8377\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t1.72s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t3.15s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1784.17s of the 2682.45s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.91% memory usage per fold, 59.62%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=14.91%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=77602)\u001b[0m [1000]\tvalid_set's rmse: 837.77\n",
      "\u001b[36m(_ray_fit pid=77604)\u001b[0m [1000]\tvalid_set's rmse: 837.755\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77602)\u001b[0m [2000]\tvalid_set's rmse: 837.311\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77604)\u001b[0m [2000]\tvalid_set's rmse: 837.343\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77601)\u001b[0m [3000]\tvalid_set's rmse: 835.815\n",
      "\u001b[36m(_ray_fit pid=77602)\u001b[0m [3000]\tvalid_set's rmse: 837.218\n",
      "\u001b[36m(_ray_fit pid=77602)\u001b[0m [4000]\tvalid_set's rmse: 837.269\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77633)\u001b[0m [1000]\tvalid_set's rmse: 838.016\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77639)\u001b[0m [1000]\tvalid_set's rmse: 838.978\n",
      "\u001b[36m(_ray_fit pid=77633)\u001b[0m [2000]\tvalid_set's rmse: 837.641\n",
      "\u001b[36m(_ray_fit pid=77650)\u001b[0m [1000]\tvalid_set's rmse: 836.729\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77633)\u001b[0m [3000]\tvalid_set's rmse: 837.545\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77650)\u001b[0m [2000]\tvalid_set's rmse: 836.358\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77650)\u001b[0m [3000]\tvalid_set's rmse: 836.254\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=77650)\u001b[0m [4000]\tvalid_set's rmse: 836.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-837.9725\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t177.89s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t54.56s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 1597.59s of the 2495.87s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.10% memory usage per fold, 64.41%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=16.10%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=77668)\u001b[0m [1000]\tvalid_set's rmse: 833.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-835.3215\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t40.88s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t10.86s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1553.94s of the 2452.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-836.3109\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t738.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t21.64s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 792.87s of the 1691.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.44% memory usage per fold, 61.75%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=15.44%)\n",
      "\u001b[36m(_ray_fit pid=77758)\u001b[0m \tRan out of time, early stopping on iteration 331.\n",
      "\u001b[36m(_ray_fit pid=77829)\u001b[0m \tRan out of time, early stopping on iteration 297.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-839.7034\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t633.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t0.45s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 157.25s of the 1055.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 214 due to low time. Expected time usage reduced from 219.7s -> 157.0s...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-837.7403\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t104.9s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t15.36s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 36.60s of the 934.88s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=77828)\u001b[0m \tRan out of time, early stopping on iteration 293.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.14% memory usage per fold, 48.27%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=24.14%)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 30.98s of the 929.27s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.85% memory usage per fold, 75.41%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=18.85%)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-838.3682\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t26.86s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t2.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 2.58s of the 900.86s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=1, gpus=0, memory=9.67%)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 889.79s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.609, 'RandomForestMSE_BAG_L1': 0.391}\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-834.6325\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t0.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 889.08s of the 889.00s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.67% memory usage per fold, 58.68%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=14.67%)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-834.3459\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t21.12s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t3.77s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 865.23s of the 865.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.65% memory usage per fold, 62.60%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=15.65%)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-834.2672\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t14.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t2.09s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 848.98s of the 848.91s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 123 due to low time. Expected time usage reduced from 2062.4s -> 848.4s...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-837.217\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t576.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t10.49s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 261.12s of the 261.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 17.83% memory usage per fold, 71.31%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=17.83%)\n",
      "\u001b[36m(_ray_fit pid=78051)\u001b[0m \tRan out of time, early stopping on iteration 98.\n",
      "\u001b[36m(_ray_fit pid=78110)\u001b[0m \tRan out of time, early stopping on iteration 103.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-834.4097\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t207.68s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t0.37s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 51.33s of the 51.25s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 57 due to low time. Expected time usage reduced from 266.2s -> 50.6s...\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 32.47s compared to 30.23s of available time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesMSE_BAG_L2.\n",
      "\u001b[36m(_ray_fit pid=78112)\u001b[0m \tRan out of time, early stopping on iteration 103.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 14.85s of the 14.77s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 24.67% memory usage per fold, 49.34%/80.00% total).\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=24.67%)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 9.15s of remaining time.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L2': 0.52, 'LightGBMXT_BAG_L2': 0.36, 'RandomForestMSE_BAG_L2': 0.12}\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t-834.1636\t = Validation score   (-root_mean_squared_error)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t0.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m AutoGluon training complete, total runtime = 2689.86s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1656.4 rows/s (133334 batch size)\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/haukesteffen/dev/TabularShenanigans/S4E12/AutogluonModels/ag-20241228_163852/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=77568)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                     model  score_holdout   score_val              eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      WeightedEnsemble_L3    -833.432346 -834.163599  root_mean_squared_error       25.699314     127.519196  2339.549270                 0.001856                0.010204           0.933408            3       True         14\n",
      "1          LightGBM_BAG_L2    -833.459806 -834.267235  root_mean_squared_error       23.934046     113.255234  1740.564826                 0.791288                2.087964          14.154720            2       True         11\n",
      "2        LightGBMXT_BAG_L2    -833.505816 -834.345912  root_mean_squared_error       24.473036     114.933116  1747.534438                 1.330278                3.765846          21.124332            2       True         10\n",
      "3          CatBoost_BAG_L2    -833.588155 -834.409656  root_mean_squared_error       23.273642     111.541270  1934.091504                 0.130884                0.374000         207.681398            2       True         13\n",
      "4      WeightedEnsemble_L2    -833.722499 -834.632518  root_mean_squared_error        4.284969      32.509566   780.536937                 0.002259                0.011217           0.677210            2       True          9\n",
      "5          LightGBM_BAG_L1    -834.284672 -835.321471  root_mean_squared_error        3.437595      10.861169    40.884591                 3.437595               10.861169          40.884591            1       True          4\n",
      "6   RandomForestMSE_BAG_L1    -835.019842 -836.310880  root_mean_squared_error        0.845115      21.637180   738.975136                 0.845115               21.637180         738.975136            1       True          5\n",
      "7   RandomForestMSE_BAG_L2    -835.074300 -837.217000  root_mean_squared_error       23.575892     121.655182  2303.336810                 0.433134               10.487912         576.926704            2       True         12\n",
      "8     ExtraTreesMSE_BAG_L1    -836.145688 -837.740274  root_mean_squared_error        0.582906      15.355925   104.901048                 0.582906               15.355925         104.901048            1       True          7\n",
      "9        LightGBMXT_BAG_L1    -836.624082 -837.972474  root_mean_squared_error       15.255457      54.561407   177.894975                15.255457               54.561407         177.894975            1       True          3\n",
      "10          XGBoost_BAG_L1    -837.229145 -838.368185  root_mean_squared_error        1.673594       2.048932    26.856971                 1.673594                2.048932          26.856971            1       True          8\n",
      "11         CatBoost_BAG_L1    -838.610078 -839.703446  root_mean_squared_error        0.478380       0.451653   633.457477                 0.478380                0.451653         633.457477            1       True          6\n",
      "12   KNeighborsUnif_BAG_L1    -940.458069 -942.019849  root_mean_squared_error        0.427914       3.099527     1.721196                 0.427914                3.099527           1.721196            1       True          1\n",
      "13   KNeighborsDist_BAG_L1    -966.754442 -967.837689  root_mean_squared_error        0.441797       3.151478     1.718711                 0.441797                3.151478           1.718711            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t2720s\t = DyStack   runtime |\t8080s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 8080s\n",
      "AutoGluon will save models to \"/Users/haukesteffen/dev/TabularShenanigans/S4E12/AutogluonModels/ag-20241228_163852\"\n",
      "Train Data Rows:    1200000\n",
      "Train Data Columns: 19\n",
      "Label Column:       Premium Amount\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    8247.41 MB\n",
      "\tTrain Data (Original)  Memory Usage: 782.25 MB (9.5% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 9.5% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting DatetimeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])                      :  8 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
      "\t\t('object', [])                     : 10 | ['Gender', 'Marital Status', 'Education Level', 'Occupation', 'Location', ...]\n",
      "\t\t('object', ['datetime_as_object']) :  1 | ['Policy Start Date']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])             : 8 | ['Marital Status', 'Education Level', 'Occupation', 'Location', 'Policy Type', ...]\n",
      "\t\t('float', [])                : 8 | ['Age', 'Annual Income', 'Number of Dependents', 'Health Score', 'Previous Claims', ...]\n",
      "\t\t('int', ['bool'])            : 2 | ['Gender', 'Smoking Status']\n",
      "\t\t('int', ['datetime_as_int']) : 5 | ['Policy Start Date', 'Policy Start Date.year', 'Policy Start Date.month', 'Policy Start Date.day', 'Policy Start Date.dayofweek']\n",
      "\t4.6s = Fit runtime\n",
      "\t19 features in original data used to generate 23 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 130.47 MB (1.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.91s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 5381.78s of the 8074.68s of remaining time.\n",
      "\t-941.6147\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t3.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 5376.10s of the 8069.00s of remaining time.\n",
      "\t-966.7311\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.86s\t = Training   runtime\n",
      "\t3.61s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5370.40s of the 8063.31s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.06% memory usage per fold, 52.25%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.06%)\n",
      "\t-837.6152\t = Validation score   (-root_mean_squared_error)\n",
      "\t218.61s\t = Training   runtime\n",
      "\t94.26s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 5143.11s of the 7836.02s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.87% memory usage per fold, 55.48%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.87%)\n",
      "\t-835.0705\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.15s\t = Training   runtime\n",
      "\t12.6s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 5089.94s of the 7782.84s of remaining time.\n",
      "\t-835.9267\t = Validation score   (-root_mean_squared_error)\n",
      "\t468.79s\t = Training   runtime\n",
      "\t24.11s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 4596.60s of the 7289.50s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 15.93% memory usage per fold, 63.74%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=15.93%)\n",
      "\t-836.5743\t = Validation score   (-root_mean_squared_error)\n",
      "\t3677.28s\t = Training   runtime\n",
      "\t1.29s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 917.57s of the 3610.48s of remaining time.\n",
      "\t-837.1274\t = Validation score   (-root_mean_squared_error)\n",
      "\t160.54s\t = Training   runtime\n",
      "\t22.82s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 733.61s of the 3426.51s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 22.36% memory usage per fold, 44.71%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=22.36%)\n",
      "\t-846.9632\t = Validation score   (-root_mean_squared_error)\n",
      "\t543.82s\t = Training   runtime\n",
      "\t4.53s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 186.99s of the 2879.89s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 18.86% memory usage per fold, 75.42%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=18.86%)\n",
      "\t-836.2687\t = Validation score   (-root_mean_squared_error)\n",
      "\t152.18s\t = Training   runtime\n",
      "\t6.62s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 31.79s of the 2724.69s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 10.54% memory usage per fold, 42.15%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=10.54%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 23.40s of the 2716.31s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 13.07% memory usage per fold, 52.29%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=13.07%)\n",
      "2024-12-28 19:53:42,424\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-28 19:53:42,428\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "2024-12-28 19:53:42,428\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-835.2028\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.6s\t = Training   runtime\n",
      "\t7.49s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 538.18s of the 2692.47s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.455, 'RandomForestMSE_BAG_L1': 0.364, 'LightGBMLarge_BAG_L1': 0.136, 'XGBoost_BAG_L1': 0.045}\n",
      "\t-834.3825\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2691.56s of the 2691.48s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.93% memory usage per fold, 67.73%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=16.93%)\n",
      "\t-834.0236\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.58s\t = Training   runtime\n",
      "\t4.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 2663.51s of the 2663.43s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.33% memory usage per fold, 65.30%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (4 workers, per: cpus=2, gpus=0, memory=16.33%)\n",
      "\t-833.9696\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.69s\t = Training   runtime\n",
      "\t2.51s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 2643.46s of the 2643.37s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 267 due to low time. Expected time usage reduced from 2963.4s -> 2642.6s...\n",
      "\t-835.378\t = Validation score   (-root_mean_squared_error)\n",
      "\t1704.81s\t = Training   runtime\n",
      "\t24.92s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 913.01s of the 912.93s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 20.18% memory usage per fold, 40.35%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=20.18%)\n",
      "\t-833.9795\t = Validation score   (-root_mean_squared_error)\n",
      "\t720.33s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 190.44s of the 190.36s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 177 due to low time. Expected time usage reduced from 320.6s -> 189.6s...\n",
      "\t-835.1381\t = Validation score   (-root_mean_squared_error)\n",
      "\t136.55s\t = Training   runtime\n",
      "\t13.42s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 39.82s of the 39.73s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 31.56% memory usage per fold, 63.12%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=31.56%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 32.98s of the 32.90s of remaining time.\n",
      "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 22.57% memory usage per fold, 45.14%/80.00% total).\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=4, gpus=0, memory=22.57%)\n",
      "2024-12-28 20:38:25,669\tERROR worker.py:422 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\t-837.1979\t = Validation score   (-root_mean_squared_error)\n",
      "\t30.39s\t = Training   runtime\n",
      "\t2.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 0.39s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.333, 'LightGBMXT_BAG_L2': 0.222, 'CatBoost_BAG_L2': 0.222, 'RandomForestMSE_BAG_L2': 0.167, 'ExtraTreesMSE_BAG_L2': 0.056}\n",
      "\t-833.8455\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.49s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 8080.8s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1031.8 rows/s (150000 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/Users/haukesteffen/dev/TabularShenanigans/S4E12/AutogluonModels/ag-20241228_163852\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.tabular.predictor.predictor.TabularPredictor at 0x306e14bf0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "autogluon_model = TabularPredictor(\n",
    "    label=label,\n",
    "    eval_metric='rmse' #ag_rmsle_clamped_scorer\n",
    ")\n",
    "autogluon_model.fit(\n",
    "    train,\n",
    "    presets='best_quality',\n",
    "    time_limit=3*60*60,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MLJar**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear algorithm was disabled.\n",
      "AutoML directory: AutoML_4\n",
      "The task is regression with evaluation metric rmse\n",
      "AutoML will use algorithms: ['Decision Tree', 'Random Forest', 'Extra Trees', 'LightGBM', 'Xgboost', 'CatBoost', 'Neural Network', 'Nearest Neighbors']\n",
      "AutoML will stack models\n",
      "AutoML will ensemble available models\n",
      "AutoML steps: ['adjust_validation', 'simple_algorithms', 'default_algorithms', 'not_so_random', 'mix_encoding', 'golden_features', 'kmeans_features', 'insert_random_feature', 'features_selection', 'hill_climbing_1', 'hill_climbing_2', 'boost_on_errors', 'ensemble', 'stack', 'ensemble_stacked']\n",
      "* Step adjust_validation will try to check up to 1 model\n",
      "1_DecisionTree rmse 859.993049 trained in 461.52 seconds\n",
      "Disable stacking for split validation\n",
      "* Step simple_algorithms will try to check up to 2 models\n",
      "2_DecisionTree rmse 857.173619 trained in 473.27 seconds\n",
      "3_DecisionTree rmse 857.173619 trained in 487.26 seconds\n",
      "* Step default_algorithms will try to check up to 6 models\n",
      "4_Default_LightGBM rmse 843.672865 trained in 455.96 seconds\n",
      "5_Default_Xgboost rmse 844.761465 trained in 427.3 seconds\n",
      "6_Default_CatBoost rmse 847.24925 trained in 206.62 seconds\n",
      "7_Default_NeuralNetwork rmse 865.288487 trained in 442.51 seconds\n",
      "* Step not_so_random will try to check up to 54 models\n",
      "17_LightGBM rmse 844.259567 trained in 438.85 seconds\n",
      "8_Xgboost rmse 844.127219 trained in 443.53 seconds\n",
      "26_CatBoost rmse 846.569899 trained in 619.61 seconds\n",
      "35_RandomForest rmse 858.06773 trained in 383.42 seconds\n",
      "44_ExtraTrees rmse 863.0776 trained in 446.15 seconds\n",
      "53_NeuralNetwork rmse 865.287631 trained in 473.5 seconds\n",
      "18_LightGBM rmse 845.207778 trained in 455.82 seconds\n",
      "9_Xgboost rmse 844.223618 trained in 473.34 seconds\n",
      "* Step mix_encoding will try to check up to 1 model\n",
      "8_Xgboost_categorical_mix rmse 844.131578 trained in 436.43 seconds\n",
      "* Step golden_features will try to check up to 3 models\n",
      "None 10\n",
      "Add Golden Feature: Previous Claims_sum_Number of Dependents\n",
      "Add Golden Feature: Previous Claims_multiply_Number of Dependents\n",
      "Add Golden Feature: Annual Income_ratio_Credit Score\n",
      "Add Golden Feature: Credit Score_ratio_Annual Income\n",
      "Add Golden Feature: Previous Claims_ratio_Credit Score\n",
      "Add Golden Feature: Number of Dependents_multiply_Annual Income\n",
      "Add Golden Feature: Previous Claims_diff_Insurance Duration\n",
      "Add Golden Feature: Previous Claims_ratio_Number of Dependents\n",
      "Add Golden Feature: Number of Dependents_ratio_Previous Claims\n",
      "Add Golden Feature: Number of Dependents_diff_Previous Claims\n",
      "Created 10 Golden Features in 3.91 seconds.\n",
      "4_Default_LightGBM_GoldenFeatures rmse 843.760366 trained in 462.64 seconds\n",
      "* Step kmeans_features will try to check up to 3 models\n",
      "4_Default_LightGBM_KMeansFeatures rmse 843.706398 trained in 465.53 seconds\n",
      "Not enough time to perform features selection. Skip\n",
      "Time needed for features selection ~ 3281.0 seconds\n",
      "Please increase total_time_limit to at least (32871 seconds) to have features selection\n",
      "Skip insert_random_feature because no parameters were generated.\n",
      "Skip features_selection because no parameters were generated.\n",
      "* Step hill_climbing_1 will try to check up to 23 models\n",
      "54_LightGBM rmse 843.510646 trained in 411.38 seconds\n",
      "55_LightGBM rmse 843.45958 trained in 321.07 seconds\n",
      "56_LightGBM rmse 843.921365 trained in 310.97 seconds\n",
      "57_LightGBM rmse 843.69378 trained in 304.69 seconds\n",
      "58_LightGBM_GoldenFeatures rmse 843.66579 trained in 355.32 seconds\n",
      "59_LightGBM_GoldenFeatures rmse 843.644009 trained in 294.45 seconds\n",
      "* Step hill_climbing_2 will try to check up to 23 models\n",
      "60_LightGBM rmse 843.759443 trained in 289.71 seconds\n",
      "61_LightGBM rmse 843.637769 trained in 14728.15 seconds\n",
      "* Step ensemble will try to check up to 1 model\n",
      "Ensemble rmse 843.247647 trained in 0.68 seconds\n",
      "AutoML fit time: 25114.1 seconds\n",
      "AutoML best model: Ensemble\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AutoML(eval_metric=&#x27;rmse&#x27;, mode=&#x27;Compete&#x27;, total_time_limit=10800)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;AutoML<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>AutoML(eval_metric=&#x27;rmse&#x27;, mode=&#x27;Compete&#x27;, total_time_limit=10800)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "AutoML(eval_metric='rmse', mode='Compete', total_time_limit=10800)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m The node with node id: 41bb31ae2603fd078ce011738f23a47d81c5a7eddba38fdb6b817762 and address: 127.0.0.1 and node name: 127.0.0.1 has been marked dead because the detector has missed too many heartbeats from it. This can happen when a \t(1) raylet crashes unexpectedly (OOM, etc.) \n",
      "\t(2) raylet has lagging heartbeats due to slow network or busy workload.\n",
      "\u001b[33m(raylet)\u001b[0m Raylet is terminated. Termination is unexpected. Possible reasons include: (1) SIGKILL by the user or system OOM killer, (2) Invalid memory access from Raylet causing SIGSEGV or SIGBUS, (3) Other termination signals. Last 20 lines of the Raylet logs:\n",
      "    [state-dump] \n",
      "    [state-dump] \n",
      "    [2024-12-30 22:31:48,378 I 77564 6540362] (raylet) accessor.cc:762: Received notification for node, IsAlive = 0 node_id=41bb31ae2603fd078ce011738f23a47d81c5a7eddba38fdb6b817762\n",
      "    [2024-12-30 22:31:48,393 C 77564 6540362] (raylet) node_manager.cc:1043: [Timeout] Exiting because this node manager has mistakenly been marked as dead by the GCS: GCS failed to check the health of this node for 5 times. This is likely because the machine or raylet has become overloaded.\n",
      "    *** StackTrace Information ***\n",
      "    0   raylet                              0x0000000102f38034 _ZN3raylsERNSt3__113basic_ostreamIcNS0_11char_traitsIcEEEERKNS_10StackTraceE + 84 ray::operator<<()\n",
      "    1   raylet                              0x0000000102f3b640 _ZN3ray6RayLogD2Ev + 84 ray::RayLog::~RayLog()\n",
      "    2   raylet                              0x0000000102503c4c _ZN3ray6raylet11NodeManager11NodeRemovedERKNS_6NodeIDE + 1860 ray::raylet::NodeManager::NodeRemoved()\n",
      "    3   raylet                              0x00000001025a5cb8 _ZNSt3__110__function6__funcIZN3ray6raylet11NodeManager11RegisterGcsEvE4$_29NS_9allocatorIS5_EEFvRKNS2_6NodeIDEONS2_3rpc11GcsNodeInfoEEEclESA_SD_ + 188 std::__1::__function::__func<>::operator()()\n",
      "    4   raylet                              0x0000000102744d94 _ZN3ray3gcs16NodeInfoAccessor18HandleNotificationEONS_3rpc11GcsNodeInfoE + 2312 ray::gcs::NodeInfoAccessor::HandleNotification()\n",
      "    5   raylet                              0x0000000102828208 _ZNSt3__110__function6__funcIZN3ray3gcs13GcsSubscriber20SubscribeAllNodeInfoERKNS_8functionIFvONS2_3rpc11GcsNodeInfoEEEERKNS5_IFvNS2_6StatusEEEEE3$_4NS_9allocatorISI_EEFvONS6_10PubMessageEEEclESM_ + 224 std::__1::__function::__func<>::operator()()\n",
      "    6   raylet                              0x0000000102982980 _ZN12EventTracker15RecordExecutionERKNSt3__18functionIFvvEEENS0_10shared_ptrI11StatsHandleEE + 232 EventTracker::RecordExecution()\n",
      "    7   raylet                              0x000000010297a2e4 _ZNSt3__110__function6__funcIZN23instrumented_io_context4postENS_8functionIFvvEEERKNS_12basic_stringIcNS_11char_traitsIcEENS_9allocatorIcEEEExE3$_0NS9_ISE_EES4_EclEv + 56 std::__1::__function::__func<>::operator()()\n",
      "    8   raylet                              0x0000000102979880 _ZN5boost4asio6detail18completion_handlerINSt3__18functionIFvvEEENS0_10io_context19basic_executor_typeINS3_9allocatorIvEELm0EEEE11do_completeEPvPNS1_19scheduler_operationERKNS_6system10error_codeEm + 192 boost::asio::detail::completion_handler<>::do_complete()\n",
      "    9   raylet                              0x0000000102fadd3c _ZN5boost4asio6detail9scheduler10do_run_oneERNS1_27conditionally_enabled_mutex11scoped_lockERNS1_21scheduler_thread_infoERKNS_6system10error_codeE + 624 boost::asio::detail::scheduler::do_run_one()\n",
      "    10  raylet                              0x0000000102fa28b4 _ZN5boost4asio6detail9scheduler3runERNS_6system10error_codeE + 200 boost::asio::detail::scheduler::run()\n",
      "    11  raylet                              0x0000000102fa279c _ZN5boost4asio10io_context3runEv + 32 boost::asio::io_context::run()\n",
      "    12  raylet                              0x00000001024acf10 main + 4480 main\n",
      "    13  dyld                                0x000000019511c274 start + 2840 start\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from supervised.automl import AutoML\n",
    "\n",
    "mljar_model = AutoML(\n",
    "    eval_metric='rmse',\n",
    "    mode='Compete',\n",
    "    total_time_limit=3*60*60\n",
    ")\n",
    "mljar_model.fit(\n",
    "    train.drop(columns=[label]),\n",
    "    train[label]\n",
    ")\n",
    "#predictions = automl.predict(test[[label]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TPOT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "prep = enc.fit_transform(train.drop(columns=[label, 'Policy Start Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "\n",
    "tpot_model = TPOTRegressor(\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    max_time_mins=3*60,\n",
    ")\n",
    "tpot_model.fit(\n",
    "    prep,\n",
    "    train[[label]].rename(columns={label: 'class'})\n",
    ")\n",
    "#print(tpot_model.score(X_test, y_test))\n",
    "#tpot_model.export('tpot.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TO-DO: Train NN to ensemble AutoML models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = predictor.predict(test)\n",
    "#test[label] = np.maximum(predictions.to_list(), 0)\n",
    "#test[label].to_csv('submission_5.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LearningPyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
